[
  {
    "objectID": "mld_software.html",
    "href": "mld_software.html",
    "title": "Software",
    "section": "",
    "text": "The concepts and procedures introduced in this lecture are straightforward but rather tedious to implement (just think of writing down all these transition rules for the finite state machine using binary variables). The authors of the MLD framework also developed a modelling language HYSDEL for entering a discrete hybrid automaton and subsequently converting it to the MLD description. Several links on the internet and in publications refer to the page https://control.ee.ethz.ch/~hybrid/hysdel, which is no longer available (as of December 2024). However, implementation of the HYSDEL parser/compiler is shipped together with Hybrid Toolbox created by the Alberto Bemporad, one of original HYSDEL authors.\nAlternatively, Multiparametric Toolbox 3 is a general framework for control-oriented modeling, simulation and optimization, which also contains HYSDEL among the dependencies.\nA new(er) version 3 of HYSDEL has been developed by Michal Kvasnica, but both Hybrid Toolbox and Multiparametric Toolbox are still based on HYSDEL 2.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Software"
    ]
  },
  {
    "objectID": "mld_software.html#hysdel",
    "href": "mld_software.html#hysdel",
    "title": "Software",
    "section": "",
    "text": "The concepts and procedures introduced in this lecture are straightforward but rather tedious to implement (just think of writing down all these transition rules for the finite state machine using binary variables). The authors of the MLD framework also developed a modelling language HYSDEL for entering a discrete hybrid automaton and subsequently converting it to the MLD description. Several links on the internet and in publications refer to the page https://control.ee.ethz.ch/~hybrid/hysdel, which is no longer available (as of December 2024). However, implementation of the HYSDEL parser/compiler is shipped together with Hybrid Toolbox created by the Alberto Bemporad, one of original HYSDEL authors.\nAlternatively, Multiparametric Toolbox 3 is a general framework for control-oriented modeling, simulation and optimization, which also contains HYSDEL among the dependencies.\nA new(er) version 3 of HYSDEL has been developed by Michal Kvasnica, but both Hybrid Toolbox and Multiparametric Toolbox are still based on HYSDEL 2.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Software"
    ]
  },
  {
    "objectID": "mld_software.html#support-for-indicator-constraints-in-optimization-modelling-languages-and-optimization-solvers",
    "href": "mld_software.html#support-for-indicator-constraints-in-optimization-modelling-languages-and-optimization-solvers",
    "title": "Software",
    "section": "Support for indicator constraints in optimization modelling languages and optimization solvers",
    "text": "Support for indicator constraints in optimization modelling languages and optimization solvers\nThe key trick for the MLD framework was that of reformulating the indicator constraint \n[\\delta = 1] \\leftrightarrow [f(\\bm x) \\leq 0]\n using the Big-M method as two inequalities \n\\begin{aligned}\nf(\\bm x) &\\leq (1-\\delta) M,\\\\\nf(\\bm x) &\\geq \\epsilon + (m-\\epsilon)\\delta\n\\end{aligned}\n using a sufficiently large constant M and a sufficiently small constant m. But some solvers for mixed integer programming/optimization support the indicator constraints directly, without the need to come up with M and m. As a matter of fact, only one of the two implications, namely \n[\\delta = 1] \\rightarrow [f(\\bm x) \\leq 0].\n\nGurobi does provide such support for indicator constraints, the increasingly popular free&open-source HiGHS does not, …\nThe key idea behind such support is that mixed integer programming solvers can allow inserting (activating) a linear constraint based on the value of a given binary variable.\nWhen it comes to “modelling” the optimization problems, in Julia’s JuMP package, indicators constraint can be written as follows\n\n\nCode\nusing JuMP\nmodel = Model();\n@variable(model, x)\n@variable(model, y)\n@variable(model, δ, Bin)\n@constraint(model, δ --&gt; {x + y &lt;= 1})\n\n\nδ --&gt; {x + y ≤ 1}\n\n\nWith Python API of Gurobi, the indicator constraints can be added using addGenContstrIndicator function. One possible syntax is\nmodel.addConstr((delta == 1) &gt;&gt; (x + y - 1.0 &lt;= 0.0))\nThe other direction of implication is not supported by optimization solvers (at least not that we know of). Therefore it has no support in optimization modellers such as JuMP either. In order to handle it, besides resorting to the Big-M method, we can also use the equivalent formulation \n[\\delta = 0] \\rightarrow [f(\\bm x) \\geq \\epsilon],\n where some small \\epsilon \\geq 0 had to be added to turn the strict inequality into a non-strict one.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Software"
    ]
  },
  {
    "objectID": "mld_mld_and_pwa.html",
    "href": "mld_mld_and_pwa.html",
    "title": "Mixed logical dynamical (MLD) systems",
    "section": "",
    "text": "We have just learnt how the logical conditions that encode the individual components of discrete hybrid automata can be turned into linear inequalities. Here we summarize them all into a single mathematical model called mixed logical dynamical (MLD).\n\\boxed{\n\\begin{aligned}\n\\bm x(k+1) &= \\mathbf A\\bm x(k) + \\mathbf B_u \\bm u(k) + \\mathbf B_\\delta \\bm \\delta(k) + \\mathbf B_z\\bm z(k) + \\mathbf B_0,\\\\\n\\bm y(k) &= \\mathbf C\\bm x(k) + \\mathbf D_u \\bm u(k) + \\mathbf D_\\delta \\bm \\delta(k) + \\mathbf D_z(k) \\bm z + \\mathbf D_0,\\\\\n\\mathbf E_\\delta \\bm \\delta &+ \\mathbf E_z \\bm z(k) \\leq \\mathbf E_u \\bm u(k) + \\mathbf E_x \\bm x(k) + \\mathbf E_0,  \n\\end{aligned}}\n\\tag{1} where \n\\bm x(k) = \\begin{bmatrix}\\bm x_\\mathrm{c}(k) \\\\ \\bm x_\\mathrm{b}(k) \\end{bmatrix},\\qquad \\bm u(k) = \\begin{bmatrix}\\bm u_\\mathrm{c}(k) \\\\ \\bm u_\\mathrm{b}(k) \\end{bmatrix},\\qquad \\bm y(k) = \\begin{bmatrix}\\bm y_\\mathrm{c}(k) \\\\ \\bm y_\\mathrm{b}(k) \\end{bmatrix},\n which reads that the state and control input vectors are composed of the continuous (real) and binary variables.\nThe first two (sets of) equations resemble the state and output equations of a linear time-invariant (LTI) system, but with some additional terms corresponding to auxilliary variebles (plus an offset). The auxilliary variables are not completely arbitrary – they must comply with the third (set of) equation(s).",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Mixed logical dynamical (MLD) systems"
    ]
  },
  {
    "objectID": "mld_mld_and_pwa.html#uniqueness-of-the-state-and-output-responses-predicted-by-mld-models",
    "href": "mld_mld_and_pwa.html#uniqueness-of-the-state-and-output-responses-predicted-by-mld-models",
    "title": "Mixed logical dynamical (MLD) systems",
    "section": "Uniqueness of the state and output responses predicted by MLD models",
    "text": "Uniqueness of the state and output responses predicted by MLD models\nAn immediate question that must pop up in our minds is that of the uniqueness of the state and output responses predicted by the MLD model. For given \\bm x(k) and \\bm u(k), uniqueness of the values of the auxuliary variables \\bm \\lambda(k) and \\bm z(k) compliant with the inequalities, hence the next state \\bm x(k+1) and the output \\bm y(k), is not immediately obvious. As claimed in the seminal paper [1], MLD models corresponding to real systems do have unique solutions.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Mixed logical dynamical (MLD) systems"
    ]
  },
  {
    "objectID": "mld_mld_and_pwa.html#examples",
    "href": "mld_mld_and_pwa.html#examples",
    "title": "Mixed logical dynamical (MLD) systems",
    "section": "Examples",
    "text": "Examples\n\nExample 1 (Switched linear system) We consider a discrete-time switched system that switches between two linear systems \nx(k+1) = a_i x(k) + b_i u(k), \\quad i\\in\\{0,1\\},\n where i=0 if x(k)&lt; 0 and i=1 otherwise.\nThe auxilliary binary variable \\delta (actually \\delta(k), one for each discrete time k) is introduced to encode the switching condition: \n[\\delta(k) = 1] \\leftrightarrow [-x(k)\\leq 0].\n\nThis equivalence can be rewritten as \n\\begin{aligned}\n-x(k) &\\leq (1-\\delta(k))M,\\\\\n-x(k) &\\geq \\epsilon + (m-\\epsilon)\\delta(k),\n\\end{aligned}\n where m and M are lower and upper bounds on x(k), respectively, and \\epsilon is a small positive number. Say, if it is known that x\\in [-10,10], then m=-10, M=10. We can set \\epsilon = 10^{-8}.\nFurthermore, just a single continuous (real) variable z is introduced to encode one of two modes of the system: \n\\begin{aligned}\\\\\n[\\delta(k) = 1] \\rightarrow [z(k) &= a_2 x(k) + b_2 u(k)],\\\\\n[\\delta(k) = 0] \\rightarrow [z(k) &= a_1 x(k) + b_1 u(k)].\n\\end{aligned}\n\nThis can be rewritten as \n\\begin{aligned}\n(m_1-M_2)\\delta(k) + z(k) &\\leq a_1 x(k) + b_1 u(k),\\\\\n(m_2-M_1)\\delta(k) - z(k) &\\leq -a_1 x(k) - b_1 u(k),\\\\\n(m_2-M_1)(1-\\delta(k)) + z(k) &\\leq a_2 x(k) + b_2 u(k),\\\\\n(m_1-M_2)(1-\\delta(k)) - z(k) &\\leq -a_2 x(k) - b_2 u(k),\n\\end{aligned}\n where m_1 and M_1 are lower and upper bounds on a_1 x(k) + b_1 u(k), and m_2 and M_2 are lower and upper bounds on a_2 x(k) + b_2 u(k).\nCollecting all the six inequalities (and reformatting them) we get \n\\begin{aligned}\nM\\delta(k) &\\leq x(k) + M,\\\\\n(m-\\epsilon)\\delta(k) &\\leq -x(k) - \\epsilon,\\\\\n(m_1-M_2)\\delta(k) + z(k) &\\leq a_1 x(k) + b_1 u(k),\\\\\n(m_2-M_1)\\delta(k) - z(k) &\\leq -a_1 x(k) - b_1 u(k),\\\\\n(M_1-m_2)\\delta(k) + z(k) &\\leq a_2 x(k) + b_2 u(k) + (M_1-m_2),\\\\\n(M_2-m_1)\\delta(k) - z(k) &\\leq - a_2 x(k) - b_2 u(k) + (M_2-m_1).\n\\end{aligned}\n\nWe can rewrite these in a compact way as \n\\mathbf E_\\delta \\delta(k) + \\mathbf E_z z(k) \\leq \\mathbf E_x x(k) + \\mathbf E_u u(k) + \\mathbf E_0,\n where \n\\begin{aligned}\n\\mathbf E_\\delta &= \\begin{bmatrix} M\\\\ m-\\epsilon\\\\ m_1-M_2\\\\ m_2-M_1\\\\ M_1-m_2\\\\ M_2-m_1\\end{bmatrix}, \\qquad \\mathbf E_z = \\begin{bmatrix} 0\\\\ 0\\\\ 1\\\\ -1\\\\ 1\\\\ -1\\end{bmatrix},\\\\\n\\mathbf E_x &= \\begin{bmatrix} 1\\\\ -1\\\\ a_1\\\\ -a_1\\\\ a_2\\\\ -a_2\\end{bmatrix},\\qquad \\mathbf E_u = \\begin{bmatrix} 0\\\\ 0\\\\ b_1\\\\ -b_1\\\\ b_2\\\\ -b_2\\end{bmatrix},\\qquad \\mathbf E_0 = \\begin{bmatrix} M\\\\ -\\epsilon\\\\ 0\\\\ 0\\\\ M_1-m_2\\\\ M_2-m_1\\end{bmatrix}.\n\\end{aligned}\n\nOn top of these inequalities, we need to add the state update equation. It is, however, particularly simple in this case: \nx(k+1) = z(k),\n from which we can extract the remaining matrices parameterizing the MLD model in Eq. 1: \n\\begin{aligned}\nA &= 0, \\quad B_u = 0, \\quad B_\\delta = 0, \\quad B_z = 1, \\quad B_0 = 0,\\\\\nC &= 1, \\quad D_u = 0, \\quad D_\\delta = 0, \\quad D_z = 0, \\quad D_0 = 0.\n\\end{aligned}\n\nNote, in particular, that A=0, which might be confusing at first, because it does not correspond to any of the time-discretized LTI models, but it is just a demonstration of the fact that MLD is not a state equation, it is a different type of a model.\nThe inequality paramaterized by \\mathbf E_{\\lambda}, \\mathbf E_z, \\mathbf E_x, \\mathbf E_x and \\mathbf E_o, for given \\bm x(k) and \\bm u(k), defines a set in the \\delta-z plane. When the integrality of \\delta is taken into consideration, the resulting set is just a singleton (a single point), which confirms the uniqueness of the state and output responses predicted by the MLD model, see Fig. 1.\n\n\nShow the code\na1 = -3/4\na2 = 1/5\nb1 = 1.0\nb2 = 1.0\n\nm = -10.0\nM = 10.0\nm1 = m2 = m\nM1 = M2 = M\n\nϵ = 0.001\n\nA  = [0.0;;]\nBu = [0.0]\nBδ = [0.0]\nBz = [1.0]\nBo = [0.0]\n\nC  = [0.0;;]\nDu = [0.0]\nDδ = [0.0]\nDz = [0.0]\nDo = [0.0]\n\nEδ = [M, m-ϵ, m1-M2, m2-M1, M1-m2, M2-m1]\nEz = [0.0, 0.0, 1.0, -1.0, 1.0, -1.0]\nEx = [1.0, -1.0, a1, -a1, a2, -a2]\nEu = [0.0, 0.0, b1, -b1, b2, -b2]\nEo = [M, -ϵ, 0.0, 0.0, M1-m2, M2-m1]\n\nusing JuMP\nusing HiGHS\n\nopt_problem = Model(HiGHS.Optimizer) \nset_silent(opt_problem)\n\n@variable(opt_problem, m &lt;= x⁺ &lt;= M)\n@variable(opt_problem, δ, Bin)\n@variable(opt_problem, z)\n\nx = 2.0\nu = 1.0\n\n@constraint(opt_problem, x⁺ .== A*x + Bu*u + Bδ*δ + Bz*z + Bo)\n@constraint(opt_problem, Eδ*δ + Ez*z .&lt;= Ex*x + Eu*u + Eo)\n@objective(opt_problem, Min, 0.0)\noptimize!(opt_problem)\n\nb = Ex*x + Eu*u + Eo\n\nusing LazySets\n\nH1 = HalfSpace([Eδ[1], Ez[1]], b[1])\nH2 = HalfSpace([Eδ[2], Ez[2]], b[2])\nH3 = HalfSpace([Eδ[3], Ez[3]], b[3])\nH4 = HalfSpace([Eδ[4], Ez[4]], b[4])\nH5 = HalfSpace([Eδ[5], Ez[5]], b[5])\nH6 = HalfSpace([Eδ[6], Ez[6]], b[6])\n\nH = H1 ∩ H2 ∩ H3 ∩ H4 ∩ H5 ∩ H6\n\nusing Plots\n\nplot(H, aspect_ratio=:auto,xlabel=\"δ\",ylabel=\"z\",label=false)\n\nS1 = Singleton([value(δ), value(z)])\nplot!(S1)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: The set of feasible values of the auxilliary variables \\delta and z. The blue polyhedron relaxes the integrality condition on \\delta, but if the condition is taken into consideration, the set is a single (orange) point.\n\n\n\n\n\n\nExample 2 (Switched linear system with memory) Consider the first-order linear system \nx(k+1) = a x(k) + b_{q(k)} u(k), \\quad q(k)\\in\\{0,1\\},\n where the variable q(k) is a discrete state variable that that evolves – with some (perhaps transparent) abuse of notation – according to \nq(k+1) = q(k) \\lor [x(k) \\leq x_{\\text{lb}}],\n and x_\\text{lb}=-1, \\; a=0.5, \\; b_1=0.1, \\; b_2=0.3. The initial continuous state is x(0) = 1, consequently the initial discrete state is q(k)=1. The control input u(k) is constrained to the interval [-10,10].\nObviously, once the real state x(k) falls below x_{\\text{lb}}, the system switches to the other mode and stays there forever.\n\n\n\n\n\n\nNote on the common abuse of notation\n\n\n\nIf we wanted to avoid the aformentioned abuse of notation, we could introduce a Boolean variable Q(k) and write \nQ(k+1) \\leftrightarrow (Q(k) \\lor [x(k) \\leq x_{\\text{lb}}]),\n where Q(k) \\leftrightarrow [q(k)=1]. Or we could write even without explicitly introducing the variable Q(k): \n[q(k+1)=1] \\leftrightarrow ([q(k)=1] \\lor [x(k) \\leq x_{\\text{lb}}]),\n but this makes the model somewhat clumsy and heavy. The somewhat abusive view of q as both a logical (Boolean) and binary (integer) variable is a common practice.\n\n\nTo comply with the notation of this framework, we composed the state vector of the the real and binary components as \n\\bm x(k) = \\begin{bmatrix} x(k)\\\\ q(k)\\end{bmatrix},\n and in what follows we are going to refer to the real and binary state vaiables as x_\\mathrm{c}(k) and x_\\mathrm{b}(k), respectively.\nThe auxilliary binary variable (actually variables, one for each time) \\delta_1(k), is introduced to encode the switching condition (the EG component of the discrete hybrid automaton): \n[\\delta_1(k) = 1] \\leftrightarrow [x_\\mathrm{c}(k) - x_\\text{lb} \\leq 0].\n\nWe can rewrite this as \n\\begin{aligned}\nx_\\mathrm{c}(k) - x_\\text{lb} &\\leq (1-\\delta_1(k))M,\\\\\nx_\\mathrm{c}(k) - x_\\text{lb} &\\geq \\epsilon + (m-\\epsilon)\\delta_1(k),\n\\end{aligned}\n where m and M are lower and upper bounds on x_\\mathrm{c}(k), respectively, and \\epsilon is a small positive number. Say, it is assumed that x_\\mathrm{c}\\in [-10,10], then m=-10, and M=10. We can set \\epsilon to something like \\epsilon = 10^{-8}.\nWe can also write the mode selection (MS) component of the discrete hybrid automaton as \n\\text{if}\\; [\\delta_1(k) = 1],\\; \\text{then}\\; z(k) = a x_\\mathrm{c}(k) + b_1 u(k), \\; \\text{else} \\; z(k) = a x_\\mathrm{c}(k) + b_2 u(k).\n\nThis we can rewrite as a set of linear inequalities \n\\begin{aligned}\n(m_2-M_1)\\delta_1(k) + z(k) &\\leq a x_\\mathrm{c}(k) + b_2 u(k),\\\\\n(m_1-M_2)\\delta_1(k) - z(k) &\\leq -a x_\\mathrm{c}(k) - b_2 u(k),\\\\\n(m_1-M_2)(1-\\delta_1(k)) + z(k) &\\leq a x_\\mathrm{c}(k) + b_1 u(k),\\\\\n(m_2-M_1)(1-\\delta_1(k)) - z(k) &\\leq -a x_\\mathrm{c}(k) - b_1 u(k),\n\\end{aligned}\n where m_1 and M_1 are lower and upper bounds on a x_\\mathrm{c}(k) + b_1 u(k), and m_2 and M_2 are lower and upper bounds on a x_\\mathrm{c}(k) + b_2 u(k).\nWe also need to encode the finite state automaton/machine (FSM) component of the discrete hybrid automaton. We write down the state update equation once again here: \n[x_\\mathrm{b}(k+1)=1] \\leftrightarrow [x_\\mathrm{b}(k)=1] \\lor [\\delta_1(k) = 1]\n and for convenience, we rewrite it using (temporarily introduced) Boolean variables: \nC \\leftrightarrow A \\lor B.\n The equivalence can be rewritten as \nC \\rightarrow (A \\lor B), \\qquad  (A\\lor B) \\rightarrow C.\n\nThe former can be rewritten as \n\\neg C \\lor (A \\lor B),\n which (when mapping to the original binary variables) is equivalent to \n(1-x_\\mathrm{b}(k+1)) + x_\\mathrm{b}(k) + \\delta_1(k) \\geq 1,\n which can be finally writen as \nx_\\mathrm{b}(k+1) \\leq x_\\mathrm{b}(k) + \\delta_1(k).\n\nNote that this inequality contains the state at the next time, which is not supported by the MLD formalism. But the fix is easy. We introduce another auxilliary binary variable \\delta_2(k) \\coloneqq x_\\mathrm{b}(k+1) and rewrite the inequality as\n\n\\delta_2(k) \\leq x_\\mathrm{b}(k) + \\delta_1(k).\n\nThe latter implication can be rewritten as \n\\neg (A\\lor B) \\lor C,\n which can be rewritten as \n(\\neg A\\land \\neg B) \\lor C,\n in which the distributive law gives \n(\\neg A \\lor C) \\land (\\neg B \\lor C),\n which can finally be rewritten using the original binary variables as two inequalities \n\\begin{aligned}\n(1-x_\\mathrm{b}(k)) + x_\\mathrm{b}(k+1) &\\geq 1,\\\\\n(1-\\delta_1(k)) + x_\\mathrm{b}(k+1) &\\geq 1.\n\\end{aligned}\n\nOnce again, replacing the state at the next time by the auxilliary binary variable \\delta_2(k) \\coloneqq x_\\mathrm{b}(k+1) (and subtracting the 1 from both sides), we get \n\\begin{aligned}\n-x_\\mathrm{b}(k) + \\delta_2(k) &\\geq 0,\\\\\n-\\delta_1(k) + \\delta_2(k) &\\geq 0.\n\\end{aligned}\n\nWe are now ready to start collecting the equations and inequalities into the MLD model. The state update equation is \n\\begin{bmatrix}\nx_\\mathrm{c}(k+1)\\\\\nx_\\mathrm{b}(k+1)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 & 0\\\\\n0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n\\delta_1(k)\\\\\n\\delta_2(k)\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n1\\\\\n0\n\\end{bmatrix}\nz(k).\n\nThe inequalities are \n\\begin{aligned}\nM\\delta_1(k) &\\leq -x_\\mathrm{c}(k) + M + x_\\text{lb},\\\\\n(m-\\epsilon)\\delta_1(k) &\\leq -x_\\mathrm{c}(k) - \\epsilon - x_\\text{lb},\\\\\n(m_2-M_1)\\delta_1(k) + z(k) &\\leq a x_\\mathrm{c}(k) + b_2 u(k),\\\\\n(m_1-M_2)\\delta_1(k) - z(k) &\\leq -a x_\\mathrm{c}(k) - b_2 u(k),\\\\\n(m_1-M_2)(1-\\delta_1(k)) + z(k) &\\leq a x_\\mathrm{c}(k) + b_1 u(k),\\\\\n(m_2-M_1)(1-\\delta_1(k)) - z(k) &\\leq -a x_\\mathrm{c}(k) - b_1 u(k),\\\\\n-\\delta_1(k) + \\delta_2(k) &\\leq x_\\mathrm{b}(k),\\\\\n-\\delta_2(k) &\\leq -x_\\mathrm{b}(k),\\\\\n\\delta_1(k) - \\delta_2(k) &\\leq 0.\n\\end{aligned}\n\nWriting down the matrices is straightforward:\n\n\\mathbf A = \\begin{bmatrix}0 & 0\\\\0 & 0\\end{bmatrix}, \\quad \\mathbf B_u = \\begin{bmatrix}0\\\\0\\end{bmatrix}, \\quad \\mathbf B_\\delta = \\begin{bmatrix}0 & 0\\\\0 & 1\\end{bmatrix}, \\quad \\mathbf B_z = \\begin{bmatrix}1\\\\0\\end{bmatrix}, \\quad \\mathbf B_0 = \\begin{bmatrix}0\\\\0\\end{bmatrix},\n and \n\\begin{aligned}\n\\mathbf E_\\delta &= \\begin{bmatrix} M & 0\\\\ m-\\epsilon & 0\\\\ m_2-M_1 & 0\\\\ m_1-M_2 & 0\\\\M_2-m_1 & 0\\\\M_1-m_2 & 0\\\\ -1 & 1\\\\0 & -1\\\\ 1 & -1\\end{bmatrix}, \\qquad \\mathbf E_z = \\begin{bmatrix} 0\\\\ 0\\\\ 1\\\\ -1\\\\ 1\\\\ -1\\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix},\\\\\n\\mathbf E_x &= \\begin{bmatrix} -1 & 0\\\\ -1 & 0\\\\ a & 0\\\\ -a_1 & 0\\\\ a_2 & 0\\\\ -a_2 & 0 \\\\ 0 & 1\\\\ 0 & -1 \\\\ 0 & 0\\end{bmatrix},\\qquad \\mathbf E_u = \\begin{bmatrix} 0\\\\ 0\\\\ b_2\\\\ -b_2\\\\ b_1\\\\ -b_1\\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix},\\qquad \\mathbf E_0 = \\begin{bmatrix} M+x_\\text{lb}\\\\ -\\epsilon-x_\\text{lb}\\\\ 0\\\\ 0\\\\ M_2-m_1\\\\ M_1-m_2\\\\ 0 \\\\ 0 \\\\ 0\\end{bmatrix}.\n\\end{aligned}\n\n\nTwo general lessons can be learnt from the previous example. First, the procedure of finding the matrices defining the MLD model is rather tedious and error-prone. Second, the MLD model is, indeed, not a state-space model, but a different kind of a model. In particular, in the latter example we can see that the control input u does not affect the next state through the state update equation, it only appears in the inequalities.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Mixed logical dynamical (MLD) systems"
    ]
  },
  {
    "objectID": "mld_mld_and_pwa.html#hysdel-language",
    "href": "mld_mld_and_pwa.html#hysdel-language",
    "title": "Mixed logical dynamical (MLD) systems",
    "section": "HYSDEL language",
    "text": "HYSDEL language\nTo address the first lesson learnt from the examples – that the procedure for turning the discrete-time hybrid automaton into a MLD model is rather tedious and error-prone –, some automation of the procedure is desirable. The only tool for this that we are aware of is the HYSDEL language and parser (see the section on software for details on availability). Here we do not explain it – we refer the student to the section 16.7 in [2], which is freely downloadable –, but we show the code for Example 1, which is perhaps self-explaining.\nSYSTEM switched_LTI_1 {\n    INTERFACE {\n        INPUT {\n            REAL u [-1.0,1.0];\n        }\n        STATE {\n            REAL x [-10, 10];\n        }\n        OUTPUT {\n            REAL y;\n        }\n        PARAMETER {\n            REAL A1 = -3/4;\n            REAL A2 = 1/5;\n            REAL B1 = 1;\n            REAL B2 = 1;\n        }\n    }\n    IMPLEMENTATION {\n        AUX {\n            REAL z;\n            BOOL delta;\n        }\n        AD {\n            delta = x &gt;= 0;\n        }\n        DA {\n            z = {IF delta THEN A2*x + B2*u ELSE A1*x + B1*u};\n        }\n        CONTINUOUS {\n            x = z;\n        }\n        OUTPUT {\n            y = x;\n        }\n    }\n}",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Mixed logical dynamical (MLD) systems"
    ]
  },
  {
    "objectID": "mld_mld_and_pwa.html#piecewise-affine-systems",
    "href": "mld_mld_and_pwa.html#piecewise-affine-systems",
    "title": "Mixed logical dynamical (MLD) systems",
    "section": "Piecewise affine systems",
    "text": "Piecewise affine systems\nTightly related to the MLD model is another representation of a hybrid system – a PWA (piecewise affine) system (actually a model) \n\\begin{aligned}\n\\bm x(k+1) &= \\mathbf A_{i(k)}\\bm x(k) + \\mathbf B_{i(k)} \\bm u(k) + \\mathbf f_{i(k)},\\\\\n\\bm y(k) &= \\mathbf C_{i(k)}\\bm x(k) + \\mathbf D_{i(k)} \\bm u(k) + \\mathbf g_{i(k)},\\\\\n& \\; \\mathbf H_{i(k)} \\bm x(k) + \\mathbf J_{i(k)} \\bm u(k) \\leq \\mathbf K_{i(k)}.\n\\end{aligned}",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Mixed logical dynamical (MLD) systems"
    ]
  },
  {
    "objectID": "mld_mld_and_pwa.html#equivalence-of-mld-dha-and-pwa-and-some-more",
    "href": "mld_mld_and_pwa.html#equivalence-of-mld-dha-and-pwa-and-some-more",
    "title": "Mixed logical dynamical (MLD) systems",
    "section": "Equivalence of MLD, DHA, and PWA (and some more)",
    "text": "Equivalence of MLD, DHA, and PWA (and some more)\nAs stated in the section 16.8 in the freely downloadable [2], the three models – MLD, DHA, and PWA – are equivalent. In fact two more kinds of models that we also covered in the course – linear complementarity systems and max-(min-)plus(-scaling) systems are also included in this equivalence statement, the key reference is [3].",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Mixed logical dynamical (MLD) systems"
    ]
  },
  {
    "objectID": "petri_nets_references.html",
    "href": "petri_nets_references.html",
    "title": "Literature",
    "section": "",
    "text": "Literature for Petri nets is vast, but a decent (and perfectly satisfactory) introduction can be found in Chapter 4 and 5.3 (for the timed PN) of the classical (and award-winning) reference [1]. Note that electronic version (in fact, PDF) is accessible through the NTK library (upon CTU login, for example to usermap first).\nA nice introduction is also in Chapter 2 of the freely online available book [2].\nThe survey paper that is particularly focused on Petri nets from the control systems perspective is [3] and it gives a wealth of other references.\nA few more monographs, mostly inclined towards control systems, are [4], [5], [6].",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Literature"
    ]
  },
  {
    "objectID": "petri_nets_references.html#petri-nets-and-their-derivatives-such-as-grafcet-in-international-standards",
    "href": "petri_nets_references.html#petri-nets-and-their-derivatives-such-as-grafcet-in-international-standards",
    "title": "Literature",
    "section": "Petri nets and their derivatives such as Grafcet in international standards",
    "text": "Petri nets and their derivatives such as Grafcet in international standards\nWe mention at the beginning of this chapter that Petri nets have made it to international standards. Here they are: [7], [8], and [9].\nBased on Petri nets, another framework has been derived and standardized, namely GRAFCET, see [10] and [11], upon which, in turn, the popular Sequential Function Chart (SFC) language for PLC programming [12] is based.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Literature"
    ]
  },
  {
    "objectID": "mpc_mld_software.html",
    "href": "mpc_mld_software.html",
    "title": "Software",
    "section": "",
    "text": "Essentially the same as in the previous chapter.\n\n\n\n Back to top",
    "crumbs": [
      "11. Model predictive control (MPC) for MLD systems",
      "Software"
    ]
  },
  {
    "objectID": "verification_references.html",
    "href": "verification_references.html",
    "title": "Literature",
    "section": "",
    "text": "The topic of verification is vast. While we only reserved a single week/chapter/block for it, it would easily fill a dedicated course, supported by a couple of books. Having a smaller time budget, we can still find some confirmation of usefulness even of a modest introduction in the Chapter 3 of [1]. Although we do not follow the book closely, we do cover some of their topics.\nAmong general references for hybrid system verification, we can recommend [2] for an overview. Although the book is not freely available for download, its web page contains quite some additional material such as slides and codes.",
    "crumbs": [
      "12. Formal verification",
      "Literature"
    ]
  },
  {
    "objectID": "verification_references.html#reachability-analysis-by-set-propagation-techniques",
    "href": "verification_references.html#reachability-analysis-by-set-propagation-techniques",
    "title": "Literature",
    "section": "Reachability analysis (by set propagation techniques)",
    "text": "Reachability analysis (by set propagation techniques)\nThe overview paper [3] is recommendable. In addition, the manual for the CORA toolbox for Matlab [4] (by the same author and his team) can do a good tutorial job.",
    "crumbs": [
      "12. Formal verification",
      "Literature"
    ]
  },
  {
    "objectID": "verification_references.html#barier-certificates",
    "href": "verification_references.html#barier-certificates",
    "title": "Literature",
    "section": "Barier certificates",
    "text": "Barier certificates\nWe based our introduction on [5], including the example. But a wealth of papers have been published on the topic, including the extension from analysis to control design in the form of control barrier functions, which has been introduced in [6]. A recent overview is in the book [7].",
    "crumbs": [
      "12. Formal verification",
      "Literature"
    ]
  },
  {
    "objectID": "verification_references.html#temporal-logics",
    "href": "verification_references.html#temporal-logics",
    "title": "Literature",
    "section": "Temporal logics",
    "text": "Temporal logics\nTwo popular monographs on verification (model checking) based on temporal logics such as LTL, CTL and CTL* are [8], and [9]. These do not cover hybrid systems, though. Still they are recommendable (at least their first chapters) for understanding the basics.\nSome learning material and sketches of applications of temporal logics in control systems for robotics and autonomous driving are in the lectures [10], and [11].\nA temporal logic particularly useful for specifying more complex requirements on (hybrid) control systems is Signal Temporal Logic (STL). Its treatment of this framework in textbooks is still rather sketchy. Research papers are then the only source. STL has been introduced in the readable [12]. Robustness degree has been described in [13] and the self-contained slides [14]. Some more recent papers that also contain other relevant references are [15], [16], [17], [18].",
    "crumbs": [
      "12. Formal verification",
      "Literature"
    ]
  },
  {
    "objectID": "stability_recap.html",
    "href": "stability_recap.html",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "",
    "text": "Before we start discussing stability of hybrid dynamical systems, it will not hurt to recapitulate the stability analysis for continuous (both in value and in time) dynamical systems modelled by the standard state equation\n\\dot{\\bm{x}} = \\mathbf f(\\bm x).",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#equilibrium",
    "href": "stability_recap.html#equilibrium",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Equilibrium",
    "text": "Equilibrium\nLoosely speaking, equilibrium is a state at which the system can rest indefinitely when undisturbed by external disturbances. More technically speaking, equilibrium is a point in the state space, that is, a vector \\bm x_\\mathrm{eq}\\in \\mathbb R^n, at which the vector field \\mathbf f vanishes, that is,\n\\mathbf f(\\bm x_\\mathrm{eq}) = \\mathbf 0.\nWithout loss of generality we often assume that \\bm x_\\mathrm{eq} = \\mathbf 0, because if the equilibrium is considered anywhere else than at the origin, we can alway introduce a new shifted state vector \\bm x_\\mathrm{new}(t) = \\bm x(t) - \\bm x_\\mathrm{eq}.\n\n\n\n\n\n\nAn equilibrium and not a system is what we analyze for stability\n\n\n\nAlthough every now and then we may hear the term stability attributed to a system, strictly speaking it is an equilibrium that is stable or unstable. For linear systems, there is not need to distinguish between the two, for nonlinear systems it can easily happen that some equilibrium is stable while some other is unstable.",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#lyapunov-stability",
    "href": "stability_recap.html#lyapunov-stability",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Lyapunov stability",
    "text": "Lyapunov stability\nOne of the most common types of stability is Lyapunov stability. Loosely speaking, it means that if the system starts close to the equilibrium, it stays close to it. More formally, for a given \\varepsilon&gt;0, there is a \\delta&gt;0 such that …",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#attractivity",
    "href": "stability_recap.html#attractivity",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Attractivity",
    "text": "Attractivity\nThis is another property of an equilibrium. If it is (locally) attractive, it means that if the systems starts close to the equilibrium, it will converge to it. The global version of attractivity means that the system asymptotically converges to the equilibrium from anywhere.\nPerhaps it is not immediately clear that attractivity is distinct from (Lyapunov) stability. The following example shows an attractive but Lyapunov unstable equilibrium.\n\nExample 1 (Example of an attractive but unstable equilibrium)  \n\n\nShow the code\nf(x) = [(x[1]^2*(x[2]-x[1])+x[2]^5)/((x[1]^2+x[2]^2)*(1+(x[1]^2+x[2]^2)^2)); \n        (x[2]^2*(x[2]-2x[1]))/((x[1]^2+x[2]^2)*(1+(x[1]^2+x[2]^2)^2))]\n\nusing CairoMakie\nfig = Figure(; size = (800, 800),fontsize=20)\nax = Axis(fig[1, 1], xlabel = \"x₁\", ylabel = \"x₂\")\nstreamplot!(ax,x-&gt;Point2f(f(x)), -1.5..1.5, -1.5..1.5, colormap = :magma)\nfig",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#asymptotic-stability",
    "href": "stability_recap.html#asymptotic-stability",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Asymptotic stability",
    "text": "Asymptotic stability\nCombination of Lyapunov stability and attractivity is called assymptotic stability.\nIf the attractivity is global, the assymptotic stability is called global too.",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#exponential-stability",
    "href": "stability_recap.html#exponential-stability",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Exponential stability",
    "text": "Exponential stability\nExponential convergence.",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#stability-of-time-varying-systems",
    "href": "stability_recap.html#stability-of-time-varying-systems",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Stability of time-varying systems",
    "text": "Stability of time-varying systems\nStability (Lyapunov, asymptotic, …) is called uniform, if it is independent of the inititial time.",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#stability-analysis-via-lyapunov-function",
    "href": "stability_recap.html#stability-analysis-via-lyapunov-function",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Stability analysis via Lyapunov function",
    "text": "Stability analysis via Lyapunov function\nNow that we recapitulated the key stability concepts, it is time to recapitulate the methods of checking if this or that type of stability is achieved. The classical method is based on the searching for a Lyapunov function.\nLyapunov function is a scalar function V(\\cdot)\\in\\mathcal{C}_1 defined on open \\mathcal{D}\\subset \\mathbb{R}^n containing the origin (the equilibrium) that satisfies the following conditions V(0) = 0, \\; V(x) &gt; 0\\, \\text{for all}\\, x\\in \\mathcal{D}\\setminus \\{0\\}, \n \\underbrace{\\left(\\nabla V(x)\\right)^\\top f(x)}_{\\frac{\\mathrm d}{\\mathrm d t}V(x(t))} \\leq 0.\nIn words, Lyapunov function for a given system and a given equilibrium is a function that is positive everywhere except at the origin, where it is zero (we call such function positive definite), and its derivative along the trajectories of the system is nonpositive (aka negative semidefinite), which is a way to guarantee that the function does not increase along the trajectories. If such function exists, the equilibrium is Lyapunov stable.\nIf the latter condition is made strict, that is, if \\left(\\nabla V(x)\\right)^\\top f(x) &lt; 0, which is a way to guarantee that the function decreases along the trajectories, the equilibrium is asymptotically stable.\nThe interpretation is quite intuitive: …",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#lasalles-invariance-principle",
    "href": "stability_recap.html#lasalles-invariance-principle",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "LaSalle’s invariance principle",
    "text": "LaSalle’s invariance principle\nA delicate question is if the derivative of the Lyapunov function ocassionally vanishes, it it automatically means that the equilibrium is not assymptotically stable. The aswer is: not necessarily. LaSalle’s invariance principle states that even if the derivative of the Lyapunov function occasionally vanishes, the equilibrium can still be asymptotically stable, provided some condition is satisfied. We will not elaborate on it here. Look it up in your favourite nonlinear (control) system textbook.",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#formulated-using-comparison-functions",
    "href": "stability_recap.html#formulated-using-comparison-functions",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Formulated using comparison functions",
    "text": "Formulated using comparison functions\nThe above properties of the Lyapunov function be also be formulated using comparison functions. For Lyapunov stability, the following holds \\kappa_1(\\|x\\|) \\leq V(x) {\\color{gray}\\leq \\kappa_2(\\|x\\|)}, where\n\n\\kappa_1(\\cdot), \\kappa_2(\\cdot) are class \\mathcal{K} comparison functions, that is, they are continuous, zero at zero and (strictly) increasing.\nIf \\kappa_1 increases to infinity (\\kappa_1(\\cdot)\\in\\mathcal{K}_\\infty), the stability is global.\n\nFor asymptotic stability\n\\left(\\nabla V(x)\\right)^\\top f(x) \\leq -\\rho(\\|x\\|), where \\rho(\\cdot) is a positive definite continuous function, zero at the origin.\n\nThe upper bound \\kappa_2(\\cdot) does not have to be there, it is automatically satisfied for time-invariant systems. It does have to be imposed for time-varying systems though.",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#exponential-stability-1",
    "href": "stability_recap.html#exponential-stability-1",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Exponential stability",
    "text": "Exponential stability\nk_1 \\|x\\|^p \\leq V(x) \\leq k_2 \\|x\\|^p,\n\\left(\\nabla V(x)\\right)^\\top f(x) \\leq -k_3 \\|x\\|^p.",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#exponential-stability-with-quadratic-lyapunov-function",
    "href": "stability_recap.html#exponential-stability-with-quadratic-lyapunov-function",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Exponential stability with quadratic Lyapunov function",
    "text": "Exponential stability with quadratic Lyapunov function\n\nV(x) = x^\\top P x\n\n\\lambda_{\\min} (P) \\|x\\|^2 \\leq V(x) \\leq \\lambda_{\\max} (P) \\|x\\|^2",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "stability_recap.html#converse-theorems",
    "href": "stability_recap.html#converse-theorems",
    "title": "Recap of stability analysis for continuous dynamical systems",
    "section": "Converse theorems",
    "text": "Converse theorems\n\nfor (G)UAS,\nfor Lyapunov stability only time-varying Lyapunov function guaranteed.",
    "crumbs": [
      "8. Stability",
      "Recap of stability analysis for continuous dynamical systems"
    ]
  },
  {
    "objectID": "petri_nets_timed.html",
    "href": "petri_nets_timed.html",
    "title": "Timed Petri nets",
    "section": "",
    "text": "Recall that when introducing enabled transitions, we emphasized that these can but do not have to fire immediately after having been enabled \\boxed{\\mathrm{ENABLING} \\neq \\text{FIRING}.}",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Timed Petri nets"
    ]
  },
  {
    "objectID": "petri_nets_timed.html#delays-associated-with-transitions",
    "href": "petri_nets_timed.html#delays-associated-with-transitions",
    "title": "Timed Petri nets",
    "section": "Delays associated with transitions",
    "text": "Delays associated with transitions\nWell then, the enabled transitions do not have to fire immediately, but they can possibly fire with some delay after enabling. This is for the first time that we are introducing the concept of time into the Petri nets, isn’t it?\nFor the jth transition, the delay of the kth firing is v_{j,k}, and we collect the sequence of delayes into v_j = \\{v_{j,1}, v_{j,2}, \\ldots \\}.\nBut not all transitions have to be timed. Denote the timed transitions \\mathcal{T}_\\mathrm{D}\\subseteq \\mathcal{T}. We define the clock structure for a PN as \\mathcal{V} = \\{v_j\\mid t_j\\in\\mathcal{T}_\\mathrm{D}\\}.\nThe definition of a timed Petri net (TPN) is then obtained by augmenting the definition of a Petri net with the clock structure\n\\boxed{TPN = \\{\\mathcal{P}, \\mathcal{T}, \\mathcal{A}, w, x, \\mathcal{V}\\}}.\n\nExample 1 (Timed Petri net) Model of processing multiple tasks: task 1 and task 2 are processed sequentially, and task 3 is processed in parallel with them; task 4 can only be processed after both tasks 2 and 3 have been finished. Finishing individual tasks corresponds to the individual transitions. The transition 4 is untimed, it only expresses the logical requirement.\n\n\n\nExample of a timed Petri net\n\n\n\n\n\n\n\n\n\nRectangles instead of bars\n\n\n\nSometimes instead of a bar, the untimed transitions are modelled using similarly thin rectangles as the timed transitions, but filled.\n\n\n\nPlaces can also be delayed\nWith delays associated with just one type of a node in a Petri net, the situation is rather nonsymmetric. In some literature, delays can also associated with places. And yet in some other literature delays are only associated with places. Such delays associated with places are called holding time for a place It is the minimum duration the token must rest in the place. But the token can stay longer if the output transition is waiting for other places.\n\n\n\n\n\n\nDelays associated with transitions and places\n\n\n\nThere is a major difference in delays associated with places compared to the delays associated with transitions. While the former tells the minimum duration the token has to dwell in the place, the latter tell the exact delay with which the transition fires after having been enabled.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Timed Petri nets"
    ]
  },
  {
    "objectID": "petri_nets_timed.html#timed-petri-net-dynamics",
    "href": "petri_nets_timed.html#timed-petri-net-dynamics",
    "title": "Timed Petri nets",
    "section": "Timed Petri net dynamics",
    "text": "Timed Petri net dynamics\nWith the introduction of time into the Petri nets, we can now study the dynamics of the system. For general Petri nets, alhough perfectly doable, it may quicly become too complex, and therefore here we only consider event graphs.\nSome notation:\n\n\\{\\tau_{j,1}, \\tau_{j,2}, \\ldots\\} are the firing times of the jth transition,\n\\{\\pi_{i,1},\\pi_{i,2},\\ldots\\} are the times when the ith place receives a token,\nx_i = x(p_i) is the number of tokens at the ith place,\nx_{i,k} = \\left.x(p_i)\\right|_k, is the number of tokens at the ith place after the kth firing.\n\nNow, assume first that x_{i,0} = 0. We can then relate the time of the arrival of the token to the place with the firing of the transition from which the token arrives \\pi_{i,k} = \\tau_{j,k},\\quad p_i\\in \\mathcal{O}(t_j).\nBut generally x_{i,0} \\neq 0 and the above relation needs to be modified to \\pi_{i,k+x_{i,0}} = \\tau_{j,k},\\quad p_i\\in \\mathcal{O}(t_j), or, equivalently \\boxed{\\pi_{i,k} = \\tau_{j,k-x_{i,0}},\\quad p_i\\in \\mathcal{O}(t_j).} \\tag{1}\nThis can be read in the following way. If there are initially, say, 3 tokens in the place, the time of the arrival of the 4th token is the time of the first firing of the transition from which the 4th token arrives.\nGood. Keep this result in mind. Now we go for another.\nFor an untimed transition with a single input place, the firing time is the same as the time of the arrival of the token to the place \n\\tau_{j,k} = \\pi_{i,k}.\n\nModifying this result for a timed transition with a single input place we get \n\\tau_{j,k} = \\pi_{i,k} + v_{j,k}.\n\nIn words, the firing time is given by the time of the arrival of the token to the place, which enables the transition, and the delay associated with the transition.\nFinally, we extend this result to the case of a timed transition with multiple input places \\boxed{\n\\tau_{j,k} = \\max_{p_i\\in\\mathcal{I}(t_j)}\\{\\pi_{i,k}\\} + v_{j,k}.}\n\\tag{2}\nThis is the other promised important result. Keep both boxed formulas Eq. 1 and Eq. 2 handy, they will be needed in what is coming.\n\nExample 2 (Timed Petri net dynamics) Consider the Petri net with three places and two transitions, one of which is timed, as in Fig. 1.\n\n\n\n\n\n\nFigure 1: Example of a Petri net for which the dynamics is analyzed\n\n\n\nWe first use Eq. 2 to write down the firing times of the two transitions \n\\begin{aligned}\n\\tau_{1,k} &= \\max\\{\\pi_{1,k},\\pi_{3,k}\\}\\\\\n\\tau_{2,k} &= \\pi_{2,k}+v_{2,k}.\n\\end{aligned}\n\nNow we apply Eq. 1 to write down the times of the arrival of the tokens to the places \n\\begin{aligned}\n\\pi_{1,k} &= \\tau_{1,k-1}, \\qquad k=2,\\ldots, \\qquad \\pi_{1,0} = 0\\\\\n\\pi_{2,k} &= \\tau_{1,k-1}, \\qquad k=2,\\ldots, \\qquad \\pi_{2,0} = 0\\\\\n\\pi_{3,k} &= \\tau_{2,k}, \\qquad k=1,\\ldots\n\\end{aligned}\n\nSubstituting from the latter into the former we get \n\\begin{aligned}\n\\tau_{1,k} &= \\max\\{\\tau_{1,k-1},\\tau_{1,k-1}+v_{2,k}\\}\\\\\n&= \\tau_{1,k-1}+v_{2,k}, \\quad \\tau_{1,k} = 0\\\\\n\\tau_{2,k} &= \\tau_{1,k-1}+v_{2,k}.\n\\end{aligned}\n\nThis is the ultimate model for the dynamics of the Petri net. Should we need it, we can also get similar expressions for the times of the arrival of the tokens to the places.\n\n\n\n\n\n\n\nUpdate equations for times and not states\n\n\n\nWhile with state equations we compute a sequences of values of the state vector (\\bm x_0, \\bm x_1, \\bm x_2, \\ldots), in other words, we compute the evolution of the state in time, here we compute the sequences of times when transitions fire (or token arrive to places). This update scheme for times resembles the state equations, but the interpretation is different.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Timed Petri nets"
    ]
  },
  {
    "objectID": "petri_nets_timed.html#queueing-system-using-tpn",
    "href": "petri_nets_timed.html#queueing-system-using-tpn",
    "title": "Timed Petri nets",
    "section": "Queueing system using TPN",
    "text": "Queueing system using TPN\nWe can also model a queueing system using a TPN. The Petri net is shown in Fig. 2.\n\n\n\n\n\n\nFigure 2: Timed Petri net modelling a queueing system\n\n\n\nOf the three transitions \\mathcal{T} = \\{a,s,c\\}, which we have already identified previously, we assume that only are times, namely \\mathcal{T}_\\mathrm{D} = \\{a,c\\}. The associated firing delays are \\bm v = \\begin{bmatrix}v_a \\\\ v_c\\end{bmatrix}.\nFor convenience we relabel the firing times of the transitions. Instead of t_{a,k} we will use a_k, and similarly s_k, and c_k. Application of Eq. 2 and Eq. 1 gives \n\\begin{aligned}\na_k &= a_{k-1} + v_{a,k},\\quad k=1,2,\\ldots,\\quad a_0 = 0\\\\\ns_k &= \\max\\{\\pi_{Q,k},\\pi_{I,k}\\}\\\\\nc_k &= \\pi_{B,k} + v_{c,k}\\\\\n\\pi_{Q,k} &= a_{k},\\quad k=1,2,\\ldots\\\\\n\\pi_{I,k} &= c_{k-1},\\quad k= 2, \\ldots, \\quad \\pi_{I,0}=1\\\\\n\\pi_{B,k} &= s_{k},\\quad k=1,2,\\ldots\\\\\n\\end{aligned}\n\nCombining gives the desired update equations \n\\begin{aligned}\na_k &= a_{k-1} + v_{a,k},\\quad k=1,2,\\ldots,\\quad a_0 = 0\\\\\ns_k &= \\max\\{a_{k},c_{k-1}\\}\\\\\nc_k &= s_{k} + v_{c,k}\\\\\n&= \\max\\{a_{k},c_{k-1}\\} + v_{c,k},\\quad k=1,\\ldots, \\quad c_0=0\n\\end{aligned}\n\nThe time of completing the kth task is given by the time at which the previous task was completed and the time needed to complete the kth task itself, unless there is a gap in the queue after finishing the previous task, in which case the server must wait for the next task to arrive.\n\nExample 3 (Timed Petri net for synchronization of train lines) We consider three closed rail tracks and two stations as in Fig. 3.\n\n\n\n\n\n\nFigure 3: Example with three train lines\n\n\n\nDeparture of a train at a station must be synchronized with arrival of the other train so that passengers can change train. The timed Petri net for this system is shown in Fig. 4.\n\n\n\n\n\n\nFigure 4: Timed Petri net for the example of synchronization of three train lines\n\n\n\nIf time is associated with the places, the Petri net simplifies significantly to Fig. 5.\n\n\n\n\n\n\nFigure 5: Timed Petri net for the example of synchronization of three train lines\n\n\n\n\n\nExample 4 (Manufacturing) tbd",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Timed Petri nets"
    ]
  },
  {
    "objectID": "petri_nets_timed.html#extensions",
    "href": "petri_nets_timed.html#extensions",
    "title": "Timed Petri nets",
    "section": "Extensions",
    "text": "Extensions\n\nStochastic Petri nets (SPN)\nNumerous extensions are possible, some of which we have already mentioned when discussing untimed Petri nets. But upon introducing time, stochastic Petr nets can be concived, in which delays are random variables.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Timed Petri nets"
    ]
  },
  {
    "objectID": "hybrid_automata_software.html",
    "href": "hybrid_automata_software.html",
    "title": "Software",
    "section": "",
    "text": "pure Simulink: Relational operators, Logical operators, Extra options for the Integrator block (external reset, external initial conditions, possibly state port).\npure Matlab: Event Location with ODE solvers.\nStateflow: Continuous-time modeling in Stateflow",
    "crumbs": [
      "4. Hybrid systems: Hybrid automata",
      "Software"
    ]
  },
  {
    "objectID": "hybrid_automata_software.html#matlab",
    "href": "hybrid_automata_software.html#matlab",
    "title": "Software",
    "section": "",
    "text": "pure Simulink: Relational operators, Logical operators, Extra options for the Integrator block (external reset, external initial conditions, possibly state port).\npure Matlab: Event Location with ODE solvers.\nStateflow: Continuous-time modeling in Stateflow",
    "crumbs": [
      "4. Hybrid systems: Hybrid automata",
      "Software"
    ]
  },
  {
    "objectID": "hybrid_automata_software.html#julia",
    "href": "hybrid_automata_software.html#julia",
    "title": "Software",
    "section": "Julia",
    "text": "Julia\n\nHybridSystems.jl – the package essentially just defines some basic data types, currently it is mainly used by some other packages, such as ReachabilityAnalysis.jl.\nReachabilityAnalysis.jl",
    "crumbs": [
      "4. Hybrid systems: Hybrid automata",
      "Software"
    ]
  },
  {
    "objectID": "hybrid_automata_software.html#python",
    "href": "hybrid_automata_software.html#python",
    "title": "Software",
    "section": "Python",
    "text": "Python\n\n…",
    "crumbs": [
      "4. Hybrid systems: Hybrid automata",
      "Software"
    ]
  },
  {
    "objectID": "mpc_mld_explicit.html",
    "href": "mpc_mld_explicit.html",
    "title": "Explicit MPC for hybrid systems",
    "section": "",
    "text": "Model predictive control (MPC) is not computationally cheap (compared to, say, PID or LQG control) as it requires solving optimization problem – typically a quadratic program (QP) - online. The optimization solver needs to be a part of the controller.\nThere is an alternative, though, at least in same cases. It is called explicit MPC. The computationally heavy optimization is only perfomed only during the design process and the MPC controller is then implemented just as an affine state feedback\n\\bm u_k(\\bm x(k)) = \\mathbf F_k^i \\bm x(k) + \\mathbf g_k^i,\\; \\text{if}\\; \\bm x(k) \\in \\mathcal R_k^i,\nwith the coefficients picked from some kind of a lookup table in real time Although retreiving the coefficients of the feedback controller is not computationally trivial, still it is cheaper than full optimization.",
    "crumbs": [
      "11. Model predictive control (MPC) for MLD systems",
      "Explicit MPC for hybrid systems"
    ]
  },
  {
    "objectID": "mpc_mld_explicit.html#multiparametric-programming",
    "href": "mpc_mld_explicit.html#multiparametric-programming",
    "title": "Explicit MPC for hybrid systems",
    "section": "Multiparametric programming",
    "text": "Multiparametric programming\nThe key technique for explicit MPC is multi-parametric programming. In order to explain it, consider the following problem\n\nJ^\\ast(x) = \\inf_z J(z;x).\n\nThe z variable is an optimization variable, while x is a parameter. For a given parameter x, the cost function J is minimized. We study how the optimal cost J^\\ast depends on the parameter, hence the name parametric programming. If x is a vector, the name of the problem changes to multiparametric programming.\n\nExample: scalar variable, single parameter\nConsider the following cost function J(z;x) in z parameterized by x. The optimization variable z is constrained and this constraint is also parameterized by x. \n\\begin{aligned}\nJ(z;x) &= \\frac{1}{2} z^2 + 2zx + 2x^2 \\\\\n\\text{subject to} &\\quad  z \\leq 1 + x.\n\\end{aligned}\n\nIn this simple case we can aim at analytical solution. We proceed in the standard way – we introduce a Lagrange multiplicator \\lambda and form the augmented cost function \nL(z,\\lambda; x) = \\frac{1}{2} z^2 + 2zx + 2x^2 + \\lambda (z-1-x).\n\nThe necessary conditions of optimality for the inequality-constrained problem come in the form of KKT conditions \n\\begin{aligned}\nz + 2x + \\lambda &= 0,\\\\\nz - 1 - x &\\leq  0,\\\\\n\\lambda & \\geq 0,\\\\\n\\lambda (z - 1 - x) &= 0.\n\\end{aligned}\n\nThe last condition – the complementarity condition – gives rise to two scenarios: one corresponding to \\lambda = 0, and the other corresponding to z - 1 - x = 0. We consider them separately below.\nAfter substituting \\lambda = 0 into the KKT conditions, we get \n\\begin{aligned}\nz + 2x &= 0,\\\\\nz - 1 - x & \\leq  0.\n\\end{aligned}\n\nFrom the first equation we get how z depends on x, and from the second we obtain a bound on x. Finally, we can also substitute the expression for z into the cost function J to get the optimal cost J^\\ast as a function of x. All these are summarized here \n\\begin{aligned}\nz &= -2x,\\\\\nx & \\geq -\\frac{1}{3},\\\\\nJ^\\ast(x) &= 0.\n\\end{aligned}\n\nNow, the other scenario. Upon substitutin z - 1 - x = 0 into the KKT conditions we get\n\n\\begin{aligned}\nz + 2x + \\lambda &= 0,\\\\\nz - 1 - x &=  0,\\\\\n\\lambda & \\geq 0.\n\\end{aligned}\n\nFrom the second equation we get the expression for z in terms of x, substituting into the first equation and invoking the condition on nonnegativity of \\lambda we get the bound on x (not suprisingly it complements the one obtained in the previous scenario). Finally, substituting for z in the cost function J we get a formula for the cost J^\\ast as a function of x.\n\n\\begin{aligned}\nz &= 1 + x,\\\\\n\\lambda &= -z - 2x \\geq 0 \\quad \\implies \\quad x \\leq -\\frac{1}{3},\\\\\nJ^\\ast(x) &= \\frac{9}{2}x^2 + 3x + \\frac{1}{2}.\n\\end{aligned}\n\nThe two scenarios can now be combined into a single piecewise affine function z(x) \nz(x) = \\begin{cases}\n1+x & \\text{if } x \\leq -\\frac{1}{3},\\\\\n-2x & \\text{if } x &gt; -\\frac{1}{3}.\n\\end{cases}\n\n\n\nShow the code\nx = range(-1, 1, length=100)\nz(x) = x &lt;= -1/3 ? 1 + x : -2x\nJstar(x) = x &lt;= -1/3 ? 9/2*x^2 + 3x + 1/2 : 0\n\nusing Plots\nplot(x, z.(x), label=\"z(x)\")\nvline!([-1/3],line=:dash)\nxlabel!(\"x\")\nylabel!(\"z(x)\")\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nand a piecewise quadratic cost function J^\\ast(x) \nJ^\\ast(x) = \\begin{cases}\n\\frac{9}{2}x^2 + 3x + \\frac{1}{2} & \\text{if } x \\leq -\\frac{1}{3},\\\\\n0 & \\text{if } x &gt; -\\frac{1}{3}.\n\\end{cases}\n\n\n\nShow the code\nplot(x, Jstar.(x), label=\"J*(x)\")\nvline!([-1/3],line=:dash)\nxlabel!(\"x\")\nylabel!(\"J*(x)\")",
    "crumbs": [
      "11. Model predictive control (MPC) for MLD systems",
      "Explicit MPC for hybrid systems"
    ]
  },
  {
    "objectID": "classes_software.html",
    "href": "classes_software.html",
    "title": "Software",
    "section": "",
    "text": "Reset systems, switched systems, and piecewise affine (PWA) systems can all be viewed as special classes of hybrid systems, and as such can be modelled and simulated using software for hybrid systems (or even general purpose modelling and simulation software).\nHowever, there are also some dedicated software tools/packages/libraries for PWA systems:\n\nPLECS\n\nPower electronics\nCommercial\n\nMultiparametric Toolbox (MPT) for Matlab\n\nGeneral\nSpecial data type/class (and some related functions) for PWA systems is available in the section on Modeling of dynamical systems in MPT3.\nFree and open source.\n\n\nAlthough some more free and open-source software packages for PWA systems can be found on the internet, none of them (at as far as we know) is actively developed or at least maintained anymore:\n\nPWATOOLS toolbox for Matlab, which accompanies the recently published book [1]. Unfortunately, this ten-year old toolbox is no longer working with the recent releases of Matlab and the author is no longer maintaining it.\nPWLTool toolbox for Matlab: some traces of this toolbox can be found on the internet, but this one seems even older, obviously back then accompanying the book [2].\n\nOverall, besides the MPT toolbox that is still being actively developed (by our colleagues at STU Bratislava), not much is currently available within the open-source software domain… :-(\n\n\n\n\n Back to topReferences\n\n[1] L. Rodrigues, B. Samadi, and M. Moarref, Piecewise Affine Control: Continuous-Time, Sampled-Data, and Networked Systems. in Advances in Design and Control. Philadelphia: Society for Industrial and Applied Mathematics, 2019. Available: https://doi.org/10.1137/1.9781611975901\n\n\n[2] M. K.-J. Johansson, Piecewise Linear Control Systems: A Computational Approach. in Lecture Notes in Control and Information Sciences. Berlin, Heidelberg: Springer, 2003. Available: https://doi.org/10.1007/3-540-36801-9",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Software"
    ]
  },
  {
    "objectID": "classes_references.html",
    "href": "classes_references.html",
    "title": "Literature",
    "section": "",
    "text": "There is no single recommended literature for this lecture. Instead, a bunch of papers and monographs is listed here to get you started should need to delve deeper.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Literature"
    ]
  },
  {
    "objectID": "classes_references.html#reset-control-systems",
    "href": "classes_references.html#reset-control-systems",
    "title": "Literature",
    "section": "Reset control systems",
    "text": "Reset control systems\nThe origing of the reset control can be traced to the paper [1]. While it may be of historical curiosity to have a look at that paper containing also some schematics with opamps, it is perhaps easier to learn the basics of reset control in some more recent texts such as the monograph [2]. Alternatively, papers such as [3], [4], [5], or [6] can provide another concise introduction to the topic.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Literature"
    ]
  },
  {
    "objectID": "classes_references.html#switched-systems",
    "href": "classes_references.html#switched-systems",
    "title": "Literature",
    "section": "Switched systems",
    "text": "Switched systems\nReadable introduction to switched systems is in the slim book [7]. The book is not freely available online, but a useful excerpt can be found in the lecture notes [8].\nSwitched systems can also be viewed as systems described by differential equations with discontinuous right-hand side. The theory of such systems is described in the classical book [9]. The main concepts and results can also be found in the tutorial [10], perhaps even in a more accessible form. Additionally, accessible discussion in the online available beautiful (I really mean it) textbook [11], chapters 3 and 11. What is particularly nice about the latter book is that every concepts, even the most theoretical one, is illustrated by a simple Matlab code invoking the epic Chebfun toolbox.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Literature"
    ]
  },
  {
    "objectID": "classes_references.html#piecewise-affine-pwa-systems",
    "href": "classes_references.html#piecewise-affine-pwa-systems",
    "title": "Literature",
    "section": "Piecewise affine (PWA) systems",
    "text": "Piecewise affine (PWA) systems\nIn our course we based our treatment of PWA systems on the monograph [12]. It is not freely available online, but it is based on the author’s PhD thesis [13], which is available online. While these resources are a bit outdated (in particular, when it comes to stability analysis, back then they were not aware of the possibility to extend the S-procedure to higher-degree polynomials), they still constitute a good starting point. Published at about the same time, the paper [14] reads well (as usual in the case of the second author). A bit more up-to-date book dedicated purely to PWA control is [15], but again, no free online version. The book refers to the Matlab toolbox documented in [16]. While the toolbox is rather dated and will hardly run on the current versions of Matlab (perhaps an opportunity for nice student project), the tutorial paper gives some insight into how the whole concept of a PWA approximation can be used in control design.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Literature"
    ]
  },
  {
    "objectID": "classes_references.html#piecewise-affine-linear-approximation",
    "href": "classes_references.html#piecewise-affine-linear-approximation",
    "title": "Literature",
    "section": "Piecewise affine (linear) approximation",
    "text": "Piecewise affine (linear) approximation\nThere is quite a lot of relevant know-how available even outside the domain of (control) systems, in particular, search for piecewise affine (-linear) approximation or fitting (using optimization): [17] (although it is only restricted to convex functions), [18], [19], …",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Literature"
    ]
  },
  {
    "objectID": "stability_concepts.html",
    "href": "stability_concepts.html",
    "title": "Stability of hybrid systems",
    "section": "",
    "text": "As we have recalled in the recap section on stability of continuous dynamical systems, stability is a property of an equilibrium. But what is an equilibrium of a hybrid systems? It turns out that the definition is not as straightforward as in the continuous case. It also depends on the chosen framework for modelling of hybrid systems.",
    "crumbs": [
      "8. Stability",
      "Stability of hybrid systems"
    ]
  },
  {
    "objectID": "stability_concepts.html#equilibrium-of-a-hybrid-system-modelled-by-a-hybrid-automaton",
    "href": "stability_concepts.html#equilibrium-of-a-hybrid-system-modelled-by-a-hybrid-automaton",
    "title": "Stability of hybrid systems",
    "section": "Equilibrium of a hybrid system modelled by a hybrid automaton",
    "text": "Equilibrium of a hybrid system modelled by a hybrid automaton\nFirst, an equilibrium of a hybrid automaton is a point \\bm x_\\mathrm{eq} in the continuous state space \\mathcal X\\subset \\mathbb R^n.\n\n\n\n\n\n\nNote\n\n\n\nAlthough we often assume the equilibrium at the origin, that is, \\bm x_\\mathrm{eq} = \\mathbf 0, the assumption does not have to be invoked in order to provide the definition.\n\n\nWe now consider a hybrid automaton for which the dynamics of each individual mode q is given by \\dot{\\bm x} = \\mathbf f_q(\\bm x). The invariants (or domains) of each mode are \\mathcal X_q, \\, q=1, \\ldots, m.\nThe definition of the equilibrium \\bm x_\\mathrm{eq} that is ofter found in the literature imposes these two conditions:\n\n\\mathbf 0 = \\mathbf f_q(\\bm x_\\mathrm{eq}) for all q\\in \\mathcal Q,\nthe reset map r(q,q',\\bm x_\\mathrm{eq}) = \\bm x_\\mathrm{eq}.\n\nThe first condition states that the point in the continuous state space should qualify as an equilibrium for each mode. This might appear unnecessarily restrictive (what if the particular \\bm x_\\mathrm{eq} is not an element of \\mathcal X_q for all q?) as we discuss later. But note that this definition appears in several resources. For example, in the definition 4.9 in the section 4.2 in [1] or the definition 8.2 in the section 8.2 in (no longer available online) [2].\nThe second condition states that the system can be regarded as resting at the equlibrium even if it jumps from one discrete state (mode) to another (while staying in the equilibrium continuous state).",
    "crumbs": [
      "8. Stability",
      "Stability of hybrid systems"
    ]
  },
  {
    "objectID": "stability_concepts.html#equilibrium-of-a-hybrid-system-modelled-by-hybrid-equations",
    "href": "stability_concepts.html#equilibrium-of-a-hybrid-system-modelled-by-hybrid-equations",
    "title": "Stability of hybrid systems",
    "section": "Equilibrium of a hybrid system modelled by hybrid equations",
    "text": "Equilibrium of a hybrid system modelled by hybrid equations\nThe state vector within this modelling framework is composed by both the discrete and continuous state variables. The two conditions for the equilibrium of a hybrid automata can be translated into the hybrid equation framework, which means that the equilibrium is not just a single point but rather a set of points.\n\nExample 1 (Equilibrium of a hybrid system modelled by hybrid equations) Consider a hybrid system modelled by hybrid equations, for which the state space is given by \\mathcal X = \\{0,1\\} \\times \\mathbb R. The dynamics of the system is given by\n\nThis makes the analysis significantly more challenging. Therefore, in our lecture we will only consider stability of hybrid automata.",
    "crumbs": [
      "8. Stability",
      "Stability of hybrid systems"
    ]
  },
  {
    "objectID": "stability_concepts.html#stability-of-a-hybrid-automaton",
    "href": "stability_concepts.html#stability-of-a-hybrid-automaton",
    "title": "Stability of hybrid systems",
    "section": "Stability of a hybrid automaton",
    "text": "Stability of a hybrid automaton\nThe equilibrium \\bm x_\\mathrm{eq}=\\mathbf 0 is stable if for a given \\varepsilon &gt; 0 there exists \\delta &gt; 0 such that for all hybrid systems executions/trajectories starting at (q_0,\\bm x_0), \n\\|\\bm x_0\\| &lt; \\delta \\Rightarrow \\|\\bm x(\\tau)\\| &lt; \\varepsilon, \\; \\forall \\tau \\in \\mathcal{T},\n where \\tau is a hybrid time and \\mathcal{T} is the hybrid time domain.",
    "crumbs": [
      "8. Stability",
      "Stability of hybrid systems"
    ]
  },
  {
    "objectID": "stability_concepts.html#asymptotic-stability",
    "href": "stability_concepts.html#asymptotic-stability",
    "title": "Stability of hybrid systems",
    "section": "Asymptotic stability",
    "text": "Asymptotic stability\nThe equilibrium is stable and furthermore we can choose some \\delta such that \n\\|\\bm x_0\\| &lt; \\delta \\quad \\Rightarrow \\quad \\lim_{\\tau\\rightarrow \\tau_\\infty} \\|\\bm x(\\tau)\\| = 0,\n where \\tau_\\infty&lt;\\infty if the execution is Zeno and \\tau_\\infty=\\infty otherwise.",
    "crumbs": [
      "8. Stability",
      "Stability of hybrid systems"
    ]
  },
  {
    "objectID": "stability_concepts.html#is-stability-of-the-individual-dynamics-enough",
    "href": "stability_concepts.html#is-stability-of-the-individual-dynamics-enough",
    "title": "Stability of hybrid systems",
    "section": "Is stability of the individual dynamics enough?",
    "text": "Is stability of the individual dynamics enough?\n\n\n\nHybrid automaton that is unstable due to switching even though the two modes are stable\n\n\n\nA_1 =\n\\begin{bmatrix}\n-1 & -100\\\\ 10 & -1\n\\end{bmatrix}, \\quad\nA_2 =\n\\begin{bmatrix}\n-1 & 10\\\\ -100 & -1\n\\end{bmatrix}\n\n\nBoth are stable.\nSwitching can be destabilizing.",
    "crumbs": [
      "8. Stability",
      "Stability of hybrid systems"
    ]
  },
  {
    "objectID": "stability_concepts.html#can-the-individual-dynamics-be-unstable",
    "href": "stability_concepts.html#can-the-individual-dynamics-be-unstable",
    "title": "Stability of hybrid systems",
    "section": "Can the individual dynamics be unstable?",
    "text": "Can the individual dynamics be unstable?\n\n\n\nHybrid automaton that is stable thanks to switching even though the two modes are unstable\n\n\n\nA_1 =\n\\begin{bmatrix}\n1 & -100\\\\ 10 & 1\n\\end{bmatrix}, \\quad\nA_2 =\n\\begin{bmatrix}\n1 & 10\\\\ -100 & 1\n\\end{bmatrix}\n\n\nBoth are unstable.\nSwitching can be stabilizing.",
    "crumbs": [
      "8. Stability",
      "Stability of hybrid systems"
    ]
  },
  {
    "objectID": "max_plus_systems.html",
    "href": "max_plus_systems.html",
    "title": "Max-plus linear (MPL) systems",
    "section": "",
    "text": "We start with an example of a discrete-event systems modelled using (max,+) algebra.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus linear (MPL) systems"
    ]
  },
  {
    "objectID": "max_plus_systems.html#model-of-an-event-graph-as-a-max-plus-linear-mpl-state-space-system",
    "href": "max_plus_systems.html#model-of-an-event-graph-as-a-max-plus-linear-mpl-state-space-system",
    "title": "Max-plus linear (MPL) systems",
    "section": "Model of an event graph as a Max-plus linear (MPL) state-space system",
    "text": "Model of an event graph as a Max-plus linear (MPL) state-space system\nGeneralizing what we have seen in the previous example, we can write the MPL state-space system (actually a model) as \\boxed{\n  \\begin{aligned}\n  x(k) &= A\\otimes x(k-1) \\oplus B\\otimes u(k),\\\\\n  y(k) &= C\\otimes x(k),\n  \\end{aligned}}\n\\tag{1}\nwhere A, B, and C are matrices of appropriate dimensions. or, equivalently (after relabelling) \n  \\begin{aligned}\n  x(k+1) &= A\\otimes x(k) \\oplus B\\otimes u(k),\\\\\n  y(k) &= C\\otimes x(k),\n  \\end{aligned}\n\nwhich mimics the conventional state-space system \n  \\begin{aligned}\n  x(k+1) &= A x(k) + Bu(k),\\\\\n  y(k) &= Cx(k).\n  \\end{aligned}\n\nWe already know this from the example, but we need to emphasize it here again: the role of the variables u(k), x(k), y(k) is that they are event times. Namely the times of\n\narrivals of inputs,\nbeginning of processing\nfinishing of processing,\n\nrespectively.\nThe independent variable k is now a counter of the events.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus linear (MPL) systems"
    ]
  },
  {
    "objectID": "max_plus_systems.html#state-response-of-an-mpl-system",
    "href": "max_plus_systems.html#state-response-of-an-mpl-system",
    "title": "Max-plus linear (MPL) systems",
    "section": "State response of an MPL system",
    "text": "State response of an MPL system\nIn order to simulate an MPL system, we can now find use of the definitions of the basic operations in (max,+) algebra that we studied previously. Note that \n\\begin{aligned}\nx_1 &= A\\otimes x_0 \\oplus B\\otimes u_1\\\\\nx_2 &= A\\otimes x_1 \\oplus B\\otimes u_2\\\\\n    &= A\\otimes (A\\otimes x_0 \\oplus B\\otimes u_1) \\oplus B\\otimes u_2\\\\\n    &= A^{\\otimes^2}\\otimes x_0 \\oplus A\\otimes B\\otimes u_1 \\oplus B\\otimes u_2\\\\\n    &\\vdots    \n\\end{aligned}\n which can be generalized to \\boxed{\nx_k = A^{\\otimes^k}\\otimes x_0 \\oplus \\bigoplus_{i=1}^k A^{\\otimes^{k-i}} \\otimes B\\otimes u_i.}\n\\tag{2}\n\n\n\n\n\n\nResponse of an LTI state-space system\n\n\n\nThe response of a linear time-invariant (LTI) system described by a (vector) state equation x(k+1) = Ax(k) + Bu(k) is \nx_{k} = A^k x_0 + \\sum_{i=0}^{k-1} A^{k-1-i}Bu_i.\n\n\n\n\n\n\n\n\n\nLower and upper bounds for the summation shifted by 1\n\n\n\nNote how the lower and upper bounds for the summation are shifted by 1 compared to the traditional convolution.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus linear (MPL) systems"
    ]
  },
  {
    "objectID": "max_plus_systems.html#max-linearity",
    "href": "max_plus_systems.html#max-linearity",
    "title": "Max-plus linear (MPL) systems",
    "section": "(max,+) linearity",
    "text": "(max,+) linearity\nWe should emphasize that the linearity exhibited by the state equation Eq. 1 and the convolution Eq. 2 must only be understood in the (max,+) sense.\nIndeed, if we consider two input sequences u_1= \\{u_{1,1},u_{1,2},\\ldots\\} and u_2= \\{u_{2,1},u_{2,2},\\ldots\\}, a (max,+)-linear combination \\alpha \\otimes u_1 \\oplus \\beta \\otimes u_2 of the two inputs yields the same (max,+)-linear combination of the outputs y_1 and y_2.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus linear (MPL) systems"
    ]
  },
  {
    "objectID": "max_plus_systems.html#input-output-response-of-an-mpl-system",
    "href": "max_plus_systems.html#input-output-response-of-an-mpl-system",
    "title": "Max-plus linear (MPL) systems",
    "section": "Input-output response of an MPL system",
    "text": "Input-output response of an MPL system\nWe can also eliminate the state variables from the model and aim at finding the relation between the input and output sequences \nU = \\begin{bmatrix}u_1 \\\\ u_2 \\\\ \\vdots \\\\ u_p\\end{bmatrix}, \\qquad Y = \\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_p\\end{bmatrix}\n in the form of \\boxed\n{Y = G\\otimes x_0 \\oplus H\\otimes U,}\n where \nH =\n\\begin{bmatrix}\nC\\otimes B & \\varepsilon & \\varepsilon & \\ldots & \\varepsilon\\\\\nC\\otimes A\\otimes B & C\\otimes B & \\varepsilon & \\ldots & \\varepsilon\\\\\nC\\otimes A^{\\otimes^2}\\otimes B & C\\otimes A\\otimes B & C\\otimes B & \\ldots & \\varepsilon\\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\nC\\otimes A^{\\otimes^{p-1}}\\otimes B & C\\otimes A^{\\otimes^{p-2}}\\otimes B & C\\otimes A^{\\otimes^{p-3}}\\otimes B & \\ldots & C\\otimes B\n\\end{bmatrix}\n and \nG =\n\\begin{bmatrix}\nC \\\\ C\\otimes A \\\\ C\\otimes A^{\\otimes^2} \\\\ \\vdots \\\\ C\\otimes A^{\\otimes^{p-1}}\n\\end{bmatrix}.\n\n\nExample 2 (Production system) We consider again the production system in Example 1. On the time horizon of 4, and assuming zero initial state, the input-output model is paramaterized by \nY = \\begin{bmatrix}y_1 & y_2 & y_3 & y_4\\end{bmatrix}^\\top, \\quad U = \\begin{bmatrix}u_1 & u_2 & u_3 & u_4\\end{bmatrix}^\\top,\n\n\nx_0 = \\begin{bmatrix}\\varepsilon & \\varepsilon & \\varepsilon\\end{bmatrix}^\\top,\n\n\nH =\n\\begin{bmatrix}\n21 & \\varepsilon & \\varepsilon & \\varepsilon\\\\\n32 & 21 & \\varepsilon & \\varepsilon\\\\\n43 & 32 & 21 & \\varepsilon\\\\\n55 & 43 & 32 & 21\n\\end{bmatrix}.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus linear (MPL) systems"
    ]
  },
  {
    "objectID": "max_plus_systems.html#analysis-of-an-irreducible-mpl-system",
    "href": "max_plus_systems.html#analysis-of-an-irreducible-mpl-system",
    "title": "Max-plus linear (MPL) systems",
    "section": "Analysis of an irreducible MPL system",
    "text": "Analysis of an irreducible MPL system\nWe now consider an autonomous MPL system \nx_{k+c} = A^{\\otimes^{k+c}}\\otimes x_0,\n for which we assume irreducibility of the matrix A.\nWe have learnt previously, that for large enough k and c, \nx_{k+c} = \\lambda^{\\otimes^c}\\otimes A^{\\otimes^{k}}\\otimes x_0 = \\lambda^{\\otimes^c}\\otimes x_k.\n\nThis can be interpreted in the standard algabra as \nx_{k+c} = c\\lambda + x_k,\n from which it follows that \nx_{k+c}-x_k = c\\lambda.\n\nThis is an insightful result. When the system under consideration is a production system, then once it reaches a cyclic behaviour, the average cycle is \\lambda. The average production rate is then 1/\\lambda.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus linear (MPL) systems"
    ]
  },
  {
    "objectID": "max_plus_systems.html#model-predictive-control-mpc-for-mpl-systems",
    "href": "max_plus_systems.html#model-predictive-control-mpc-for-mpl-systems",
    "title": "Max-plus linear (MPL) systems",
    "section": "Model Predictive Control (MPC) for MPL systems",
    "text": "Model Predictive Control (MPC) for MPL systems\nNow we are finally ready to consider control problems form MPL systems. We will consider the MPC approach.\n\nCosf function for MPC\nWe consider the const function composed of two parts \nJ = J_\\mathrm{output} + \\lambda J_\\mathrm{input}.\n\nAt “time” k, with the prediction horizon N_\\mathrm{p}, and with the number of outputs n_\\mathrm{y}: \nJ_\\mathrm{output} = \\sum_{j=0}^{N_\\mathrm{p}-1}\\sum_{i=1}^{n_\\mathrm{y}} \\max \\{y_{i,k+j} - r_{i,k+j},0\\}\n\nThis cost function penalizes tardiness (late delivery).\n\n\n\n\n\n\nCaution\n\n\n\nIs the lower value for j correct?\n\n\nAlternative choice of the cost function is \nJ_\\mathrm{output} = \\sum_{j=0}^{N_\\mathrm{p}-1}\\sum_{i=1}^{n_\\mathrm{y}} \\left|y_{i,k+j} - r_{i,k+j} \\right |,\n which penalizes difference between the due and actual dates, or \nJ_\\mathrm{output} = \\sum_{j=1}^{N_\\mathrm{p}-1}\\sum_{i=1}^{n_\\mathrm{y}} \\left |\\Delta^2 y_{i,k+j}\\right |,\n which balances the output rates.\nThe input cost can be set to \nJ_\\mathrm{input} = -\\sum_{j=0}^{N_\\mathrm{p}-1}\\sum_{l=1}^{n_\\mathrm{u}} u_{l,k+j},\n which penalizes early feeding (favours just-in-time feeding). Note the minus sign.\n\n\nControl horizon vs. prediction horizon\nAssume constant feeding rate after the control horizon N_\\mathrm{c} \n\\Delta u_{k+j} = \\Delta u_{k+N_\\mathrm{c}-1},\\qquad j=N_\\mathrm{c},\\ldots, N_\\mathrm{p}-1\n where \\Delta u_k = u_k - u_{k-1}.\nAlternatively, \n\\Delta^2 u_{k+j} = 0,\\qquad j=N_\\mathrm{c},\\ldots, N_\\mathrm{p}-1\n where \\Delta^2 u_k = \\Delta u_k - \\Delta u_{k-1} = u_k - 2u_{k-1} + u_{k-2}.\n\n\nInequality constraints for MPC\nThere are several possibilities for the constraints in the MPC for MPL systems. For example, we can constrain the minimum and maximum separation of input and output events \na_{k+j} \\leq \\Delta u_{k+j} \\leq b_{k+j},\\qquad j=0,1,\\ldots,N_\\mathrm{c}-1,\n \nc_{k+j} \\leq \\Delta y_{k+j} \\leq d_{k+j},\\qquad j=0,1,\\ldots,N_\\mathrm{p}-1.\n\nWe can also impose constraint on the maximum due dates for the output events \ny_{k+j} \\leq r_{k+j},\\qquad j=0,1,\\ldots,N_\\mathrm{p}-1.\n\nWe can also enforce the condition that the input and output events are consecutive \n\\Delta u_{k+j} \\geq 0, \\qquad j=0,1,\\ldots,N_\\mathrm{c}-1.\n\n\n\nMPC for MPL system leads to a nonlinear optimization problem\nOur motivation for formulating the problems within the (max,+) algebra was to fake the reality a bit and pretend that the problem is linear. This allowed us to invoke many concepts that we are familiar with from linear systems theory. However, at the end of the day, when it comes to actually solving the problem, we must reveal the nonlinear nature of the problem.\nWhen we consider the MPC for MPL systems, we are faced with a nonlinear optimization problem. We can use some general nonlinear solvers (fmincon, ipopt, …).\nAlternatively, there is a dedicated framework for solving these problem. It is called Extended Linear Complementarity Problem (ELCP) and was developed by [1]. We will introduce the complementarity problem(s) later in a chapter dedicated to complementarity.\nYet another approach is through Mixed Integer (Linear) Programming (MILP).",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus linear (MPL) systems"
    ]
  },
  {
    "objectID": "intro_references.html",
    "href": "intro_references.html",
    "title": "Literature",
    "section": "",
    "text": "The discipline of hybrid system is huge and spans several areas of science and engineering. As a result, finding a single comprehensive reference is difficult if not impossible. The more so that our selection of topics is inevitably biased. Admittedly, our selections of both topics and references will mostly be biased towards control engineering, and yet even within that discipline we have our own preferences. Therefore, we will always provide a list of references when studying particular topics.",
    "crumbs": [
      "0. Introduction",
      "Literature"
    ]
  },
  {
    "objectID": "intro_references.html#introductoryoverview-texts-freely-available-online",
    "href": "intro_references.html#introductoryoverview-texts-freely-available-online",
    "title": "Literature",
    "section": "Introductory/overview texts freely available online",
    "text": "Introductory/overview texts freely available online\nAmong the texts that provide motivation for studying hybrid systems as well as some introduction into theoretical and computational frameworks, we recommend [1], which is also available on the author’s webpage. Yet another overview, which is also available online, is [2]. And yet another is [3], which is available on the author’s web page. The quartet of recommended online resources is concluded by [4].",
    "crumbs": [
      "0. Introduction",
      "Literature"
    ]
  },
  {
    "objectID": "intro_references.html#books-not-freely-available-online-at-least-not-that-we-know-of",
    "href": "intro_references.html#books-not-freely-available-online-at-least-not-that-we-know-of",
    "title": "Literature",
    "section": "Books not freely available online (at least not that we know of)",
    "text": "Books not freely available online (at least not that we know of)\nAmong the high-quality printed books, for which we are not aware of legally available online versions, the slim book [5] can be regarded as the classic.\n\nThe handbook [6] contains a wealth of contributions from several authors (in fact two of the online resources linked above are chapters from this book).\n\nThe latest textbook on the topic of hybrid systems is [7]. The book was probably the prime candidate for the book for this course, however we wanted a slightly different emphasis on each topic.\n\nAnother relatively recent book is [8]. Although it is very well written and is certainly recommendable, it follows a particular framework that is not the most common one in the literature on hybrid systems – the framework of hybrid equations. But we are certainly going to introduce their approach in our course. The more so that it is supported by a freely available Matlab toolbox.\n\nThe book [9] can be regarded as a predecessor and/or complement of the just mentioned [8]. Although the book is not available online, a short version appears as an article [10] in the popular IEEE Control Systems magazine (the one with color figures :-).\n\nLast but not least, MPC methodology is specialized to hybrid systems in [11]. Unline the other books in this list, this one is freely available on the authors’ webpage.\n\nThis list of study resources on hybrid systems is by no means exhaustive. We will provide more references in the respective chapters.",
    "crumbs": [
      "0. Introduction",
      "Literature"
    ]
  },
  {
    "objectID": "stability_software.html",
    "href": "stability_software.html",
    "title": "Software",
    "section": "",
    "text": "In our course we formulated the problem of checking stability that that of constructing a Lyapunov function, which in turn was formulated as a problem of solving an optimization problem of semidefinite programming (with linear matrix inequalities, LMI) or positive (nonnegative) polynomial programming (via sum-of-squares (SOS) programming). Hence, we need to be able to formulate and solve those optimization problems.\n\nMatlab\n\nCVX\nYALMIP\n\nTutorial for semidefinite programming\nTutorial for sum-of-squares programming\n\nSOSTOOLS\n\n\n\nJulia\n\nConvex.jl\nJuMP.jl\nSumOfSquares.jl\n\n\n\nPython\n\nCVXPY\n\nTutorial for semidefinite programming\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "8. Stability",
      "Software"
    ]
  },
  {
    "objectID": "mld_references.html",
    "href": "mld_references.html",
    "title": "Literature",
    "section": "",
    "text": "The MLD description of discrete-time hybrid systems was originally introduced in [1], but perhaps even more accessible introduction is in Chapter 16 of the freely downloadable book [2]. In our text here we followed their expositions.\nJust in case some issues are still unclear, in particular those related to the connection between the constraints (inequalities) imposed on continuous (aka real) variables and logical conditions imposed on binary variable, you may like the little bit more formal discussion in Section 2.2 of the thesis [3]. Strictly speaking, this use of binary (0-1 integer) variables to encode some constraints on real variables is standard in optimization and is described elsewhere – search for indicator variables or indicator constraints. A recommendable general resource is the book (unfortunately not available online) [4], in particular its section 9.1.3 on Indicator variables.\nAll the theoretical concepts and procedures introduced in this lecture (and in those corresponding papers and books) are straightforward but rather tedious to actually implement. There is a HYSDEL language for modelling hybrid systems (discrete hybrid automata as considered in this lecture) that automates these procedures. The HYSDEL language is described not only in the documentation but also in the dedicated paper [5], which can also serve as a learning resource for the topic.\n\nCase studies\nBatch evaporator [6] and [7].\n\n\n\n\n\n Back to topReferences\n\n[1] A. Bemporad and M. Morari, “Control of systems integrating logic, dynamics, and constraints,” Automatica, vol. 35, no. 3, pp. 407–427, Mar. 1999, doi: 10.1016/S0005-1098(98)00178-2.\n\n\n[2] F. Borrelli, A. Bemporad, and M. Morari, Predictive Control for Linear and Hybrid Systems. Cambridge, New York: Cambridge University Press, 2017. Available: http://cse.lab.imtlucca.it/~bemporad/publications/papers/BBMbook.pdf\n\n\n[3] D. Mignone, “Control and estimation of hybrid systems with mathematical optimization,” Doctoral {{Thesis}}, ETH Zurich, 2002. doi: 10.3929/ethz-a-004279802.\n\n\n[4] H. P. Williams, Model Building in Mathematical Programming, 5th ed. Hoboken, N.J: Wiley, 2013.\n\n\n[5] F. D. Torrisi and A. Bemporad, “HYSDEL—a tool for generating computational hybrid models for analysis and synthesis problems,” IEEE Transactions on Control Systems Technology, vol. 12, no. 2, pp. 235–249, Mar. 2004, doi: 10.1109/TCST.2004.824309.\n\n\n[6] A. Bemporad, F. D. Torrisi, and M. Morari, “Discrete-time Hybrid Modeling and Verification of the Batch Evaporator Process Benchmark,” European Journal of Control, vol. 7, no. 4, pp. 382–399, Jan. 2001, doi: 10.3166/ejc.7.382-399.\n\n\n[7] S. Kowalewski and O. Stursberg, “The Batch Evaporator: A Benchmark Example for Safety Analysis of Processing Systems under Logic Control,” in Proceedings 4th Int. Workshop on Discrete Event Systems (WODES’98), Cagliari, Italy: IEE, London, Aug. 1998, pp. 302–307.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Literature"
    ]
  },
  {
    "objectID": "verification_barrier.html",
    "href": "verification_barrier.html",
    "title": "Barrier certificates",
    "section": "",
    "text": "This is another technique for verification of safety of hybrid system. Unlike the optimal-control based and set-propagation based techniques, it is not based on explicit computational characterization of the evolution of states in time. Instead, it is based on searching for a function of a state that satisfies certain properties. The function is called a barrier function and it serves as a certificate of safety.\nFor notational and conceptual convenience we start with an explanation of the method for continuous systems, and only then we extend it to hybrid systems.",
    "crumbs": [
      "12. Formal verification",
      "Barrier certificates"
    ]
  },
  {
    "objectID": "verification_barrier.html#barrier-certificate-for-continuous-systems",
    "href": "verification_barrier.html#barrier-certificate-for-continuous-systems",
    "title": "Barrier certificates",
    "section": "Barrier certificate for continuous systems",
    "text": "Barrier certificate for continuous systems\nWe consider a continuous-time dynamical system modelled by \n\\dot{\\bm x}(t) = \\mathbf f(\\bm x, \\bm d),\n where \\bm d represents an uncertainty in the system description – it can be an uncertain parameter or an external disturbance acting on the system.\nWe now define two regions of the state space:\n\nthe set of initial states \\mathcal X_0,\nand the set of unsafe states \\mathcal X_\\mathrm{u}.\n\nOur goal is to prove (certify) that the system does not reach the unsafe states for an arbitrary initial state \\bm x(0)\\in \\mathcal X_0 and for an arbitrary d\\in \\mathcal D.\nWe define a barrier function B(\\bm x) with the following three properties\nB(\\bm x) &gt; 0,\\quad \\forall \\bm x \\in \\mathcal X_\\mathrm{u},\nB(\\bm x) \\leq 0,\\quad \\forall \\bm x \\in \\mathcal X_0,\n\\nabla B(\\bm x)^\\top \\mathbf f(\\bm x, \\bm d) \\leq 0,\\quad \\forall \\bm x, \\bm d \\, \\text{such that} \\, B(\\bm x) = 0.\nNow, upon finding a function B(\\bm x) with such properties, we will prove (certify) safety of the system – the function serves as a certificate of safety.\n\n\n\n\n\n\nNote\n\n\n\nIt cannot go unnoticed that the properties of a barrier function B(\\bm x) and the motivation for its finding resemble those of a Lyapunov function. Indeed, the two concepts are related. But they are not the same.\n\n\nHow do we find such function? We will reuse the computational technique based on sum-of-squares (SOS) polynomials that we already used for Lyapunov functions. But first we need to handle one unpleasant aspect of the third condition above – nonconvexity of the set given by B(\\bm x) = 0.",
    "crumbs": [
      "12. Formal verification",
      "Barrier certificates"
    ]
  },
  {
    "objectID": "verification_barrier.html#convex-relaxation-of-the-barrier-certificate-problem",
    "href": "verification_barrier.html#convex-relaxation-of-the-barrier-certificate-problem",
    "title": "Barrier certificates",
    "section": "Convex relaxation of the barrier certificate problem",
    "text": "Convex relaxation of the barrier certificate problem\nWe relax the third condition so that it holds not only at B(\\bm x) = 0 but everywhere. The three conditions are then B(\\bm x) &gt; 0,\\quad \\forall \\bm x \\in \\mathcal X_\\mathrm{u},\nB(\\bm x) \\leq 0,\\quad \\forall \\bm x \\in \\mathcal X_0,\n\\nabla B(\\bm x)^\\top \\mathbf f(\\bm x, \\bm d) \\leq 0,\\quad \\forall \\bm x\\in \\mathcal X, \\bm d \\in \\mathcal D.\nLet’s now demonstrate this by means of an example.\n\nExample 1 Consider the system modelled by \n\\begin{aligned}\n\\dot x_1 &= x_2\\\\\n\\dot x_2 &= -x_1 + \\frac{p}{3}x_1^3 - x_2,\n\\end{aligned}\n where the parameter p\\in [0.9,1.1].\nThe initial set is given by \n\\mathcal X_0 = \\{ \\bm x \\in \\mathbb R^2 \\mid (x_1-1.5)^2 + x_2^2 \\leq 0.25 \\}\n and the unsafe set is given by \n\\mathcal X_\\mathrm{u} = \\{ \\bm x \\in \\mathbb R^2 \\mid (x_1+1)^2 + (x_2+1)^2 \\leq 0.16 \\}.\n\nThe vector field \\mathbf f and the initial and unsafe sets are shown in the figure below.\n\n\nShow the code\nusing SumOfSquares\nusing DynamicPolynomials\n# using MosekTools     \nusing CSDP\n\noptimizer = optimizer_with_attributes(CSDP.Optimizer, MOI.Silent() =&gt; true)\nmodel = SOSModel(optimizer)\n@polyvar x[1:2] \n\np = 1;\n\nf = [ x[2],\n     -x[1] + (p/3)*x[1]^3 - x[2]]\n\ng₁ = -(x[1]+1)^2 - (x[2]+1)^2 + 0.16  # 𝒳ᵤ = {x ∈ R²: g₁(x) ≥ 0}\nh₁ = -(x[1]-1.5)^2 - x[2]^2 + 0.25    # 𝒳₀ = {x ∈ R²: h₁(x) ≥ 0}\n\nX = monomials(x, 0:4)\n@variable(model, B, Poly(X))\n\nε = 0.001\n@constraint(model, B &gt;= ε, domain = @set(g₁ &gt;= 0))\n\n@constraint(model, B &lt;= 0, domain = @set(h₁ &gt;= 0))\n\nusing LinearAlgebra # Needed for `dot`\ndBdt = dot(differentiate(B, x), f)\n@constraint(model, -dBdt &gt;= 0)\n\nJuMP.optimize!(model)\n\nJuMP.primal_status(model)\n\nimport DifferentialEquations, Plots, ImplicitPlots\nfunction phase_plot(f, B, g₁, h₁, quiver_scaling, Δt, X0, solver = DifferentialEquations.Tsit5())\n    X₀plot = ImplicitPlots.implicit_plot(h₁; xlims=(-2, 3), ylims=(-2.5, 2.5), resolution = 1000, label=\"X₀\", linecolor=:blue)\n    Xᵤplot = ImplicitPlots.implicit_plot!(g₁; xlims=(-2, 3), ylims=(-2.5, 2.5), resolution = 1000, label=\"Xᵤ\", linecolor=:teal)\n    Bplot  = ImplicitPlots.implicit_plot!(B; xlims=(-2, 3), ylims=(-2.5, 2.5), resolution = 1000, label=\"B = 0\", linecolor=:red)\n    Plots.plot(X₀plot)\n    Plots.plot!(Xᵤplot)\n    Plots.plot!(Bplot)\n    ∇(vx, vy) = [fi(x[1] =&gt; vx, x[2] =&gt; vy) for fi in f]\n    ∇pt(v, p, t) = ∇(v[1], v[2])\n    function traj(v0)\n        tspan = (0.0, Δt)\n        prob = DifferentialEquations.ODEProblem(∇pt, v0, tspan)\n        return DifferentialEquations.solve(prob, solver, reltol=1e-8, abstol=1e-8)\n    end\n    ticks = -5:0.5:5\n    X = repeat(ticks, 1, length(ticks))\n    Y = X'\n    Plots.quiver!(X, Y, quiver = (x, y) -&gt; ∇(x, y) / quiver_scaling, linewidth=0.5)\n    for x0 in X0\n        Plots.plot!(traj(x0), idxs=(1, 2), label = nothing)\n    end\n    Plots.plot!(xlims = (-2, 3), ylims = (-2.5, 2.5), xlabel = \"x₁\", ylabel = \"x₂\")\nend\n\nphase_plot(f, value(B), g₁, h₁, 10, 30.0, [[x1, x2] for x1 in 1.2:0.2:1.7, x2 in -0.35:0.1:0.35])\n\n\n┌ Warning: At t=4.423118290940107, dt was forced below floating point epsilon 8.881784197001252e-16, and step error estimate = 1.139033855908175. Aborting. There is either an error in your model specification or the true solution is unstable (or the true solution can not be represented in the precision of Float64).\n└ @ SciMLBase ~/.julia/packages/SciMLBase/VW1cI/src/integrator_interface.jl:623\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: The vector field, the initial and unsafe sets, and the boundary function level set for the barrier certificate example. Simulated are also a few trajectories. From Tutorials for SumOfSquares.jl.",
    "crumbs": [
      "12. Formal verification",
      "Barrier certificates"
    ]
  },
  {
    "objectID": "verification_barrier.html#barrier-certificate-for-hybrid-systems",
    "href": "verification_barrier.html#barrier-certificate-for-hybrid-systems",
    "title": "Barrier certificates",
    "section": "Barrier certificate for hybrid systems",
    "text": "Barrier certificate for hybrid systems\nFor a hybrid automaton with l locations \\{q_1,q_2,\\ldots,q_l\\}, not just one but l barrier functions/certificates are needed:\nB_i(\\bm x) &gt; 0,\\quad \\forall \\bm x \\in \\mathcal X_\\mathrm{u}(q_i),\nB_i(\\bm x) \\leq 0,\\quad \\forall \\bm x \\in \\mathcal X_0(q_i),\n\\nabla B_i(\\bm x)^\\top \\mathbf f_i(\\bm x, \\bm u) \\leq 0,\\quad \\forall \\bm x, \\bm u \\, \\text{such that} \\, B_i(\\bm x) = 0,\n\n\\begin{aligned}\nB_i(\\bm x) \\leq 0,\\quad &\\forall \\bm x \\in \\mathcal R(q_j,q_i,\\bm x^-)\\,\\text{for some}\\, q_j\\,\\\\\n&\\text{and}\\, \\bm x^-\\in\\mathcal G(q_j,q_i)\\,\\text{with}\\, B_j(\\bm x^-)\\leq 0.\n\\end{aligned}",
    "crumbs": [
      "12. Formal verification",
      "Barrier certificates"
    ]
  },
  {
    "objectID": "verification_barrier.html#convex-relaxation-of-barrier-certificates-for-hybrid-systems",
    "href": "verification_barrier.html#convex-relaxation-of-barrier-certificates-for-hybrid-systems",
    "title": "Barrier certificates",
    "section": "Convex relaxation of barrier certificates for hybrid systems",
    "text": "Convex relaxation of barrier certificates for hybrid systems\n\\nabla B_i(\\bm x)^\\top \\mathbf f_i(\\bm x, \\bm u) \\leq 0,\\quad \\forall \\bm x\\in X_0(q_i), \\bm u\\in\\mathcal U(q_i),\n\n\\begin{aligned}\nB_i(\\bm x) \\leq 0,\\quad &\\forall (\\bm x, \\bm x^-)\\,\\text{such that}\\, \\bm x \\in \\mathcal R(q_j,q_i,\\bm x^-), \\\\\n&\\text{and}\\, \\bm x^-\\in\\mathcal G(q_i,q_j).\n\\end{aligned}",
    "crumbs": [
      "12. Formal verification",
      "Barrier certificates"
    ]
  },
  {
    "objectID": "verification_reachability.html",
    "href": "verification_reachability.html",
    "title": "Reachability analysis",
    "section": "",
    "text": "For autonomous systems: Given a set of initial states \\mathcal X_0, determine the set of states \\mathcal X_{\\mathrm{reach}} that can be reached from X_0 over the time interval (0,t).\nFor non-autonomous (controlled) system: Given a set of initial states \\mathcal X_0, determine the set of states \\mathcal X_{\\mathrm{reach}} that can be reached from X_0 over the time interval (0,t) using some control.\nRobust versions exist for cases with uncertain parameters, or disturbances.",
    "crumbs": [
      "12. Formal verification",
      "Reachability analysis"
    ]
  },
  {
    "objectID": "verification_reachability.html#reachability-computations-for-hybrid-systems",
    "href": "verification_reachability.html#reachability-computations-for-hybrid-systems",
    "title": "Reachability analysis",
    "section": "Reachability computations for hybrid systems",
    "text": "Reachability computations for hybrid systems\nThere are two major approaches to reachibility analysis for hybrid systems\n\nChecking a feasibility of an optimal control problem for a MLD system. This is used in Hybrid Toolbox (and Hysdel): http://cse.lab.imtlucca.it/~bemporad/hybrid/toolbox/\nComputing the reachable sets by set propagation techniques.\n\n\nReachability analysis based on optimal control\nThe former does not need much discussion here. We have already discussed all the crucial concepts and facts when introducing the MPC for hybrid systems. Infeasibility of the corresponding optimization problem indicates unreachability. Thefefore, we focus on the latter here.\n\n\nReachability analysis based on set propagation\n\nBasic computational steps for reachability analysis based on set propagation\nGiven a set \\mathcal X_k of current states \\bm x(k), compute the set \\mathcal X_{k+1} of next states \\bm x(k+1) of a discrete-time (or discretized) system such that\n\n\\bm x(k+1) = \\mathbf f(\\bm x(k)).\n\nIn the case of a linear discrete-time system, and the set of initial states characterized by a (multidimensional) interval, the problem is to characterize the set \\mathcal X_{k+1} of all possible (reachable) \\bm x(k+1) satisfying \n\\begin{aligned}\n\\bm x(k+1) &= \\mathbf A \\bm x(k),\\\\\n\\bm x(k) &\\in \\mathcal X_k = \\{\\bm x(k) \\in \\mathbb R^n \\mid \\bm x_\\mathrm{min} \\leq \\bm x(k) \\leq \\bm x_\\mathrm{max}\\}.\n\\end{aligned}\n\nTypically, inner or outer approximations of the set of all possible next states are used, depending on the context (alowed vs forbidden regions of the state space).\n\n\nSets to be propagated\nCertain sets are (computationally) easier to propagate than others:\n\nIntervals\nPolyhedra (both in V and H representations)\nEllipsoids\nZonotopes\n\n\nZonotopes\nWhile the first three types of sets are well-known, we will discuss the forth in the list – zonotopes. Zonotopes are a class of polytopes. They are commonly used in reachability analysis because computationally they are often more efficient than general polytopes.\nThe can be obtained by an affine transformation of a unit box, that is, \n\\mathcal Z = \\{\\bm x\\in\\mathbb R^n \\mid \\bm x = \\mathbf A \\bm y+\\mathbf b, \\; \\bm y\\in\\mathbb R^m, \\; |y_i|\\leq 1\\},\n but most commonly they are represented using generator representation \n\\mathcal Z = \\{\\bm x\\in\\mathbb R^n \\mid \\bm x = \\mathbf c + \\sum_{i=1}^p \\alpha_i \\mathbf g_i, \\; \\mathbf g_i\\in\\mathbb R^n, \\; \\alpha_i\\in\\mathbb R, \\;|\\alpha_i|\\leq 1\\},\n where \\mathbf c\\in\\mathbb R^n is the center and \\mathbf g_i\\in\\mathbb R^n are the generators.",
    "crumbs": [
      "12. Formal verification",
      "Reachability analysis"
    ]
  },
  {
    "objectID": "classes_switched.html",
    "href": "classes_switched.html",
    "title": "Switched systems",
    "section": "",
    "text": "Switched systems are modelled by first-order differential (state) equations with multiple right-hand sides, that is,\n\\dot{\\bm x} = \\bm f_q(\\bm x), \\qquad q \\in \\{1,2, \\ldots, m\\},\n\\tag{1} where m right-hand sides are possible and the lower index q determines which right-hand side function is “active” at a given moment.\nThe question is, what dictates the evolution of the integer variable q? In other words, what drives the switching? It turns out that the switching can be time-driven or state-driven.\nIn both cases, the right-hand sides can also depend the control input \\bm u.\nMajor results for switched systems have been achieved without the need to refer to the framework of hybrid systems. But now that we have built such general framework, it turns out useful to view switched systems as a special class of hybrid systems. The aspects in which they are special will be discussed in the following, but here let us state that in contrast to full hybrid systems, switched systems are a bit less rich on the discrete side.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Switched systems"
    ]
  },
  {
    "objectID": "classes_switched.html#time-driven",
    "href": "classes_switched.html#time-driven",
    "title": "Switched systems",
    "section": "Time-driven",
    "text": "Time-driven\nThe evolution of the state variable complies with the following model \\dot{\\bm x} = \\bm f_{q(t)}(\\bm x), where q(t) is some function of time. The values of q(t) can be under our control or beyond our control, deterministic or stochastic.\nA hybrid automaton for a time-driven switched system is shown in Fig. 1.\n\n\n\n\n\n\nFigure 1: An automaton for a switched system with time-driven switching\n\n\n\nThe transition from one mode to another is triggered by the integer variable q(t) attaining the appropriate value.\nSince the switching signal is unrelated to the (continuous) state of the system, the invariant of the two modes are usually covering the whole state space \\mathcal X.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Switched systems"
    ]
  },
  {
    "objectID": "classes_switched.html#state-dependent-switching",
    "href": "classes_switched.html#state-dependent-switching",
    "title": "Switched systems",
    "section": "State-dependent switching",
    "text": "State-dependent switching\nThe model is \n\\dot{\\bm x}\n=\n\\begin{cases}\n\\bm f_1(\\bm x), & \\mathrm{if}\\, \\bm x \\in \\mathcal{X}_1,\\\\\n\\vdots\\\\\n\\bm f_m(\\bm x), & \\mathrm{if}\\, \\bm x \\in \\mathcal{X}_m.\n\\end{cases}\n\nLet’s consider just two domains \\mathcal X_1 and \\mathcal X_2. A hybrid automaton for a state-driven switched system is shown in Fig. 2.\n\n\n\n\n\n\nFigure 2: An automaton for a switched system with state-driven switching\n\n\n\nThe transition to the other mode is triggered by the continuous state of the system crossing the boundary between the two domains. The boundary is defined by the function s(\\bm x) (called switching function), which is zero on the boundary, see the Fig. 3.\n\n\n\n\n\n\nFigure 3: State-dependent switching\n\n\n\nThrough examples we now illustrate the possible behaviors of the system when the flow transverses the boundary, when it pulls away from the boundary, and when it pushes towards the boundary.\n\nExample 1 (The flow transverses the boundary) We consider the two right-hand sides of the state equation \n\\bm f_1(\\bm x) = \\begin{bmatrix}1\\\\ x_1^2 + 2x_2^2\\end{bmatrix}\n and \n\\bm f_2(\\bm x) = \\begin{bmatrix}1\\\\ 2x_1^2+3x_2^2-2\\end{bmatrix}\n and the switching function \ns(x_1,x_2) = (x_1+0.05)^2 + (x_2+0.15)^2 - 1.\n\nThe state portrait that also shows the switching function is generated using the following code.\n\n\nShow the code\ns(x₁,x₂) = (x₁+0.05)^2 + (x₂+0.15)^2 - 1.0\n\nf₁(x₁,x₂) = x₁^2 + 2x₂^2\nf₂(x₁,x₂) = 2x₁^2+3x₂^2-2.0\n\nf(x₁,x₂) = s(x₁,x₂) &lt;= 0.0 ? [1,f₁(x₁,x₂)] : [1,f₂(x₁,x₂)] \n\nN = 100\nx₁ = range(0, stop = 0.94, length = N)\n\nusing CairoMakie\nfig = Figure(size = (600, 600),fontsize=20)\nax = Axis(fig[1, 1], xlabel = \"x₁\", ylabel = \"x₂\")\nstreamplot!(ax,(x₁,x₂)-&gt;Point2f(f(x₁,x₂)), 0..1.5, 0..1.5, colormap = :magma)\nlines!(ax,x₁,sqrt.(1 .- (x₁ .+ 0.05).^2) .- 0.15, color = :red, linewidth=5)\nx10 = 0.5\nx20 = sqrt(1 - (x10 + 0.05)^2) - 0.15\nMakie.scatter!(ax,[x10],[x20],color=:blue,markersize=30)\nfig\n\n\n\n\n\n\n\n\n\nThe state portrait also shows a particular initial state \\bm x_0 using a blue dot. Note that the projection of both vector fields \\mathbf f_1 and \\mathbf f_2 evaluated at \\bm x_0 onto the normal (the gradient) of the switching function at \\bm x_0 is positive, that is \n\\left.\\left(\\nabla s\\right)^\\top \\bm f_1\\right|_{\\bm x_0} \\geq 0, \\quad \\left.\\left(\\nabla s\\right)^\\top \\bm f_2\\right|_{\\bm x_0} \\geq 0.\n\nThis is consistent with the observation that the flow goes through the boundary.\nWe can also plot a particular solution of the ODE using the following code.\n\n\nShow the code\nusing DifferentialEquations\nF(u, p, t) = f(u[1],u[2])\nu0 = [0.0,0.4]\ntspan = (0.0, 1.0)\nprob = ODEProblem(F, u0, tspan)\nsol = solve(prob, Tsit5(), reltol = 1e-8, abstol = 1e-8)\n\nusing Plots\nPlots.plot(sol,lw=3,xaxis=\"Time\",yaxis=\"x\",label=false)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStrictly speaking, this solution does not satisfy the differential equation on the boundary of the two domains (the derivative of x_2 does not exist there). This is visually recognized in the above plot as the sharp corner in the solution. But other than that, the solution is perfectly “reasonable” – for a while the system evolves according to one state equations, then at one particular moment the system starts evolving according to another state equation. That is it. Not much more to see here.\n\n\nExample 2 (The flow pulls away from the boundary) We now consider another pair of the right-hand sides. \n\\bm f_1(\\bm x) = \\begin{bmatrix}-1\\\\ x_1^2 + 2x_2^2\\end{bmatrix}\n and \n\\bm f_2(\\bm x) = \\begin{bmatrix}1\\\\ 2x_1^2+3x_2^2-2\\end{bmatrix}.\n\nThe switching function is the same as in the previous example.\nThe state portrait is below.\n\n\nShow the code\nf(x₁,x₂) = s(x₁,x₂) &lt;= 0.0 ? [-1, f₁(x₁,x₂)] : [1, f₂(x₁,x₂)] \n\nfig = Figure(size = (600, 600),fontsize=20)\nax = Axis(fig[1, 1], xlabel = \"x₁\", ylabel = \"x₂\")\nstreamplot!(ax,(x₁,x₂)-&gt;Point2f(f(x₁,x₂)), 0..1.5, 0..1.5, colormap = :magma)\nlines!(ax,x₁,sqrt.(1 .- (x₁ .+ 0.05).^2) .- 0.15, color = :red, linewidth=5)\nx10 = 0.8\nx20 = sqrt(1 - (x10 + 0.05)^2) - 0.15\nMakie.scatter!(ax,[x10],[x20],color=:blue,markersize=30)\nfig\n\n\n\n\n\n\n\n\n\nWe focus on the blue dot again. The projections of the two vector fields onto the normal of the switching function satisfy \n\\left.\\left(\\nabla s\\right)^\\top \\bm f_1\\right|_{\\bm x_0} \\leq 0, \\quad \\left.\\left(\\nabla s\\right)^\\top \\bm f_2\\right|_{\\bm x_0} \\geq 0.\n\nThe only interpretation of this situation is that a unique solution does not start at \\bm x_0. Again, not much more to see here.\n\n\nExample 3 (The flow pushes towards the boundary) And one last pair of the right-hand sides: \n\\bm f_1(\\bm x) = \\begin{bmatrix}1\\\\ x_1^2 + 2x_2^2\\end{bmatrix}\n and \n\\bm f_2(\\bm x) = \\begin{bmatrix}-1\\\\ 2x_1^2+3x_2^2-2\\end{bmatrix}.\n\nThe state-portrait is below.\n\n\nShow the code\nf(x₁,x₂) = s(x₁,x₂) &lt;= 0.0 ? [1, f₁(x₁,x₂)] : [-1, f₂(x₁,x₂)] \n\nfig = Figure(size = (600, 600),fontsize=20)\nax = Axis(fig[1, 1], xlabel = \"x₁\", ylabel = \"x₂\")\nstreamplot!(ax,(x₁,x₂)-&gt;Point2f(f(x₁,x₂)), 0..1.5, 0..1.5, colormap = :magma)\nlines!(ax,x₁,sqrt.(1 .- (x₁ .+ 0.05).^2) .- 0.15, color = :red, linewidth=5)\nx10 = 0.5\nx20 = sqrt(1 - (x10 + 0.05)^2) - 0.15\nMakie.scatter!(ax,[x10],[x20],color=:blue,markersize=30)\nfig\n\n\n\n\n\n\n\n\n\nThe projections of the two vector fields onto the normal of the switching function satisfy \n\\left.\\left(\\nabla s\\right)^\\top \\bm f_1\\right|_{\\bm x_0} \\geq 0, \\quad \\left.\\left(\\nabla s\\right)^\\top \\bm f_2\\right|_{\\bm x_0} \\leq 0.\n\nBut this is interesting! Once the trajectory hits the switching curve and tries to penetrate it futher, it is pushed back to the switching curve. As it tries to penetrate it further, it is pushed back to the switching curve again. And so on. But then, how does the state evolve from \\bm x_0?\nHint: solve the ODE numerically with some finite step size. The solution will exhibit zig-zagging or chattering along the switching curve, away from the blue point. Now, keep shrinking the step size. The solution will ultimately “slide” smoothly along the switching curve. Perhaps this was your guess. One thing should worry you, however: such “sliding” solution satisfies neither of the two state equations!\nWe will make this more rigorous in a moment, but right now we just wanted to tease the intuition.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Switched systems"
    ]
  },
  {
    "objectID": "classes_switched.html#conditions-for-existence-and-uniqueness-of-solutions-of-ode",
    "href": "classes_switched.html#conditions-for-existence-and-uniqueness-of-solutions-of-ode",
    "title": "Switched systems",
    "section": "Conditions for existence and uniqueness of solutions of ODE",
    "text": "Conditions for existence and uniqueness of solutions of ODE\nIn order to analyze the situations such as the previous example, we need to recapitulate some elementary facts about the existence and uniqueness of solutions of ordinary differential equations (ODEs). And then we are going to add some new stuff.\nConsider the ODE\n\\dot x(t) = f(x(t),t).\nWe ask the following two questions:\n\nUnder which conditions does a solution exists?\nUnder which conditions is the solution unique?\n\nTo answer both, the function f() must be analyzed.\nBut before we answer the two questions, we must ask another one that is even more fundamental:\n\nWhat does it mean that a function x(t) is a solution of the the ODE?\n\nHowever trivial this question may seem, an answer can escalate rather quickly – there are actually several concepts of a solution of an ordinary differential equation.\n\nClassical solution (Peano, also Cauchy-Peano)\nWe assume that f(x(t),t) is continuous with respect to both x and t. Then existence of a solution is guaranteed locally (on some finite interval), but uniqueness is not.\n\n\n\n\n\n\nNot guaranteed does not mean impossible\n\n\n\nUniqueness is not not excluded in all cases, it is just that it is not guaranteed.\n\n\nA solution is guaranteed to be continuously differentiable ( x\\in\\mathrm C^1 ). Such function x(t) satisfies the ODE \\dot x(t) = f(x(t),t) \\; \\forall t, that is why such solution is called classical.\n\nExample 4 An example of a solution that exists only on a finite interval is \n  \\dot x(t) = x^2(t),\\; x(0) = 1,\n\nfor which the solution is x(t) = \\frac{1}{1-t} . The solution blows up at t=1 .\n\n\nExample 5 An example of nonuniqueness is provided by \\dot x(t) = \\sqrt{x(t)}, \\; x(0) = 0.\nOne possible solution is x(t) = \\frac{1}{4}t^2. Another is x(t) = 0. Yet another example is x(t) = \\frac{1}{4}(t-t_0)^2. It is related to the Leaky bucket example.\n\n\n\nStrenghtening the requirement of continuity (Pickard-Lindelöf)\nSince continuity of f(x(t),t) was not enough to guarantee uniqueness, we need to impose a stricter condition on f(). Namely, we impose a stricter condition on f() with respect to x – Lipschitz continuity, while we still require that the function be continuous with respect to t.\nNow it is not only existence but also uniqueness of a solution that is guaranteed.\n\n\n\n\n\n\nUniqueness not guaranteed does not mean it is impossible\n\n\n\nSimilarly as with Peano conditions, here too the condition is not necessary, it is just sufficient – even if the function f is not Lipschitz continuous, there may exist a unique solution.\n\n\nSince the condition is stricter than mere continuity, whatever goodies hold here too. In particular, the solution is guaranteed to be continuously differentiable.\nIf the function is only locally Lipschitz, the solution is guaranteed on some finite interval. If the function is (globally) Lipschitz, the solution is guaranteed on an unbounded interval.\n\n\nExtending the set of solutions (Carathéodory)\nIn contrast with the classical solution, we can allow the solution x(t) to fail to satisfy the ODE at some isolated points in time. This is called Carathéodory (or extended) solution.\nCarathéodory solution x(t) is more than just continuous (even more than uniformly continuous) but less than contiuously differentiable (aka \\mathcal C^1) – it is absolutely continuous. Absolutely continuous function is a solution of the integral equation (indeed, an equation) x(t) = x(t_0) + \\int_{t_0}^t f(x(\\tau),\\tau)\\mathrm{d}\\tau,\nwhere we use Lebesgue integral (instead of Riemann).\nHaving referred to absolute continuity and Lebesgue integral, the discussion could quickly become rather technical. But all we want to say is that f can be “some kind of discontinuous” with respect to t. In particular, it must be measurable wrt t, which again seems to start escalating… But it suffices to say that it includes the case when f(x,t) is piecewise continuous with respect to t (sampled data control with ZOH).\nNeedles to say that for a continuous f, solutions x are just classical (smooth).\nIf the function f is discontinuous with respect to x, some more concepts of a solution need to be invoked so that existence and uniqueness can be analyzed.\n\nExample 6 (Some more examples of nonexistence and nonuniqueness of solutions) The system with a discontinuous RHS \n\\begin{aligned}\n\\dot x_1 &= -2x_1 - 2x_2\\operatorname*{sgn(x_1)},\\\\\n\\dot x_2 &= x_2 + 4x_1\\operatorname*{sgn(x_1)}\n\\end{aligned}\n can be reformulated as a switched system \n\\begin{aligned}\n\\dot{\\bm x} &= \\begin{bmatrix}-2 & 2\\\\-4 & 1\\end{bmatrix}\\begin{bmatrix}x_1\\\\ x_2\\end{bmatrix}, \\quad  s(\\bm x)\\leq 0\\\\\n\\dot{\\bm x} &= \\begin{bmatrix}-2 & -2\\\\4 & 1\\end{bmatrix}\\begin{bmatrix}x_1\\\\ x_2\\end{bmatrix}, \\quad s(\\bm x)&gt; 0,\n\\end{aligned}\n where the switching function is s(\\bm x) = x_1.\n\n\nShow the code\ns(x) = x[1]\n\nf₁(x) = [-2x[1] + 2x[2], x[2] - 4x[1]]\nf₂(x) = [-2x[1] - 2x[2], x[2] + 4x[1]]\n\nf(x) = s(x) &lt;= 0.0 ? f₁(x) : f₂(x) \n\nusing CairoMakie\nfig = Figure(size = (600, 600),fontsize=20)\nax = Axis(fig[1, 1], xlabel = \"x₁\", ylabel = \"x₂\")\nstreamplot!(ax,x-&gt;Point2f(f(x)), -1.5..1.5, -1.5..1.5, colormap = :magma)\nvlines!(ax,0; ymin = -1.1, ymax = 1.1, color = :red)\nfig\n\n\n\n\n\n\n\n\n\n\n\n\nSliding mode dynamics (on simple boundaries)\nThe previous example provided yet another illustration of a phenomenon of sliding, or a sliding mode. We say that there is an attractive sliding mode at \\bm x_\\mathrm{s}, if there is a trajectory that ends at \\bm x_\\mathrm{s}, but no trajectory that starts at \\bm x_\\mathrm{s}.\n\n\nGeneralized solutions (Filippov)\nIt is now high time to introduce yet another concept of a solution. A concept that will make it possible to model the sliding mode dynamics in a more rigorous way. Remember that when the state \\bm x(t) slides along the boundary, it qualifies as a solution to neither of the two state equations in any sense we have discussed so far. But now comes the concept of Fillipov solution.\n\\bm x() is a Filippov solution on [t_0,t_1] if for almost all t \n\\dot{\\bm{x}}(t) \\in \\overline{\\operatorname*{co}}\\{\\mathbf f(\\bm x(t),t)\\},\n where \\overline{\\operatorname*{co}} denotes the (closed) convex hull.\n\nExample 7 Consider the model in the previous example. The switching surface, along which the solution slides, is given by \\mathcal{S}^+ = \\{\\bm x \\mid x_1=0 \\land x_2\\geq 0\\}.\nNow, Filippov solution must satisfy the following differential inclusion \n\\begin{aligned}\n\\dot{\\bm x}(t) &\\in \\overline{\\operatorname*{co}}\\{\\bm A_1\\bm x_1(t), \\bm A_2\\bm x_2(t)\\}\\\\\n&= \\alpha_1(t) \\bm A_1\\bm x_1(t) + \\alpha_2(t) \\bm A_2\\bm x_2(t),\n\\end{aligned}\n where \\alpha_1(t), \\alpha_2(t) \\geq 0, \\alpha_1(t) + \\alpha_2(t) = 1.\nNote, however, that not all the weights keep the solution on \\mathcal S^+. We must impose some restriction, namely that \\dot x_1 = 0 for \\bm x(t) \\in \\mathcal S^+. This leads to \n\\alpha_1(t) [-2x_1 + 2x_2] + \\alpha_2(t) [-2x_1 - 2x_2] = 0\n\nCombining this with \\alpha_1(t) + \\alpha_2(t) = 1 gives \n\\alpha_1(t) = \\alpha_2(t) = 1/2,\n which in this simple case perhaps agrees with our intuition (the average of the two vector fields).\nThe dynamics on the sliding mode is modelled by \n\\dot x_1 = 0, \\quad \\dot x_2 = x_2, \\quad \\bm x \\in \\mathcal{S}^+.\n\n\n\n\n\n\n\n\nPossible nonuniqueness on intersection of boundaries\n\n\n\n…",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Switched systems"
    ]
  },
  {
    "objectID": "hybrid_system_course_mindmap.html",
    "href": "hybrid_system_course_mindmap.html",
    "title": "B(E)3M35HyS",
    "section": "",
    "text": "(State) automata (state machines) (and timed automata)\nPetri nets (and timed Petri nets),\nMax-Plus algebra and Max-Plus Linear (MPL) systems\n\n\n\n\n\nHybrid automata\nHybrid equations\n\n\n\n\n\nReset (control) systems\nSwitched/switching systems\nPiecewise affine systems (PWA)\n\n\n\n\n\nComplementarity dynamical systems (and complementarity optimization constraints)\n\n\n\n\n\nSolutions of hybrid systems\n\n\nStability of hybrid systems\n\nCommon Lyapunov function\n\nQuadratic Lyapunov function via linear matrix inequality (LMI) and semidefinite programming (SDP)\nPolynomial Lyapunov function via sum-of-squares (SOS) programming\n\nPiecewise quadratic/polynomial Lyapunov function via S-procedure / Putinar’s Positivstellensatz\n\n\n\n\n\n\nMixed-logical dynamical (MLD) description of hybrid systems\nModel predictive control (MPC) for MLD systems\n\n\n\n\n\nReachability analysis\n\n(In)feasibility of an optimal control problem\nSet propagation techniques\n\n(Control) barrier functions\nTemporal logics\n\nLTL, CTL, CTL, MTL, MITL, TCTL, STL, …"
  },
  {
    "objectID": "hybrid_system_course_mindmap.html#discrete-event-systems",
    "href": "hybrid_system_course_mindmap.html#discrete-event-systems",
    "title": "B(E)3M35HyS",
    "section": "",
    "text": "(State) automata (state machines) (and timed automata)\nPetri nets (and timed Petri nets),\nMax-Plus algebra and Max-Plus Linear (MPL) systems"
  },
  {
    "objectID": "hybrid_system_course_mindmap.html#modelling-hybrid-systems",
    "href": "hybrid_system_course_mindmap.html#modelling-hybrid-systems",
    "title": "B(E)3M35HyS",
    "section": "",
    "text": "Hybrid automata\nHybrid equations"
  },
  {
    "objectID": "hybrid_system_course_mindmap.html#special-classes-of-hybrid-systems",
    "href": "hybrid_system_course_mindmap.html#special-classes-of-hybrid-systems",
    "title": "B(E)3M35HyS",
    "section": "",
    "text": "Reset (control) systems\nSwitched/switching systems\nPiecewise affine systems (PWA)"
  },
  {
    "objectID": "hybrid_system_course_mindmap.html#numerical-simulation-of-hybrid-systems",
    "href": "hybrid_system_course_mindmap.html#numerical-simulation-of-hybrid-systems",
    "title": "B(E)3M35HyS",
    "section": "",
    "text": "Complementarity dynamical systems (and complementarity optimization constraints)"
  },
  {
    "objectID": "hybrid_system_course_mindmap.html#analysis-of-hybrid-systems",
    "href": "hybrid_system_course_mindmap.html#analysis-of-hybrid-systems",
    "title": "B(E)3M35HyS",
    "section": "",
    "text": "Solutions of hybrid systems\n\n\nStability of hybrid systems\n\nCommon Lyapunov function\n\nQuadratic Lyapunov function via linear matrix inequality (LMI) and semidefinite programming (SDP)\nPolynomial Lyapunov function via sum-of-squares (SOS) programming\n\nPiecewise quadratic/polynomial Lyapunov function via S-procedure / Putinar’s Positivstellensatz"
  },
  {
    "objectID": "hybrid_system_course_mindmap.html#control-design",
    "href": "hybrid_system_course_mindmap.html#control-design",
    "title": "B(E)3M35HyS",
    "section": "",
    "text": "Mixed-logical dynamical (MLD) description of hybrid systems\nModel predictive control (MPC) for MLD systems"
  },
  {
    "objectID": "hybrid_system_course_mindmap.html#verification-of-hybrid-systems",
    "href": "hybrid_system_course_mindmap.html#verification-of-hybrid-systems",
    "title": "B(E)3M35HyS",
    "section": "",
    "text": "Reachability analysis\n\n(In)feasibility of an optimal control problem\nSet propagation techniques\n\n(Control) barrier functions\nTemporal logics\n\nLTL, CTL, CTL, MTL, MITL, TCTL, STL, …"
  },
  {
    "objectID": "verification_software.html",
    "href": "verification_software.html",
    "title": "Software",
    "section": "",
    "text": "Multiparametric Toolbox (MPT): https://www.mpt3.org\n\nSome functionality (invariant set computation) purely for discrete-time systems\n\nCORA: https://tumcps.github.io/CORA/\n\nSupports also continuous-time systems, and not only linear but also nonlinear and hybrid ones.\n\n\nQuite a few other tools can be found on the web but mostly unmaintained.\n\n\n\n\nReachabilityAnalysis.jl: https://juliareach.github.io/ReachabilityAnalysis.jl/\n\n\n\n\n\nSorry, I am not aware of anything, but I will gladly add whatever you suggest. Just keep in mind that the tool should be actively maintained to be useful at least for study purposes.\n\n\n\n\n\nNo specialized software. At the moment just the same computational tools as for Lyapunov stability analysis – nonnegative (sum-of-squares) polynomial optimization, etc.\n\n\n\nMainly some experimental code accompanying research papers.\n\n\n\nSignalTemporalLogic.jl\n\n\n\n\n\n\n\n\nBreach toolbox for Matlab\nBeware that Matlab’s toolboxes such as Requirements Toolbox and Simulink Design Verifier mention some temporal logic and temporal operators, but they do not adhere to the syntax of STL.",
    "crumbs": [
      "12. Formal verification",
      "Software"
    ]
  },
  {
    "objectID": "verification_software.html#reachability-analysis",
    "href": "verification_software.html#reachability-analysis",
    "title": "Software",
    "section": "",
    "text": "Multiparametric Toolbox (MPT): https://www.mpt3.org\n\nSome functionality (invariant set computation) purely for discrete-time systems\n\nCORA: https://tumcps.github.io/CORA/\n\nSupports also continuous-time systems, and not only linear but also nonlinear and hybrid ones.\n\n\nQuite a few other tools can be found on the web but mostly unmaintained.\n\n\n\n\nReachabilityAnalysis.jl: https://juliareach.github.io/ReachabilityAnalysis.jl/\n\n\n\n\n\nSorry, I am not aware of anything, but I will gladly add whatever you suggest. Just keep in mind that the tool should be actively maintained to be useful at least for study purposes.\n\n\n\n\n\nNo specialized software. At the moment just the same computational tools as for Lyapunov stability analysis – nonnegative (sum-of-squares) polynomial optimization, etc.\n\n\n\nMainly some experimental code accompanying research papers.\n\n\n\nSignalTemporalLogic.jl\n\n\n\n\n\n\n\n\nBreach toolbox for Matlab\nBeware that Matlab’s toolboxes such as Requirements Toolbox and Simulink Design Verifier mention some temporal logic and temporal operators, but they do not adhere to the syntax of STL.",
    "crumbs": [
      "12. Formal verification",
      "Software"
    ]
  },
  {
    "objectID": "max_plus_references.html",
    "href": "max_plus_references.html",
    "title": "Literature",
    "section": "",
    "text": "One last time in this course we refer to [1], a comprehensive and popular introduction do discrete event systems. A short introduction to the framework (max,+) algebra can be found (under the somewhat less known name “Dioid algebras”) in Chapter 5.4.\nBut as a recommendable alternative, (any one of) the a series of papers by Bart de Schutter (TU Delft) and his colleagues can be read instead. For example [2] and [3].\nFor anyone interested in learning yet more, a beautiful (and freely online) book is [4], which we have also mentioned in the context of Petri nets.\nMax-plus algebra is relevant outside the domain of discrete-event systems – it is also investigated in optimization for its connection with piecewise linear/affine functions. Note that the community prefers using the name tropical geometry (to emphasise that they view it as a branch of algebraic geometry). A lovely tutorial is [5].\n\n\n\n\n Back to topReferences\n\n[1] C. G. Cassandras and S. Lafortune, Introduction to Discrete Event Systems, 3rd ed. Cham: Springer, 2021. Available: https://doi.org/10.1007/978-3-030-72274-6\n\n\n[2] B. De Schutter, T. van den Boom, J. Xu, and S. S. Farahani, “Analysis and control of max-plus linear discrete-event systems: An introduction,” Discrete Event Dynamic Systems, vol. 30, no. 1, pp. 25–54, Mar. 2020, doi: 10.1007/s10626-019-00294-w.\n\n\n[3] B. De Schutter and T. van den Boom, “Model predictive control for max-plus-linear discrete-event systems: Extended report & Addendum,” Delft University of Technology, Delft, The Netherlands, Technical Report bds:99-10a, Nov. 2000. Available: https://pub.deschutter.info/abs/99_10a.html\n\n\n[4] F. Baccelli, G. Cohen, G. J. Olsder, and J.-P. Quadrat, Synchronization and linearity: An algebra for discrete event systems, Web edition. Chichester: Wiley, 2001. Available: https://www.rocq.inria.fr/metalau/cohen/documents/BCOQ-book.pdf\n\n\n[5] J. Rau, “A First Expedition to Tropical Geometry,” Apr. 2017. Available: https://www.math.uni-tuebingen.de/user/jora/downloads/FirstExpedition.pdf",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Literature"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html",
    "href": "verification_temporal_logics.html",
    "title": "Temporal logics",
    "section": "",
    "text": "It is natural to invoke the standard (propositional) logic when defining whatever requirements – we require that “if this and that conditions are satisfied, then yet another condition must not hold”, and so on.\nHowever, the spectrum of requirements expressed with propositional logic is not rich enough when specifying requirements for discrete-event and hybrid systems whose states evolve causally in time. Temporal logics add some more expressiveness.\nBefore listing the most common temporal logics, we introduce the key temporal operators that are going to be used together with logical operators for form temporal formulas.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html#temporal-operators",
    "href": "verification_temporal_logics.html#temporal-operators",
    "title": "Temporal logics",
    "section": "Temporal operators",
    "text": "Temporal operators\nThe name might be misleading here – the adjective temporal has nothing to do with time as measured by the wall clock. Their basic versions have been developed for discrete-event systems, and as state trajectories of these form sequencies, temporal operators refer to sequences.\nBasic temporal operators that we are going to introduce can be extended so that they also refer to the wall-clock time. But we will only mention these extensions after introducing the basics.\n\nExample 1 (Insufficiency of propositional logic to express requirements on a traffic light controller) Consider the state automaton for a controller for two traffic lights (but note that we intentionally simplify here a lot compared to real traffic light controllers). The state trajectory for each light is a sequence of color states \\{\\text{green}, \\text{yellow}, \\text{red}, \\text{red-yellow}\\} of the traffic light. We may want to impose a requirement such that \\text{green} is never on at both lights at the same time. This we can easily express just with the standard logical operators, namely, \\neg(\\text{green}_1 \\land \\text{green}_2). But now consider that we require that sooner or later, \\text{green} must be on for each light (to guarantee fairness). And that this must be true all the time, that is, \\text{green} must come infinitely often. And, furthermore, that \\text{red} cannot come imediately after its respective \\text{green}.\n\nRequirements like these cannot be expressed with standard logical operators such as \\lnot, \\land, \\lor, \\implies and \\iff, and temporal operators must be introduced. Here they are.\n\nTemporal operators\n\n\n\n\n\n\n\nSymbol\nAlternative symbol\nMeaning\n\n\n\n\n\\mathbf{F}\n\\Diamond\nEventually (Finally)\n\n\n\\mathbf{G}\n\\Box\nGlobally (Always)\n\n\n\\mathbf{X}\n\\bigcirc\nNeXt\n\n\n\\mathbf{U}\n\\sqcup (also \\mathcal{U})\nUntill\n\n\n\\mathbf{R}\n\\sqcap (also \\mathcal{R})\nRelease\n\n\n\\mathbf{W}\n\\mathcal{W}\nWeak Untill\n\n\n\\mathbf{M}\n\\mathcal{M}\nMighty (strong) Release\n\n\n\nWe are going to explain their use while introducing our first temporal logic.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html#linear-temporal-logic-ltl",
    "href": "verification_temporal_logics.html#linear-temporal-logic-ltl",
    "title": "Temporal logics",
    "section": "Linear temporal logic (LTL)",
    "text": "Linear temporal logic (LTL)\n“Linear” refers to linearity in time (one after another, as opposed to branching). Consider a sequence of discrete states (aka state trajectory or path) x_0, x_1, x_2, \\ldots of a given discrete-event or hybrid system that is initiated at some state x_0. Now, referring to the concept of a Labelled Transition System (LTS), each state is labelled by a some atomic proposition(s) that is (are) true in this state. For simplicity, say, there is just one such boolean label p(x). Instead of a sequence of states, of sequence of the values of the label function can be considered. Say, false, false, true, false, false … Graphically, we can represent this sequence as in Fig. 1, where the filled circle corresponds to true.\n\n\n\n\n\n\n\n\npath\n\n\n\nx0\n\nx0\n\n\n\nx1\n\nx1\n\n\n\nx0-&gt;x1\n\n\n\n\n\nx2\n\nx2\n\n\n\nx1-&gt;x2\n\n\n\n\n\nx3\n\nx3\n\n\n\nx2-&gt;x3\n\n\n\n\n\nx4\n\nx4\n\n\n\nx3-&gt;x4\n\n\n\n\n\n\nx4-&gt;x5\n\n\n\n\n\n\n\n\nFigure 1: Graphical representation of a sequence of Boolean labels attached to the discrete states\n\n\n\n\n\nWe now consider some property of the whole discrete state trajectory expressed by a Boolean formula \\phi (as such it evaluates to true or false).\nHow do we express such property formula \\phi? In order to be able to express requirements on future states, \\phi cannot be just a (proposional) logic formula, it must by a Linear Temporal Logic (LTL) formula. Here comes a formal definition (using recursion): \\boxed{\n\\phi = \\text{true} \\, | \\, p \\, | \\, \\neg \\phi_1 \\, | \\, \\phi_1 \\land \\phi_2 \\, | \\, \\phi_1 \\lor \\phi_2 \\, | \\, \\bigcirc \\phi_1 \\, | \\, \\Diamond \\phi_1 \\, | \\, \\Box \\phi_1 | \\, \\phi_1 \\sqcup \\phi_2, \\, \\phi_1 \\sqcap \\phi_2}\n where p is an atomic formula, and \\phi_1 and \\phi_2 are some LTL sub-formulas.\nThe trajectory will be identified by its initial x, we write that a state sequence initiated at the given discrete state x satisfies the formula as \\boxed{\nx \\models \\phi.}\n\nIt the initial state x does not determine the trajectory uniquely, the above is then interpreted as “for all trajectories initiated at x”.\n\nVisualisation of some basic LTL formulas\n\n\n\nx \\models \\Box p\n●──→●──→●──→●──→●──→●──→●┄┄→\n\n\nx \\models \\Diamond p\n○──→○──→○──→○──→○──→●──→○┄┄→\n\n\nx \\models \\bigcirc p\n○──→●──→○──→○──→○──→○──→○┄┄→\n\n\nx \\models p_1 \\sqcup p_2\n●──→●──→●──→■──→○──→○──→○┄┄→\n\n\nx \\models p_1 \\sqcap p_2\n■──→■──→■──→■●──→○──→○──→○┄┄→\n\n\n\nThe last two examples (lines) use actually two atomic formulas p_1 and p_2, satisfaction of the former is visualized by a filled circle and the latter by a square, satisfaction of both by displaying both next to each other.\nThe difference between the Untill and Weak Untill is that for the former it is guaranteed that p_2 will eventually hold, while for the latter it is not. Similarly, the difference between Release and Mighty Release is that for the latter it is guaranteed that p_1 will eventually hold. In this regard, Mighty Release is dual to the (strong) Untill.\n\n\n\n\n\n\nRedundancy in the enumerated temporal operators\n\n\n\nThere is some redundancy in the set of the temporal operators. For example, \\Diamond \\phi \\equiv \\text{true} \\sqcup \\phi. But there is no advantage in going with just the minimal set of temporal operators.\n\n\n\nExample 2 (Some nontrivial LTL formulas) Here we consider some requirements expressed by notrivial LTL formulas.\n\n\n\n\n\n\n\nx\\models \\Box \\neg p\n○──→○──→○──→○──→○──→○──→○┄┄→\n\n\nx \\models \\Box\\Diamond p\n○──→○──→●──→○──→○──→●──→○┄┄→\n\n\nx \\models \\Diamond\\Box p\n○──→○──→○──→○──→●──→●──→●┄┄→\n\n\nx \\models \\Diamond(p_1 \\land \\bigcirc\\Diamond p_2)\n○──→○──→○──→○──→●──→○──→■┄┄→\n\n\n\n\nWe have mentioned at the beginning of this whole chapter on verification that a special kind of a requirement is that of a safety – something bad (say, a collision) must never happen. How do we express it using an LTL formula?\n\n\\Box \\neg \\text{collision}\n\nWe have also mentioned that alternatively this can be expressed as a invariance property – something good must always hold. How do we express it using an LTL formula?\nFinally, another type of a common requirement is that of stability – something good must eventually happend and then it must hold forever. How do we express it using an LTL formula?\n\n\n\n\n\n\nProperty Specification Language (PSL)\n\n\n\nExtension of the basic LTL tailored to hardware specification has been standardized as IEEE Standard for Property Specification Language (PSL). It adds some syntactic sugar and supports regular expressions.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html#computation-tree-logic-ctl",
    "href": "verification_temporal_logics.html#computation-tree-logic-ctl",
    "title": "Temporal logics",
    "section": "Computation tree logic (CTL)",
    "text": "Computation tree logic (CTL)\nAnother temporal logic is known as computation tree logic (CTL), it is sometimes known as branching temporal logic as it supports branching of state trajectories.\nObviously, instead of just a path graph, here we model the evolution of the system using a tree graph as in Fig. 2.\n\n\n\n\n\n\nFigure 2: Tree graph\n\n\n\nIn order to express requirements that must be satisfied by the tree, path quantifiers are needed. They are listed in Table 1.\n\n\n\nTable 1: Path quantifiers\n\n\n\n\n\n\n\n\n\n\nSymbol\nAlternative symbol\nMeaning\n\n\n\n\n\\mathbf{A}\n\\forall\nUniversal quantifier (for All)\n\n\n\\mathbf{E}\n\\exists\nExistential quantifier (there Exists)\n\n\n\n\n\n\n\nBasic CTL formulas\n\n\n\n\n\n\n\n\nCTL formula\nGraphical description\nInterpretation\n\n\n\n\n\\forall \\Box \\phi\n\nFor all paths, \\phi must hold always.\n\n\n\\exists \\Box \\phi\n\nThere exists a path such that \\phi always holds.\n\n\n\\forall \\Diamond \\phi\n\nFor all paths, \\phi must hold eventually.\n\n\n\\exists \\Diamond \\phi\n\nThere exists a path such that \\phi holds eventually.\n\n\n\nTemporal operators and path quantifiers always come in pairs when forming CTL formulas. For example, \\forall \\Diamond \\Box \\phi is not a valid CTL formula.\n\nExample 3 (Some nontrivial CTL formulas and their interpretations)  \n\n\n\n\n\n\n\n\n\\forall \\Box \\neg \\text{collision}\nSafety Property\nFor all possible paths and all times, a collision will never occur.\n\n\n\\exists \\Diamond \\text{goal}\nLiveness Property\nThere exists some path along which the system will eventually reach the goal state.\n\n\n\\forall \\Box (\\text{request} \\implies \\forall \\Diamond \\text{grant})\nResponse Property (Cause-Effect)\nFor all possible paths and all times, if a request occurs, it is guaranteed that eventually a grant will follow.\n\n\n\\forall \\Box (\\neg (P_1 \\land P_2))\nMutual Exclusion Property\nFor all paths and times, the two processes P1 and P2 are not in their critical sections simultaneously.\n\n\n\\forall \\Box (\\text{enabled}\\implies \\forall\\Diamond \\text{executed})\nFairness Property\nIf an action becomes enabled, it will be eventually executed, whichever path is taken.\n\n\n\\forall \\Box (\\text{condition} \\implies \\exists \\Diamond (\\exists \\Box \\text{safe}))\nNested Temporal Properties\nFor all states globally, if a condition holds, then there exists a path where eventually the system will enter a state from which it can always stay in safe states.\n\n\n\\forall \\Box (\\neg \\text{error} \\land (\\exists \\Diamond \\text{goal}))\nCombined Safety and Liveness\nIt is always true globally that the system avoids an error state and guarantees that a goal state can eventually be reached.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html#ctl",
    "href": "verification_temporal_logics.html#ctl",
    "title": "Temporal logics",
    "section": "CTL*",
    "text": "CTL*\nA combination of CTL and LTL is known as CTL*. In particular, the restriction that temporal operators and path quantifiers must come in pairs, which is imposed in CTL, is relaxed. The expressive power is best. But it comes at cost – verification of the formulas is more difficult.\n\nExample 4 (Some examples of CTL*) Having state above, that \\forall \\Diamond \\Box \\phi is not a valid CTL formula, it is a valid CTL* formula. But \\forall \\Diamond \\forall \\Box \\phi is a valid CTL formula. These two are not equivalent. Investigating the difference between the two shows that CTL* is indeed more expressive than CTL.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html#probabilistic-ctl-pctl-and-continuous-stochastic-logic-csl",
    "href": "verification_temporal_logics.html#probabilistic-ctl-pctl-and-continuous-stochastic-logic-csl",
    "title": "Temporal logics",
    "section": "Probabilistic CTL (PCTL) and Continuous stochastic logic (CSL)",
    "text": "Probabilistic CTL (PCTL) and Continuous stochastic logic (CSL)\nProbability added.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html#timed-computation-tree-logic-tctl",
    "href": "verification_temporal_logics.html#timed-computation-tree-logic-tctl",
    "title": "Temporal logics",
    "section": "Timed computation tree logic (TCTL)",
    "text": "Timed computation tree logic (TCTL)\n“Dense” time added to CTL. Used by UPPAAL.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html#metric-temporal-logic-mtl-and-metric-interval-temporal-logic-mitl",
    "href": "verification_temporal_logics.html#metric-temporal-logic-mtl-and-metric-interval-temporal-logic-mitl",
    "title": "Temporal logics",
    "section": "Metric temporal logic (MTL) and Metric interval temporal logic (MITL)",
    "text": "Metric temporal logic (MTL) and Metric interval temporal logic (MITL)\nDense time added to LTL.\n\nExample 5 \n\\square (\\mathrm{pressWalkButton} \\Rightarrow \\Diamond_{(1,10)} \\mathrm{greenLight})\n\n\nMITL does not allow singleton time intervals allowed by MTL. The motivation for this extension is that the verification of MTL requirements has been shown to be undecidable.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "verification_temporal_logics.html#signal-temporal-logic-stl",
    "href": "verification_temporal_logics.html#signal-temporal-logic-stl",
    "title": "Temporal logics",
    "section": "Signal temporal logic (STL)",
    "text": "Signal temporal logic (STL)\nLast but not least, STL is an extension of MITL towards continuous and hybrid systems. It also supports the continuous (aka dense) time, and furthermore it replaces the proposional logic with the predicate logic as it allows inequalities with real variables to play the role of atomic propositions. It is available for both continuous- and discrete-time systems.\n\nExample 6 (Examples of STL formulas) \n\\square \\neg(x(t) &gt; 10.0)\n\n\n\\square (x(t) \\leq 5.5 \\Rightarrow \\Diamond_{(1,10)} \\mathrm{greenLight})\n \n\\Diamond_{(0,60)}\\square_{(0,20)} (x(t)\\leq 5.5)\n \n\\square\\Diamond_{[0,10]} (\\bm x(t) \\in \\mathcal A) \\land \\square\\Diamond_{[0,10]} (\\bm x(t) \\in \\mathcal B)\n\n\nIt allows combinations of surveillance (“visit regions A, B, and C every 10–60 s”), safety (“always between 5–25 s stay at least 1 m away from D”), and many others.\n\nRobustness degree in STL\nIt turns out that if we only learn that the STL formula has been satisfied, it is not clear the corresponding constraint has been satisfied with quite some margin or just so so. This is compensated for by introducing a robustness degree. See the literature for more.\n\n\nMonitoring, run-time verification\nLTL and CTL logics (a bit less so CTL* and significantly less so MITL) lend themselves for some rigorous symbolic (fully exhaustive) verification (model checking) techniques with known complexities. In contrast, there are no such general techniques for STL. Instead, verification of STL formulas for the whole system must then be approached by evaluating them on individual trajectories (called monitoring) obtained either by simulation, running tests or obtaining operational data. The outcomes from several trajectories are then processesed statistically in Monte-Carlo style. This is known as simulation-based or run-time verification.",
    "crumbs": [
      "12. Formal verification",
      "Temporal logics"
    ]
  },
  {
    "objectID": "complementarity_software.html",
    "href": "complementarity_software.html",
    "title": "Software",
    "section": "",
    "text": "Surprisingly, there are not many software packages that can handle complementarity constraints directly.\n\nWithin the realm of free software, I am only aware of PATH solver. Well, it is not open source and it is not issued under any classical free and open source license. It can be interfaced from Matlab and Julia (and AMPL and GAMS, which are not relevant for our course). For Matlab, compiled mexfiles can be downloaded. For Julia, the solver can be interfaced directly from the popular JuMP package (choosing the PATHSolver.jl solver), see the section on Complementarity constraints and Mixed complementarity problems in JuMP manual.\n\nWhen restricted to Matlab, there are several options, all of them commercial:\n\nOptimization Toolbox for Matlab does not offer a specialized solver for complementarity problems. The fmincon function can only handle it as a general nonlinear constraint g_1(x)g_2(x)=0, \\, g_1(x) \\geq 0, \\, g_2(x) \\geq 0.\nTomlab toolbox has some support for complementarity constraints.\nKnitro solver (by Artelys) has some support for complementarity constraints.\nYALMIP toolbox supports definining the complementarity constraints through the command complements: F = complements(w &gt;= 0, z &gt;= 0). By default, it converts the problem into the format suitable for a mixed-integer solver. If Knitro is available, it can be interfaced.\n\nGurobi does not seem to support complementarity constraints.\nMosek supports disjunctive constraints, within which complementarity constraints can be formulated. But they are then approached using a mixed-integer solver.",
    "crumbs": [
      "9. Complementarity systems",
      "Software"
    ]
  },
  {
    "objectID": "complementarity_software.html#solving-optimization-problems-with-complementarity-constraints",
    "href": "complementarity_software.html#solving-optimization-problems-with-complementarity-constraints",
    "title": "Software",
    "section": "",
    "text": "Surprisingly, there are not many software packages that can handle complementarity constraints directly.\n\nWithin the realm of free software, I am only aware of PATH solver. Well, it is not open source and it is not issued under any classical free and open source license. It can be interfaced from Matlab and Julia (and AMPL and GAMS, which are not relevant for our course). For Matlab, compiled mexfiles can be downloaded. For Julia, the solver can be interfaced directly from the popular JuMP package (choosing the PATHSolver.jl solver), see the section on Complementarity constraints and Mixed complementarity problems in JuMP manual.\n\nWhen restricted to Matlab, there are several options, all of them commercial:\n\nOptimization Toolbox for Matlab does not offer a specialized solver for complementarity problems. The fmincon function can only handle it as a general nonlinear constraint g_1(x)g_2(x)=0, \\, g_1(x) \\geq 0, \\, g_2(x) \\geq 0.\nTomlab toolbox has some support for complementarity constraints.\nKnitro solver (by Artelys) has some support for complementarity constraints.\nYALMIP toolbox supports definining the complementarity constraints through the command complements: F = complements(w &gt;= 0, z &gt;= 0). By default, it converts the problem into the format suitable for a mixed-integer solver. If Knitro is available, it can be interfaced.\n\nGurobi does not seem to support complementarity constraints.\nMosek supports disjunctive constraints, within which complementarity constraints can be formulated. But they are then approached using a mixed-integer solver.",
    "crumbs": [
      "9. Complementarity systems",
      "Software"
    ]
  },
  {
    "objectID": "complementarity_software.html#modeling-and-simulation-of-dynamical-systems-with-complementarity-constraints",
    "href": "complementarity_software.html#modeling-and-simulation-of-dynamical-systems-with-complementarity-constraints",
    "title": "Software",
    "section": "Modeling and simulation of dynamical systems with complementarity constraints",
    "text": "Modeling and simulation of dynamical systems with complementarity constraints\nWithin the modeling and simulation domains, there are two free and open source libraries that can handle complementarity constraints, mainly motivated by nonsmooth dynamical systems:\n\nSICONOS\n\nC++, Python\nphysical domain independent\n\nPINOCCHIO\n\nC++, Python\nspecialized for robotics",
    "crumbs": [
      "9. Complementarity systems",
      "Software"
    ]
  },
  {
    "objectID": "classes_PWA.html",
    "href": "classes_PWA.html",
    "title": "Piecewise affine (PWA) systems",
    "section": "",
    "text": "This is a subclass of switched systems where the functions on the right-hand side of the differential equations are affine functions of the state. For some (historical) reason these systems are also called piecewise linear (PWL).\nWe are going to reformulate such systems as switched systems with state-driven switching.\nFirst, we consider the autonomous case, that is, systems without inputs: \n\\dot{\\bm x}\n=\n\\begin{cases}\n\\bm A_1 \\bm x + \\bm b_1, & \\mathrm{if}\\, \\bm H_1 \\bm x + \\bm g_1 \\leq 0,\\\\\n\\vdots\\\\\n\\bm A_m \\bm x + \\bm b_m, & \\mathrm{if}\\, \\bm H_m \\bm x + \\bm g_m \\leq 0.\n\\end{cases}\nThe nonautonomous case of systems with inputs is then: \n\\dot{\\bm x}\n=\n\\begin{cases}\n\\bm A_1 \\bm x + \\bm B_1 u + \\bm c_1, & \\mathrm{if}\\, \\bm H_1 \\bm x + \\bm g_1 \\leq 0,\\\\\n\\vdots\\\\\n\\bm A_m \\bm x + \\bm B_m + \\bm c_m, & \\mathrm{if}\\, \\bm H_m \\bm x + \\bm g_m \\leq 0.\n\\end{cases}",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Piecewise affine (PWA) systems"
    ]
  },
  {
    "objectID": "classes_PWA.html#approximation-of-nonlinear-systems",
    "href": "classes_PWA.html#approximation-of-nonlinear-systems",
    "title": "Piecewise affine (PWA) systems",
    "section": "Approximation of nonlinear systems",
    "text": "Approximation of nonlinear systems\nWhile the example with the saturated linear state feedback can be modelled as a PWA system exactly, there are many practical cases, in which the system is not exactly PWA affine but we want to approximate it as such.\n\nExample 2 (Nonlinear system approximated by a PWA system) Consider the following nonlinear system \n\\begin{bmatrix}\n\\dot x_1\\\\\\dot x_2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nx_2\\\\\n-x_2 |x_2| - x_1 (1+x_1^2)\n\\end{bmatrix}\n\nOur task is to approximate this system by a PWA system. Equivalently, we need to find a PWA approximation for the right-hand side function.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Piecewise affine (PWA) systems"
    ]
  },
  {
    "objectID": "complementarity_simulations.html",
    "href": "complementarity_simulations.html",
    "title": "Simulations of complementarity systems using time-stepping",
    "section": "",
    "text": "One of the useful outcomes of the theory of complementarity systems is a new family of methods for numerical simulation of discontinuous systems. Here we will demonstrate the essence by introducing the method of time-stepping. And we do it by means of an example.\n\nExample 1 (Simulation using time-stepping) Consider the following discontinuous dynamical system in \\mathbb R^2: \n\\begin{aligned}\n\\dot x_1 &= -\\operatorname{sign} x_1 + 2 \\operatorname{sign} x_2\\\\\n\\dot x_2 &= -2\\operatorname{sign} x_1 -\\operatorname{sign} x_2.\n\\end{aligned}\n\nThe state portrait is in Fig. 1.\n\n\nShow the code\nf₁(x) = -sign(x[1]) + 2*sign(x[2])\nf₂(x) = -2*sign(x[1]) - sign(x[2])\nf(x) = [f₁(x), f₂(x)]\n\nusing CairoMakie\nfig = Figure(size = (800, 800),fontsize=20)\nax = Axis(fig[1, 1], xlabel = \"x₁\", ylabel = \"x₂\")\nstreamplot!(ax,(x₁,x₂)-&gt;Point2f(f([x₁,x₂])), -2.0..2.0, -2.0..2.0, colormap = :magma)\nfig\n\n\n\n\n\n\n\n\nFigure 1: State portrait of the discontinuous system\n\n\n\n\n\nOne particular (vector) state trajectory obtained by some default ODE solver is in Fig. 2.\n\n\nShow the code\nusing DifferentialEquations\n\nfunction f!(dx,x,p,t)\n    dx[1] = -sign(x[1]) + 2*sign(x[2])\n    dx[2] = -2*sign(x[1]) - sign(x[2])\nend\n\nx0 = [-1.0, 1.0]\ntfinal = 2.0\ntspan = (0.0,tfinal)\nprob = ODEProblem(f!,x0,tspan)\nsol = solve(prob)\n\nusing Plots\nPlots.plot(sol,xlabel=\"t\",ylabel=\"x\",label=false,lw=3)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Trajectory of the discontinuous system\n\n\n\n\nWe can also plot the trajectory in the state space, as in Fig. 3.\n\n\nShow the code\nPlots.plot(sol[1,:],sol[2,:],xlabel=\"x₁\",ylabel=\"x₂\",label=false,aspect_ratio=:equal,lw=3,xlims=(-1.2,0.5))\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Trajectory of the discontinuous system in the state space\n\n\n\n\nNote that for the default setting of absolute and relative tolerances, the adaptive-step ODE solver actually needed a huge number of steps:\n\n\nShow the code\nlength(sol.t)\n\n\n288594\n\n\nThis is indeed quite a lot. Can we do better?\nIn this particular example, we have the benefit of being able to analyze the solution analytically. In particular, we can ask: how fast does the solution approach the origin? We turn this into a question of how fast the distance from the origin decreases. With some anticipation we use the 1-norm \\|\\bm x\\|_1 = |x_1| + |x_2| to the distance of the state from the origin. We then ask: \n\\frac{\\mathrm d}{\\mathrm dt}\\|\\bm x\\|_1 = ?\n\nWe avoid the troubles with nonsmoothness of the absolute value by considering each quadrant separately. Let’s start in the first (upper right) quadrant, that is, x_1&gt;0 and x_2&gt;0, from which it follows that |x_1| = x_1, \\;|x_2| = x_2, and therefore \n\\frac{\\mathrm d}{\\mathrm dt}\\|\\bm x\\|_1 = \\dot x_1 + \\dot x_2 = 1 - 3 = -2.\n\nThe situation is identical in the other quadrants. We do not worry that the norm is undefined on the axes, because the trajectory obviously just crosses them.\nThe conclusion is that the trajectory will hit the origin in finite time (!): with, say, x_1(0) = 1 and x_2(0) = 1, the trajectory hits the origin at t=(|x_1(0)|+|x_2(0)|)/2 = 1. Surprisingly (or not), this will happen after an infinite number of revolutions around the origin…\nWe have seen above in Fig. 2 that a default solver for ODE can handle the situation in a decent way. But we have also seen that this was at the cost of a huge number of steps. To get some insight, we implement our own solver.\n\nForward Euler with fixed step size\nWe start with the simplest of all methods, the forward Euler method with a fixed step length. The computation of the next state is done just by the assignment \n\\begin{aligned}\n{\\color{blue}x_{1,k+1}} &= x_{1,k} + h (-\\operatorname{sign} x_{1,k} + 2 \\operatorname{sign} x_{2,k})\\\\\n{\\color{blue}x_{2,k+1}} &= x_{2,k} + h (-2\\operatorname{sign} x_{1,k} - \\operatorname{sign} x_{2,k}).\n\\end{aligned}\n\n\n\n\n\n\n\nBlue color in our text is used to denote the unknown\n\n\n\nWe use the blue color here (and in the next few paragraphs) to highlight what is uknown.\n\n\n\n\nShow the code\nf(x) = [-sign(x[1]) + 2*sign(x[2]), -2*sign(x[1]) - sign(x[2])]\n\nusing LinearAlgebra\nN = 1000\nx₀ = [-1.0, 1.0]    \nx = [x₀]\ntfinal = norm(x₀,1)/2\ntfinal = 5.0\nh = tfinal/N \nt = range(0.0, step=h, stop=tfinal)\n\nfor i=1:N\n    xnext = x[i] + h*f(x[i]) \n    push!(x,xnext)\nend\n\nX = [getindex.(x, i) for i in 1:length(x[1])]\n\nPlots.plot(t,X,lw=3,label=false,xlabel=\"t\",ylabel=\"x\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Solution trajectory for a discontinuous system obtained by the forward Euler method\n\n\n\n\nThen number of steps is\n\n\nShow the code\nlength(t)\n\n\n1001\n\n\nwhich is significantly less than before, but the solution is not perfect – notice the chattering. It could be reduced by using a smaller step size, but again, at the cost of a longer simulation time.\n\n\nBackward Euler\nAs an alternative to the forward Euler method, we can use the backward Euler method. The computation of the next state is done by solving the nonlinear equations \n\\begin{aligned}\n{\\color{blue} x_{1,k+1}} &= x_{1,k} + h (-\\operatorname{sign} {\\color{blue}x_{1,k+1}} + 2 \\operatorname{sign} {\\color{blue}x_{2,k+1}})\\\\\n{\\color{blue} x_{2,k+1}} &= x_{2,k} + h (-2\\operatorname{sign} {\\color{blue}x_{1,k+1}} - \\operatorname{sign} {\\color{blue}x_{2,k+1}}).\n\\end{aligned}\n\nThe discontinuities on the right-hand sides constitute a challenge for solvers of nonlinear equations – recall that the Newton’s method requires the first derivatives (assembled into the Jacobian) or their approximation. Instead of this struggle, we can use the linear complementarity problem (LCP) formulation.\n\n\nFormulation of the backward Euler using LCP\nInstead solving the above nonlinear equations with discontinuities, we introduce new variables u_1 and u_2 as the outputs of the \\operatorname{sign} functions: \n\\begin{aligned}\n{\\color{blue} x_{1,k+1}} &= x_{1,k} + h (-{\\color{blue}u_{1}} + 2 {\\color{blue}u_{2}})\\\\\n{\\color{blue} x_{2,k+1}} &= x_{2,k} + h (-2{\\color{blue}u_{1}} - {\\color{blue}u_{2}}).\n\\end{aligned}\n\nBut now we have to enforce the relationship between \\bm u and \\bm x_{k+1}. Recall the standard definition of the \\operatorname{sign} function is \n\\operatorname{sign}(x) = \\begin{cases}\n1 & x&gt;0\\\\\n0 & x=0\\\\\n-1 & x&lt;0,\n\\end{cases}\n but we change the definition to a set-valued function \n\\begin{cases}\n\\operatorname{sign}(x) = 1 & x&gt;0\\\\\n\\operatorname{sign}(x) \\in [-1,1] & x=0\\\\\n\\operatorname{sign}(x) = -1 & x&lt;0.\n\\end{cases}\n\nAccordingly, we set the relationship between \\bm u and \\bm x to \n\\begin{cases}\nu_1 = 1 & x_1&gt;0\\\\\nu_1 \\in [-1,1] & x_1=0\\\\\nu_1 = -1 & x_1&lt;0,\n\\end{cases}\n and \n\\begin{cases}\nu_2 = 1 & x_2&gt;0\\\\\nu_2 \\in [-1,1] & x_2=0\\\\\nu_2 = -1 & x_2&lt;0.\n\\end{cases}\n\nBut these are mixed complementarity contraints we have defined previously! We can thus write the single step of the simulation algorithm as the MCP \n\\boxed{\n\\begin{aligned}\n\\begin{bmatrix}\n{\\color{blue} x_{1,k+1}}\\\\\n{\\color{blue} x_{2,k+1}}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\nx_{1,k}\\\\\nx_{2,k}\n\\end{bmatrix} + h\n\\begin{bmatrix}\n-1 & 2 \\\\\n-2 & -1\n\\end{bmatrix}\n\\begin{bmatrix}\n{\\color{blue}u_{1}}\\\\\n{\\color{blue}u_{2}}\n\\end{bmatrix}\\\\\n-1 &\\leq {\\color{blue} u_1} \\leq 1 \\quad \\bot \\quad -{\\color{blue}x_{1,k+1}}\\\\\n-1 &\\leq {\\color{blue} u_2} \\leq 1 \\quad \\bot \\quad -{\\color{blue}x_{2,k+1}}.\n\\end{aligned}\n}\n\\tag{1}\nWe now have enough to start implementing a solver for this system, provided we have an access to a solver the MCP (see the page dedicated to software for complementarity problems). But before we do it, we analyze the problem a bit deeper. In this particular small and simple case, it is still doable with just a pencil and paper.\n\n\n9 possible combinations\nThere are now 9 possible combinations of the values of u_1 and u_2, each of them strictly inside their respective intervals, or at the either end. Let’s explore some combinations. We start with x_{1,k+1} = x_{2,k+1} = 0, while u_1 \\in [-1,1] and u_2 \\in [-1,1]:\n\n\\begin{aligned}\n\\begin{bmatrix}\n0\\\\\n0\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\nx_{1,k}\\\\\nx_{2,k}\n\\end{bmatrix} + h\n\\begin{bmatrix}\n-1 & 2 \\\\\n-2 & -1\n\\end{bmatrix}\n\\begin{bmatrix}\n{\\color{blue}u_{1}}\\\\\n{\\color{blue}u_{2}}\n\\end{bmatrix}\\\\\n& -1 \\leq {\\color{blue} u_1} \\leq 1,  \\quad -1 \\leq {\\color{blue} u_2} \\leq 1\n\\end{aligned}\n\nHow does the set of states from which the next state is zero look like? We isolate the vector \\bm u from the equation and impose the constraints on it: \n\\begin{aligned}\n-\\begin{bmatrix}\n-1 & 2 \\\\\n-2 & -1\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\nx_{1,k}\\\\\nx_{2,k}\n\\end{bmatrix}\n&= h\n\\begin{bmatrix}\n{\\color{blue}u_{1}}\\\\\n{\\color{blue}u_{2}}\n\\end{bmatrix}\\\\\n-1 \\leq {\\color{blue} u_1} \\leq 1,  \\quad -1 &\\leq {\\color{blue} u_2} \\leq 1\n\\end{aligned}\n\nWe then get \n\\begin{bmatrix}\n-h\\\\-h\n\\end{bmatrix}\n\\leq\n\\begin{bmatrix}\n0.2 & 0.4 \\\\\n-0.4 & 0.2\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1,k}\\\\\nx_{2,k}\n\\end{bmatrix}\n\\leq\n\\begin{bmatrix}\nh\\\\ h\n\\end{bmatrix}\n\nFor h=0.2, the resulting set is a rotated square, as shown in Fig. 5.\n\n\nShow the code\nusing LazySets\nh = 0.2\nH1u = HalfSpace([0.2, 0.4], h)\nH2u = HalfSpace([-0.4, 0.2], h)\nH1l = HalfSpace(-[0.2, 0.4], h)\nH2l = HalfSpace(-[-0.4, 0.2], h)\n\nHa = H1u ∩ H2u ∩ H1l ∩ H2l\n\nusing Plots\nPlots.plot(Ha, aspect_ratio=:equal,xlabel=\"x₁\",ylabel=\"x₂\",label=false,xlims=(-1.5,1.5),ylims=(-1.5,1.5))\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: The set of states from which the next state is zero (the origin)\n\n\n\n\nIndeed, if the current state is in this rotated square, then the next state will be zero. No more infite spiralling around the origin! No more chattering! Perfect zero.\n\n\nAnother combination\nWe now consider u_1 = 1, u_2 = 1, which we substitute into Eq. 1: \n\\begin{aligned}\n\\begin{bmatrix}\n{\\color{blue} x_{1,k+1}}\\\\\n{\\color{blue} x_{2,k+1}}\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\nx_{1,k}\\\\\nx_{2,k}\n\\end{bmatrix} + h\n\\begin{bmatrix}\n-1 & 2 \\\\\n-2 & -1\n\\end{bmatrix}\n\\begin{bmatrix}\n{1}\\\\\n{1}\n\\end{bmatrix}\\\\\n\\color{blue}x_{1,k+1} &\\geq 0\\\\\n\\color{blue}x_{2,k+1} &\\geq 0,\n\\end{aligned}\n which can be reformatted to \n\\begin{bmatrix}\nx_{1,k}\\\\\nx_{2,k}\n\\end{bmatrix} + h\n\\begin{bmatrix}\n-1 & 2 \\\\\n-2 & -1\n\\end{bmatrix}\n\\begin{bmatrix}\n1\\\\\n1\n\\end{bmatrix}\\geq \\bm 0,\n and further to \n\\begin{bmatrix}\nx_{1,k}\\\\\nx_{2,k}\n\\end{bmatrix}\n\\geq h\n\\begin{bmatrix}\n-1\\\\\n3\n\\end{bmatrix}.\n\nThe set of states for which the next state is such that both its state variables are positive (hence u_1 = 1, u_2 = 1) is shown in Fig. 6.\n\n\nShow the code\nusing LazySets\nh = 0.2\nA = [-1.0 2.0; -2.0 -1.0]\nu = [1.0, 1.0]\nb = h*A*u\n\nH1 = HalfSpace([-1.0, 0.0], b[1])\nH2 = HalfSpace([0.0, -1.0], b[2])\nHb = H1 ∩ H2\n\nusing Plots\nPlots.plot(Ha, aspect_ratio=:equal,xlabel=\"x₁\",ylabel=\"x₂\",label=false,xlims=(-1.5,1.5),ylims=(-1.5,1.5))\nPlots.plot!(Hb)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: The set of states from which the next state has both state variables positive\n\n\n\n\n\n\nAll nine regions\nWe plot all nine regions in Fig. 7. Note that we do not color them all – the white regions are to be counted as well.\n\n\nShow the code\nusing LazySets\nh = 0.2\nA = [-1.0 2.0; -2.0 -1.0]\n\nu = [1, -1]\nb = h*A*u\n\nH1 = HalfSpace(-[1.0, 0.0], b[1])\nH2 = HalfSpace([0.0, 1.0], -b[2])\nHc = H1 ∩ H2\n\nu = [-1, 1]\nb = h*A*u\n\nH1 = HalfSpace([1.0, 0.0], -b[1])\nH2 = HalfSpace(-[0.0, 1.0], b[2])\nHd = H1 ∩ H2\n\nu = [-1, -1]\nb = h*A*u\n\nH1 = HalfSpace([1.0, 0.0], -b[1])\nH2 = HalfSpace([0.0, 1.0], -b[2])\nHe = H1 ∩ H2\n\nusing Plots\nPlots.plot(Ha, aspect_ratio=:equal,xlabel=\"x₁\",ylabel=\"x₂\",label=false,xlims=(-1.5,1.5),ylims=(-1.5,1.5))\nPlots.plot!(Hb)\nPlots.plot!(Hc)\nPlots.plot!(Hd)\nPlots.plot!(He)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: The nine regions of the state space for the spiralling system\n\n\n\n\n\n\nSolutions using a MCP solver\nNow that we have got some insight into the algorithm, we can implement it by wrapping a for-loop around the MCP solver.\n\n\nShow the code\nM = [-1 2; -2 -1]\nh = 2e-1\ntfinal = 2.0\nN = tfinal/h\n\nx0 = [-1.0, 1.0]\nx = [x0]\n\nusing JuMP\nusing PATHSolver\n\nfor i = 1:N\n    model = Model(PATHSolver.Optimizer)\n    set_optimizer_attribute(model, \"output\", \"no\")\n    set_silent(model)\n    @variable(model, -1 &lt;= u[1:2] &lt;= 1)\n    @constraint(model, -h*M * u - x[end] ⟂ u)\n    optimize!(model)\n    push!(x, x[end]+h*M*value.(u))\nend\n\n\nThe code is admittedly unoptimized (for example, it is not wise to start building the optimization model from the scratch in every iteration), but it was our intention to keep it simple to be read conveniently.\nThe code outcome can be plotted as in Fig. 8. A solution obtained by a classical (default) ODE solver with default setting is plotted for comparison.\n\n\nShow the code\nt = range(0.0, step=h, stop=tfinal)\nX = [getindex.(x, i) for i in 1:length(x[1])]\n\nusing Plots\nPlots.plot(Ha, aspect_ratio=:equal,xlabel=\"x₁\",ylabel=\"x₂\",label=false,xlims=(-1.5,1.5),ylims=(-1.5,1.5))\nPlots.plot!(Hb)\nPlots.plot!(Hc)\nPlots.plot!(Hd)\nPlots.plot!(He)\nPlots.plot!(X[1],X[2],xlabel=\"x₁\",ylabel=\"x₂\",label=\"Time-stepping\",aspect_ratio=:equal,lw=3,markershape=:circle)\nPlots.plot!(sol[1,:],sol[2,:],label=false,lw=3)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Solution trajectory for a discontinuous system obtained by the MCP solver\n\n\n\n\nIt is worth emphasizing that once the solution trajectory hits the blue square, it is just one step from the origin. And once the solution trajectory reaches the origin, it stays there forever, no more spiralling, no more chattering.\nApparently, the chosen step length was too large. If we reduce it, the resulting trajectory resembles the one obtained by a default ODE solver, as shown in Fig. 9.\n\n\nShow the code\nM = [-1 2; -2 -1]\nh = 1e-2\ntfinal = 2.0\nN = tfinal/h\n\nx0 = [-1.0, 1.0]\nx = [x0]\n\nusing JuMP\nusing PATHSolver\n\nfor i = 1:N\n    model = Model(PATHSolver.Optimizer)\n    set_optimizer_attribute(model, \"output\", \"no\")\n    set_silent(model)\n    @variable(model, -1 &lt;= u[1:2] &lt;= 1)\n    @constraint(model, -h*M * u - x[end] ⟂ u)\n    optimize!(model)\n    push!(x, x[end]+h*M*value.(u))\nend\n\nt = range(0.0, step=h, stop=tfinal)\nX = [getindex.(x, i) for i in 1:length(x[1])]\n\nPlots.plot(X[1],X[2],xlabel=\"x₁\",ylabel=\"x₂\",label=\"Time-stepping\",aspect_ratio=:equal,lw=3,markershape=:circle)\nPlots.plot!(sol[1,:],sol[2,:],lw=3,label=\"Default ODE solver with adaptive step\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Solution trajectory for a discontinuous system obtained by the MCP solver with a smaller step size\n\n\n\n\nAnd yet the total number of steps is still much smaller:\n\n\nShow the code\nlength(t)\n\n\n201\n\n\n\n\n\nExample 2 (Time-stepping for a mechanical system with a hard stop) Let’s now apply the time-stepping method for a mechanical system with a hard stop as described in the Example 2 in the section on complementarity systems. We start by formulating the semi-explicit Euler scheme\n\n\\begin{aligned}\n\\bm x_{k+1} &= \\bm x_k + h \\bm v_{k+1}\\\\\n\\bm v_{k+1} &= \\bm v_k + h \\mathbf A \\bm x_{k} + h \\mathbf B \\bm u_k,\n\\end{aligned}\n where \n\\mathbf A = \\begin{bmatrix} -\\frac{k_1+k2}{m_1} & \\frac{k_2}{m_1}\\\\ \\frac{k_2}{m_2} & -\\frac{k_2}{m_2} \\end{bmatrix}, \\quad\n\\mathbf B = \\begin{bmatrix} \\frac{1}{m_1} & -\\frac{1}{m_1}\\\\ 0 & \\frac{1}{m_2} \\end{bmatrix}.\n\nSubstituting from the second to the first equation, we get \n{\\color{blue}\\bm x_{k+1}} = \\bm x_k + h \\bm v_k + h^2 \\mathbf A \\bm x_k + h^2 \\mathbf B {\\color{blue}\\bm u_k},\n in which we again highlight the unknown terms by blue color for convenience. These two vector unknowns must satisfy the following complementarity condition \n0 \\leq x_{1,k+1} \\perp u_{1,k} \\geq 0,\n and \n0 \\leq (x_{2,k+1} - x_{1,k+1}) \\perp u_{2,k} \\geq 0.\n\nThis can be written compactly as \n\\bm 0 \\leq \\mathbf C \\bm x_{k+1} \\perp \\bm u_{k} \\geq 0,\n where \\mathbf C is known from the previous section as \n\\mathbf C = \\begin{bmatrix}1 & 0\\\\ -1 & 1\\end{bmatrix}.\n\nThe constraint can be expanded into \n\\bm 0 \\leq \\mathbf C\\left(\\bm x_k + h \\bm v_k + h^2 \\mathbf A \\bm x_k + h^2 \\mathbf B {\\color{blue}\\bm u_k}\\right) \\perp \\bm u_{k} \\geq 0,\n which is an LCP problem with \\bm q = \\mathbf C\\left(\\bm x_k + h \\bm v_k + h^2 \\mathbf A \\bm x_k\\right) and \\mathbf M = h^2 \\mathbf C \\mathbf B.\nAn implementation of the time-stepping for this system is shown below.\n\n\nShow the code\nm1 = 1.0\nm2 = 1.0\nk1 = 1.0\nk2 = 1.0\n\nA = [-(k1+k2)/m1 k2/m1; k2/m2 -k2/m2]\nB = [1/m1 -1/m1; 0 1/m2]\nh = 1e-1\n\nx10 = 1.0\nx20 = 3.5\nv10 = 0.0\nv20 = 0.0\n\nx0 = [x10, x20] \nv0 = [v10, v20]\n\nx = [x0]\nv = [v0]\n\ntfinal = 10.0\nN = tfinal/h\n\nfor i = 1:N\n    model = Model(PATHSolver.Optimizer)\n    set_optimizer_attribute(model, \"output\", \"no\")\n    set_silent(model)\n    @variable(model, u[1:2] &gt;= 0)\n    @constraint(model, [1 0; -1 1]*(h^2*B*u + x[end] + h*v[end] + h^2*A*x[end]) ⟂ u)\n    optimize!(model) \n    push!(x, h^2*B*value.(u) + (x[end] + h*v[end] + h^2*A*x[end]))\n    push!(v, v[end] + h*A*x[end] + h*B*value.(u))\nend\n\nt = range(0.0, step=h, stop=tfinal)\nX = [getindex.(x, i) for i in 1:length(x[1])]\n\nPlots.plot(t,X[1],label=\"x₁\",lw=3,xlabel=\"t\",ylabel=\"Positions\",markershape=:circle)\nPlots.plot!(t,X[2],label=\"x₂\",lw=3,markershape=:circle)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote, once again, the amazingly small number of steps\n\n\nShow the code\nlength(t)\n\n\n101\n\n\nwhile the shape of the trajectory is already quite accurate (you can try reducing the step lenght by yourself)and whatever chattering is absent in the solution.\n\n\nExample 3 (Time stepping for a mechanical system with Coulomb friction modelled as complementarity constraints) We consider an object of mass m moving on a horizontal surface. The object is subject to an applied force F_\\mathrm{a} and a friction force F_\\mathrm{f}, both oriented in the positive direction of position and velocity, as in Fig. 10.\n\n\n\n\n\n\nFigure 10: Coulomb friction to be modelled using complementarity constraints\n\n\n\nThe friction force is modelled as a Coulomb friction model \nF_\\mathrm{f}(t) = -m g \\mu\\, \\mathrm{sgn}(v(t)),\n where \\mu is a coefficient that relates the frictional force to the normal force mg.\nThe motion equations are \n\\begin{aligned}\n\\dot x(t) &= v(t)\\\\\n\\dot v(t) &= \\frac{1}{m}(F_\\mathrm{a}(t) + F_\\mathrm{f}(t)).\n\\end{aligned}\n\nWe now express the friction force as a difference of two nonnegative variables \nF_\\mathrm{f}(t) = F^+_\\mathrm{f}(t) - F^-_\\mathrm{f}(t),\\quad F^+_\\mathrm{f}(t), \\,F^-_\\mathrm{f}(t) \\geq 0.\n\nAnd we also introduce another auxiliary variable \\nu(t) that is just the absolute value of the velocity \n\\nu(t) = |v(t)|.\n\nWith the three new variables we formulate the Coulomb friction model as \n\\begin{aligned}\n0 \\leq v + \\nu &\\perp F^+_\\mathrm{f} \\geq 0,\\\\\n0 \\leq -v + \\nu &\\perp F^-_\\mathrm{f} \\geq 0, \\\\\n0 \\leq \\mu m g - F^+_\\mathrm{f} - F^-_\\mathrm{f} &\\perp \\nu \\geq 0.\n\\end{aligned}\n\nIf F^-_\\mathrm{f} &gt; 0, that is, if the friction force is negative, the second complementarity constraint implies that the velocity is equal to its absolute value, in other words, it is nonnegative, the object moves to the right (or stays still). If the velocity is positive, the first constraint implies that F^+_\\mathrm{f} = 0, and the third constraint then implies that F^-_\\mathrm{f} = mg\\mu. Feel free to explore other cases.\nWe now proceed to implement the time-stepping method for this system. Once again, we use the semi-explicit Euler scheme \n\\begin{aligned}\nx_{k+1} &= x_k + h v_{k+1},\\\\\nv_{k+1} &= v_k + \\frac{h}{m} (F^+_{\\mathrm{f},k} - F^-_{\\mathrm{f},k}),\n\\end{aligned}\n where the velocity is subject to the complementarity constraints \n\\begin{aligned}\n0 \\leq v_{k+1} + \\nu_{k+1} &\\perp F^+_{\\mathrm{f},k} \\geq 0,\\\\\n0 \\leq -v_{k+1} + \\nu_{k+1} &\\perp F^-_{\\mathrm{f},k} \\geq 0, \\\\\n0 \\leq \\mu m g - F^+_{\\mathrm{f},k} - F^-_{\\mathrm{f},k} &\\perp \\nu_{k+1} \\geq 0,\n\\end{aligned}\n into which we substitute for v_{k+1} \\boxed{\n\\begin{aligned}\n0 \\leq v_k + \\frac{h}{m} ({\\color{blue}F^+_{\\mathrm{f},k}} - {\\color{blue}F^-_{\\mathrm{f},k}}) + {\\color{blue}\\nu_{k+1}}\\, &\\perp\\, {\\color{blue}F^+_{\\mathrm{f},k}} \\geq 0,\\\\\n0 \\leq -\\left(v_k + \\frac{h}{m} ({\\color{blue}F^+_{\\mathrm{f},k}} - {\\color{blue}F^-_{\\mathrm{f},k}})\\right) + {\\color{blue}\\nu_{k+1}}\\, &\\perp\\, {\\color{blue}F^-_{\\mathrm{f},k}} \\geq 0, \\\\\n0 \\leq \\mu m g - {\\color{blue}F^+_{\\mathrm{f},k}} - {\\color{blue}F^-_{\\mathrm{f},k}} \\,&\\perp\\, {\\color{blue}\\nu_{k+1}} \\geq 0,\n\\end{aligned}\n}\n in which we highlighted the unknowns by blue color for convenience.\n\n\nShow the code\nusing JuMP\nusing PATHSolver\nusing Plots\n\nm = 100.0\ng = 9.81\nμ = 10.0\n\nh = 2e-1\n\nx0 = 0.0\nv0 = 100.0\n\nx = [x0]\nv = [v0]\n\ntfinal = 5.0\nN = tfinal/h\n\nfor i = 1:N\n    model = Model(PATHSolver.Optimizer)\n    set_optimizer_attribute(model, \"output\", \"no\")\n    set_silent(model)\n    @variable(model, vabs &gt;= 0)\n    @variable(model, F⁺ &gt;= 0)\n    @variable(model, F⁻ &gt;= 0)\n    @constraint(model, (v[end] + h/m*(F⁺-F⁻) + vabs) ⟂ F⁺)\n    @constraint(model, (-(v[end] + h/m*(F⁺-F⁻)) + vabs) ⟂ F⁻)\n    @constraint(model, (μ*m*g - (F⁺+F⁻)) ⟂ vabs)\n    optimize!(model) \n    push!(v, v[end] + h/m*(value(F⁺)-value(F⁻)))\n    push!(x, x[end] + h*v[end])         # Here v[end] on the left already equals v_k+1\nend\n\nt = range(0.0, step=h, stop=tfinal)\nPlots.plot(t,v,label=\"v\",lw=3,markershape=:circle)\nPlots.plot!(t,x,label=\"x\",lw=3,markershape=:circle,xlabel=\"t\")\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOnce again, we can see that the method correctly simulates the system coming to a complete stop due to friction.\n\n\n\n\n\n\n\nImportant\n\n\n\nWhile concluding this section about time-stepping methods, we have to emphasize that this was really just an introduction. But the essence of using complementarity concepts in numerical simulation is perhaps a bit clearer now.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "9. Complementarity systems",
      "Simulations of complementarity systems using time-stepping"
    ]
  },
  {
    "objectID": "des.html",
    "href": "des.html",
    "title": "Discrete-event systems",
    "section": "",
    "text": "We have already mentioned that hybrid systems are composed of time-driven subsystems and event-driven subsystems. Assuming that the primary audience of this course are already familiar with the former (having been exposed to state equations and transfer function), here we are going to focus on the latter, also called discrete-event systems DES (or DEVS).",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Discrete-event systems"
    ]
  },
  {
    "objectID": "des.html#discrete-event",
    "href": "des.html#discrete-event",
    "title": "Discrete-event systems",
    "section": "(Discrete) event",
    "text": "(Discrete) event\nWe need to start with the definition of an event. Sometimes an adjective discrete is added (to get discrete event), although it appears rather redundant.\nThe primary characteristic of an event is instantaneous occurence, that is, an event takes no time.\nWithin the context of systems, an event is associated with a change of state – transition of the system from one state to another. Between two events, the systems remains in the same state, it doesn’t evolve.\n\n\n\n\n\n\nThe concept of a state\n\n\n\nTrue, here we are making a reference to the concept of a state, which we haven’t defined yet. But we can surely rely on understanding this concept developed by studying the time-driven systems (modelled by state equations).\n\n\nAlthough it is not instrumental in defining the event, the state space is frequently assumed discrete (even if infinite).\n\nExample 1 (DES state trajectory) In the figure below we can see an example state trajectory of a discrete-event system corresponding to a particular sequence of events.\n\n\n\n\n\n\nFigure 1: Example of a state trajectory in response to a sequence of events\n\n\n\nIt is perhaps worth emphasizing that the state space is not necessarily equidistantly discretized.\nAlso note that for some events no transitions occur (e_3 at t_3).\n\n\n\n\n\n\n\nFrequent notational confusion: does the lower index represent discrete time or an element of a set?\n\n\n\nThe previous example also displays one particular annoying (and frequently occuring in literature) notational conflict. How shall we interpret the lower index? Sometimes it is used to refer to (discrete) time, and on some other occasions it can just refer to a particular element of a set. In other words, this is a notational clash between name of the variable and value of the variable. In the example above we obviously adopted the latter interpretation. But in other cases, we ourselves are prone to inconsistency. Just make sure you understand what the author means.\n\n\n\nExample 2 (State trajectory of a continuous-time dynamical systems) Compare now the above example of a state trajectory in a DES with the example of a continuous-time state space system below, whose model could be \\dot x(t) = f(x). In the latter, any change, however small, takes time. In other words, the system evolves continuously in time.\n\n\n\n\n\n\nFigure 2: Example of a state trajectory of a continuous-time continuous-valued dynamical system\n\n\n\nThe set of states (aka state space) is \\mathbb{R} (or a subset) in this case (in general \\mathbb{R}^n or a subset).\n\n\nExample 3 (State trajectory of a time-discretized (aka sampled-data) system) As a yet another example of a state trajectory, consider the response of a discrete-time (actually time-discretized or also sampled-data system) system model by x_k = f(x_k) in the figure below. Although we could view the sampling instances as the events, these are given by time, hence the moments of transitions are predictable. Hence the system can still be viewed and analyzed as a time-driven and not event driven one.\n\n\n\n\n\n\nFigure 3: Example of a state trajectory of time-discretized (aka sampled data) system",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Discrete-event systems"
    ]
  },
  {
    "objectID": "des.html#when-do-events-occur",
    "href": "des.html#when-do-events-occur",
    "title": "Discrete-event systems",
    "section": "When do events occur?",
    "text": "When do events occur?\nThere are three major possibilities:\n\nwhen action is taken (button press, clutch released, …),\nspontaneously: well, this is just an “excuse” when the reason is difficult to trace down (computer failure, …),\nwhen some condition is met (water level is reached, …). This needs an introduction of a concept of a hybrid systems, wait for it.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Discrete-event systems"
    ]
  },
  {
    "objectID": "des.html#sequence-of-time-stamped-events-aka-timed-trace",
    "href": "des.html#sequence-of-time-stamped-events-aka-timed-trace",
    "title": "Discrete-event systems",
    "section": "Sequence of “time-stamped” events (aka timed trace)",
    "text": "Sequence of “time-stamped” events (aka timed trace)\nThe sequence of pairs (event, time) (e_1,t_1), (e_2,t_2), (e_3,t_3), \\ldots\nis sufficient to characterize an execution of a deterministic system, that is, a system with a unique initial state and a unique transitions at a given state and an event.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Discrete-event systems"
    ]
  },
  {
    "objectID": "des.html#des-can-be-stochastic-but-what-exactly-is-stochastic-then",
    "href": "des.html#des-can-be-stochastic-but-what-exactly-is-stochastic-then",
    "title": "Discrete-event systems",
    "section": "DES can be stochastic, but what exactly is stochastic then?",
    "text": "DES can be stochastic, but what exactly is stochastic then?\nStochasticity can be introduced in\n\nthe event times (e.g. Poisson process),\nbut also in the transitions (e.g. probabilistic automata, more on this later).",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Discrete-event systems"
    ]
  },
  {
    "objectID": "des.html#sometimes-time-stamps-not-needed-the-ordering-of-events-is-enough",
    "href": "des.html#sometimes-time-stamps-not-needed-the-ordering-of-events-is-enough",
    "title": "Discrete-event systems",
    "section": "Sometimes time stamps not needed – the ordering of events is enough",
    "text": "Sometimes time stamps not needed – the ordering of events is enough\nThe sequence of events (aka trace) e_1,e_2,e_3, \\ldots can be enough for some analysis, in which only the order of the events is important.\n\nExample 4 credit_card_swiped, pin_entered, amount_entered, money_withdrawn",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Discrete-event systems"
    ]
  },
  {
    "objectID": "des.html#discrete-event-systems-are-studied-through-their-languages",
    "href": "des.html#discrete-event-systems-are-studied-through-their-languages",
    "title": "Discrete-event systems",
    "section": "Discrete-event systems are studied through their languages",
    "text": "Discrete-event systems are studied through their languages\nWhen studying discrete-event systems, soon we are exposed to terminology from the formal language theory such as alphabet, word, and language. This must be rather confusing for most students (at least those with no education in computer science). In our course we are not going to use these terms actively (after all our only motivation for introducing the discipline of discrete-event systems is to take away just a few concepts that are useful in hybrid systems), but we want to sketch the motivation for their introduction to the discipline, which may make it easier for a student to skim through some materials on discrete-event systems.\nWe define at least those three terms that we have just mentioned. The definitions correspond to the everyday usage of these terms.\n\nAlphabet\n\na set of symbols.\n\nWord (or string)\n\na sequence of symbols from a finite alphabet.\n\nLanguage\n\na set of words from the given alphabet.\n\n\nNow, a symbol is used to label an event. Alphabet is then a set of possible events. A particular sequence of events (we also call it trace) is then represented by a word. Since we agreed that events are associated with state transitions of a corresponding system, a word represents a possible execution or run of a system. A set of all possible executions of a given system can then be formally viewed as language.\nIndeed, all this is just a formalism, the agreement how to talk about things. We will see an example of this “jargon” in the next section when we introduce the concept of an automaton and some of its properties.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Discrete-event systems"
    ]
  },
  {
    "objectID": "des.html#modelling-frameworks-for-des-as-used-in-our-course",
    "href": "des.html#modelling-frameworks-for-des-as-used-in-our-course",
    "title": "Discrete-event systems",
    "section": "Modelling frameworks for DES (as used in our course)",
    "text": "Modelling frameworks for DES (as used in our course)\nThese are the three frameworks that we are going to cover in our course. There may be some more, but these three are the major ones, and from these there is always some lesson to be learnt that we will find useful later when finally studying hybrid systems\n\nState automaton (pl. automata)\nPetri net\n(max,plus) algebra, MPL systems\n\nWhile the first two frameworks are essentially equally powerful when it comes to modelling DES, the third one can be regarded as an algebraic framework for a subset of systems modelled by Petri nets.\nWe are going to cover all the three frameworks in this course as a prequel to hybrid systems.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Discrete-event systems"
    ]
  },
  {
    "objectID": "max_plus_algebra.html",
    "href": "max_plus_algebra.html",
    "title": "Max-plus algebra",
    "section": "",
    "text": "Max-plus algebra, also written as (max,+) algebra (and also known as tropical algebra/geometry and dioid algebra), is an algebraic framework in which we can model and analyze a class of discrete-event systems, namely event graphs, which we have previously introduced as a subset of Petri nets. The framework is appealing in that the models than look like state equations \\bm x_{k+1} = \\mathbf A \\bm x_k + \\mathbf B \\bm u_k for classical linear dynamical systems. We call these max-plus linear systems, or just MPL systems. Concepts such as poles, stability and observability can be defined, following closely the standard definitions. In fact, we can even formulate control problems for these models in a way that mimicks the conventional control theory for LTI systems, including MPC control.\nBut before we get to these applications, we first need to introduce the (max,+) algebra itself. And before we do that, we recapitulate the definition of a standard algebra.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#algebra",
    "href": "max_plus_algebra.html#algebra",
    "title": "Max-plus algebra",
    "section": "Algebra",
    "text": "Algebra\nAlgebra is a set of elements equipped with\n\ntwo operations:\n\naddition (plus, +),\nmultiplication (times, ×),\n\nneutral (identity) element with respect to addition: zero, 0, a+0=a,\nneutral (identity) element with respect to multiplication: one, 1, a\\times 1 = a.\n\nInverse elements can also be defined, namely\n\nInverse element wrt addition: -a a+(-a) = 0.\nInverse element wrt multiplication (except for 0): a^{-1} a \\times a^{-1} = 1.\n\nIf the inverse wrt multiplication exists for every (nonzero) element, the algebra is called a field, otherwise it is called a ring.\nProminent examples of a ring are integers and polynomials. For integers, it is only the numbers 1 and -1 that have integer inverses. For polynomials, it is only zero-th degree polynomials that have inverses qualifying as polynomials too. An example from the control theory is the ring of proper stable transfer functions, in which only the non-minimum phase transfer functions with zero relative degree have inverses, and thus qualify as units.\nProminent example of a field is the set of real numbers.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#max-algebra-redefining-the-addition-and-multiplication",
    "href": "max_plus_algebra.html#max-algebra-redefining-the-addition-and-multiplication",
    "title": "Max-plus algebra",
    "section": "(max,+) algebra: redefining the addition and multiplication",
    "text": "(max,+) algebra: redefining the addition and multiplication\nElements of the (max,+) algebra are real numbers, but it is still a ring and not a field since the two operations are defined differently.\nThe new operations of addition, which we denote by \\oplus to distinguish it from the standard addition, is defined as \\boxed{\n  x\\oplus y \\equiv \\max(x,y).\n  }\n\nThe new operation of multiplication, which we denote by \\otimes to distinguish it from the standard multiplication, is defined as \\boxed{\n  x\\otimes y \\equiv x+y}.\n\n\n\n\n\n\n\nImportant\n\n\n\nIndeed, there is no typo here, the standard addition is replaced by \\otimes and not \\oplus.\n\n\n\n\n\n\n\n\n(min,+) also possible\n\n\n\nIndeed, we can also define the (min,+) algebra. But for our later purposes in modelling we prefer the (max,+) algebra.\n\n\n\nReals must be extended with the negative infinity\nStrictly speaking, the (max,+) algebra is a broader set than just \\mathbb R. We need to extend the reals with the minus infinity. We denote the extended set by \\mathbb R_\\varepsilon \\boxed{\n\\mathbb R_\\varepsilon \\coloneqq \\mathbb R \\cup \\{-\\infty\\}}.\n\nThe reason for the notation is that a dedicated symbol \\varepsilon is assigned to this minus infinity, that is, \\boxed\n{\\varepsilon \\coloneqq -\\infty.}\n\nIt may yield some later expressions less cluttered. Of course, at the cost of introducing one more symbol.\nWe are now going to see the reason for this extension.\n\n\nNeutral elements\n\nNeutral element with respect to \\oplus\nThe neutral element with respect to \\oplus, the zero, is -\\infty. Indeed, for x \\in \\mathbb R_\\varepsilon \nx \\oplus \\varepsilon = x,\n because \\max(x,-\\infty) = x.\n\n\nNeutral element with respect to \\otimes\nThe neutral element with respect to \\otimes, the one, is 0. Indeed, for x \\in \\mathbb R_\\varepsilon \nx \\otimes \\varepsilon = x,\n because x+0=x.\n\n\n\n\n\n\nNonsymmetric notation, but who cares?\n\n\n\nThe notation is rather nonsymmetric here. We now have a dedicated symbol \\varepsilon for the zero element in the new algebra, but no dedicated symbol for the one element in the new algebra. It may be a bit confusing as “the old 0 is the new 1”. Perhaps similarly as we introduced dedicated symbols for the new operations of addition of multiplication, we should have introduced dedicated symbols such as ⓪ and ①, which would lead to expressions such as x⊕⓪=x and x ⊗ ① = x. In fact, in some software packages they do define something like mp-zero and mp-one to represent the two special elements. But this is not what we will mostly encounter in the literature. Perhaps the best attitude is to come to terms with this notational asymetry… After all, I myself was apparently not even able to figure out how to encircle numbers in LaTeX…\n\n\n\n\n\nInverse elements\n\nInverse with respect to \\oplus\nThe inverse element with respect to \\oplus in general does not exist! Think about it for a few moments, this is not necessarily intuitive. For which element(s) does it exist? Only for \\varepsilon.\nThis has major consequences, for example, x\\oplus x=x.\nCan you verify this statement? How is is related to the fact that the inverse element with respect to \\oplus does not exist in general?\nThis is the key difference with respect to a conventional algebra, wherein the inverse element of a wrt conventional addition is -a, while here we do not even define \\ominus.\nFormally speaking, the (max,+) algebra is only a semi-ring.\n\n\nInverse with respect to \\otimes\nThe inverse element with respect to \\otimes does not exist for all elements. The \\varepsilon element does not have an inverse element with respect to \\otimes. But in this aspect the (max,+) algebra just follows the conventional algebra, beucase 0 has no inverse there either.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#powers-and-the-inverse-with-respect-to-otimes",
    "href": "max_plus_algebra.html#powers-and-the-inverse-with-respect-to-otimes",
    "title": "Max-plus algebra",
    "section": "Powers and the inverse with respect to \\otimes",
    "text": "Powers and the inverse with respect to \\otimes\nHaving defined the fundamental operations and the fundamental elements, we can proceed with other operations. Namely, we consider powers. Fot an integer r\\in\\mathbb Z, the rth power of x, denoted by x^{\\otimes^r}, is defined, unsurprisingly as x^{\\otimes^r} \\coloneqq x\\otimes x \\otimes \\ldots \\otimes x.\nObserve that it corresponds to rx in the conventional algebra x^{\\otimes^r} = rx.\nBut then the inverse element with respect to \\otimes can also be determined using the (-1)th power as x^{\\otimes^{-1}} = -x.\nThis is not actually surprising, is it?\nThere are few more implications. For example,\nx^{\\otimes^0} = 0.\nThere is also no inverse element with respect to \\otimes for \\varepsilon, but it is expected as \\varepsilon is a zero wrt \\oplus. Furthermore, for r\\neq -1, if r&gt;0 , then \\varepsilon^{\\otimes^r} = \\varepsilon, if r&lt;0 , then \\varepsilon^{\\otimes^r} is undefined, which are both expected. Finally, \\varepsilon^{\\otimes^0} = 0 by convention.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#order-of-evaluation-of-max-formulas",
    "href": "max_plus_algebra.html#order-of-evaluation-of-max-formulas",
    "title": "Max-plus algebra",
    "section": "Order of evaluation of (max,+) formulas",
    "text": "Order of evaluation of (max,+) formulas\nIt is the same as that for the conventional algebra:\n\npower,\nmultiplication,\naddition.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#max-polynomials-aka-tropical-polynomials",
    "href": "max_plus_algebra.html#max-polynomials-aka-tropical-polynomials",
    "title": "Max-plus algebra",
    "section": "(max,+) polynomials (aka tropical polynomials)",
    "text": "(max,+) polynomials (aka tropical polynomials)\nHaving covered addition, multiplication and powers, we can now define (max,+) polynomials. In order to get started, consider the the univariate polynomial p(x) = a_{n}\\otimes x^{\\otimes^{n}} \\oplus a_{n-1}\\otimes x^{\\otimes^{n-1}} \\oplus \\ldots \\oplus a_{1}\\otimes x \\oplus a_{0},\n where a_i\\in \\mathbb R_\\varepsilon and n\\in \\mathbb N.\nBy interpreting the operations, this translates to the following function \\boxed\n{p(x) = \\max\\{nx + a_n, (n-1)x + a_{n-1}, \\ldots, x+a_1, a_0\\}.}\n\n\nExample 1 (1D polynomial) Consider the following (max,+) polynomial \np(x) = 2\\otimes x^{\\otimes^{2}} \\oplus 3\\otimes x \\oplus 1.\n\nWe can interpret it in the conventional algebra as \np(x) = \\max\\{2x+2,x+3,1\\},  \n which is a piecewise linear (actually affine) function.\n\n\nShow the code\nusing Plots\nx = -5:3\nf(x) = max(2*x+2,x+3,1)\nplot(x,f.(x),label=\"\",thickness_scaling = 2)\nxc = [-2,1]\nyc = f.(xc)\nscatter!(xc,yc,markercolor=[:red,:red],label=\"\",thickness_scaling = 2)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2 (Example of a 2D polynomial) Nothing prevents us from defining a polynomial in two (and more) variables. For example, consider the following (max,+) polynomial \np(x,y) = 0 \\oplus x \\oplus y.\n\n\n\nShow the code\nusing Plots\nx = -2:0.1:2;\ny = -2:0.1:2;\nf(x,y) = max(0,x,y)\nz = f.(x',y);\nwireframe(x,y,z,legend=false,camera=(5,30))\nxlabel!(\"x\")\nylabel!(\"y\")\nzlabel!(\"f(x,y)\")\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 3 (Another 2D polynomial) Consider another 2D (max,+) polynomial \np(x,y) = 0 \\oplus x \\oplus y \\oplus (-1)\\otimes x^{\\otimes^2} \\oplus 1\\otimes x\\otimes y \\oplus (-1)\\otimes y^{\\otimes^2}.\n\n\n\nShow the code\nusing Plots\nx = -2:0.1:2;\ny = -2:0.1:2;\nf(x,y) = max(0,x,y,2*x-1,x+y+1,2*y-1)\nz = f.(x',y);\nwireframe(x,y,z,legend=false,camera=(15,30))\nxlabel!(\"x\")\nylabel!(\"y\")\nzlabel!(\"p(x,y)\")\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPiecewise affine (PWA) functions\n\n\n\nPiecewise affine (PWA) functions will turn out a frequent buddy in our course.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#solution-set-zero-set",
    "href": "max_plus_algebra.html#solution-set-zero-set",
    "title": "Max-plus algebra",
    "section": "Solution set (zero set)",
    "text": "Solution set (zero set)\n…",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#matrix-computations",
    "href": "max_plus_algebra.html#matrix-computations",
    "title": "Max-plus algebra",
    "section": "Matrix computations",
    "text": "Matrix computations\n\nAddition and multiplication\nWhat is attractive about the whole (max,+) framework is that it also extends nicely to matrices. For matrices, whose elements are in \\mathbb R_\\varepsilon, we define the operations of addition and multiplication identically as in the conventional case, we just use different definitions of the two basic scalar operations. (A\\oplus B)_{ij} = a_{ij}\\oplus b_{ij} = \\max(a_{ij},b_{ij}) \n\\begin{aligned}\n(A\\otimes B)_{ij} &= \\bigoplus_{k=1}^n a_{ik}\\otimes b_{kj}\\\\\n&= \\max_{k=1,\\ldots, n}(a_{ik}+b_{kj})\n\\end{aligned}\n\n\n\nZero and identity matrices\n(max,+) zero matrix \\mathcal{E}_{m\\times n} has all its elements equal to \\varepsilon, that is, \n\\mathcal{E}_{m\\times n} =\n\\begin{bmatrix}\n\\varepsilon & \\varepsilon & \\ldots & \\varepsilon\\\\\n\\varepsilon & \\varepsilon & \\ldots & \\varepsilon\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n\\varepsilon & \\varepsilon & \\ldots & \\varepsilon\n\\end{bmatrix}.\n\n(max,+) identity matrix I_n has 0 on the diagonal and \\varepsilon elsewhere, that is, \nI_{n} =\n\\begin{bmatrix}\n0 & \\varepsilon & \\ldots & \\varepsilon\\\\\n\\varepsilon & 0 & \\ldots & \\varepsilon\\\\\n\\vdots & \\vdots & \\ddots & \\vdots\\\\\n\\varepsilon & \\varepsilon & \\ldots & 0\n\\end{bmatrix}.\n\n\n\nMatrix powers\nThe zerothe power of a matrix is – unsurprisingly – the identity matrix, that is, A^{\\otimes^0} = I_n.\nThe kth power of a matrix, for k\\in \\mathbb N\\setminus\\{0\\}, is then defined using A^{\\otimes^k} = A\\otimes A^{\\otimes^{k-1}}.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#connection-with-graph-theory-precedence-graph",
    "href": "max_plus_algebra.html#connection-with-graph-theory-precedence-graph",
    "title": "Max-plus algebra",
    "section": "Connection with graph theory – precedence graph",
    "text": "Connection with graph theory – precedence graph\nConsider A\\in \\mathbb R_\\varepsilon^{n\\times n}. For this matrix, we can define the precedence graph \\mathcal{G}(A) as a weighted directed graph with the vertices 1, 2, …, n, and with the arcs (j,i) with the associated weights a_{ij} for all a_{ij}\\neq \\varepsilon. The kth power of the matrix is then\n\n(A)^{\\otimes^k}_{ij} = \\max_{i_1,\\ldots,i_{k-1}\\in \\{1,2,\\ldots,n\\}} \\{a_{ii_1} + a_{i_1i_2} + \\ldots + a_{i_{k-1}j}\\}\n for all i,j and k\\in \\mathbb N\\setminus 0.\n\nExample 4 (Example) \nA =\n\\begin{bmatrix}\n2 & 3 & \\varepsilon\\\\\n1 & \\varepsilon & 0\\\\\n2 & -1 & 3\n\\end{bmatrix}\n\\qquad\nA^{\\otimes^2} =\n\\begin{bmatrix}\n4 & 5 & 3\\\\\n3 & 4 & 3\\\\\n5 & 5 & 6\n\\end{bmatrix}\n\n\n\n\n\n\n\n\n\nG\n\n\n1\n\n1\n\n\n\n1-&gt;1\n\n\n2\n\n\n\n2\n\n2\n\n\n\n1-&gt;2\n\n\n1\n\n\n\n3\n\n3\n\n\n\n1-&gt;3\n\n\n2\n\n\n\n2-&gt;1\n\n\n3\n\n\n\n2-&gt;3\n\n\n-1\n\n\n\n3-&gt;2\n\n\n0\n\n\n\n3-&gt;3\n\n\n3\n\n\n\n\n\n\nFigure 1: An example of a precedence graph\n\n\n\n\n\n\n\nIrreducibility of a matrix\n\nMatrix in \\mathbb R_\\varepsilon^{n\\times n} is irreducible if its precedence graph is strongly connected.\nMatrix is irreducible iff \n(A \\oplus A^{\\otimes^2} \\oplus \\ldots A^{\\otimes^{n-1}})_{ij} \\neq \\varepsilon \\quad \\forall i,j, i\\neq j.\n\\tag{1}",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#eigenvalues-and-eigenvectors",
    "href": "max_plus_algebra.html#eigenvalues-and-eigenvectors",
    "title": "Max-plus algebra",
    "section": "Eigenvalues and eigenvectors",
    "text": "Eigenvalues and eigenvectors\nEigenvalues and eigenvectors constitute another instance of a straightforward import of concepts from the conventional algebra into the (max,+) algebra – just take the standard definition of an eigenvalue-eigenvector pair and replace the conventional operations with the (max,+) alternatives \nA\\otimes v = \\lambda \\otimes v.\n\nA few comments:\n\nIn general, total number of (max,+) eigenvalues &lt;n.\nAn irreducible matrix has only one (max,+) eigenvalue.\nGraph-theoretic interpretation: maximum average weight over all elementary circuits…\n\n\nEigenvalue-related property of irreducible matrices\nFor large enough k and c, it holds that \\boxed\n{A^{\\otimes^{k+c}} = \\lambda^{\\otimes^c}\\otimes A^{\\otimes^k}.}",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "max_plus_algebra.html#solving-max-linear-equations",
    "href": "max_plus_algebra.html#solving-max-linear-equations",
    "title": "Max-plus algebra",
    "section": "Solving (max,+) linear equations",
    "text": "Solving (max,+) linear equations\nWe can also define and solve linear equations within the (max,+) algebra. Considering A\\in \\mathbb R_\\varepsilon^{n\\times n},\\, b\\in \\mathbb R_\\varepsilon^n, we can formulate and solve the equation \nA\\otimes x = b.\n\nIn general no solution even if A is square. However, often we can find some use for a subsolution defined as \nA\\otimes x \\leq b.\n\nTypically we search for the maximal subsolution instead, or subsolutions optimal in some other sense.\n\nExample 5 (Greatest subsolution) \nA =\n\\begin{bmatrix}\n2 & 3 & \\varepsilon\\\\\n1 & \\varepsilon & 0\\\\\n2 & -1 & 3\n\\end{bmatrix},\n\\qquad\nb =  \n\\begin{bmatrix}\n1 \\\\ 2 \\\\ 3\n\\end{bmatrix}\n\n\nx =\n\\begin{bmatrix}\n-1\\\\ -2 \\\\ 0\n\\end{bmatrix}\n\n\nA \\otimes x =\n\\begin{bmatrix}\n1\\\\ 0 \\\\ 1\n\\end{bmatrix}\n\\leq b\n\n\nWith this introduction to the (max,+) algebra, we are now ready to move on to the modeling of discrete-event systems using the max-plus linear (MPL) systems.",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Max-plus algebra"
    ]
  },
  {
    "objectID": "des_software.html",
    "href": "des_software.html",
    "title": "Software",
    "section": "",
    "text": "The number of software tools for defining and analysing state automata is huge, as is the number of domains of application of this modelling concept. As we are leaning towards the control systems domain, we first encounter the tools produced by The Mathworks company (Matlab and Simulink)",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Software"
    ]
  },
  {
    "objectID": "des_software.html#matlab-and-simulink",
    "href": "des_software.html#matlab-and-simulink",
    "title": "Software",
    "section": "Matlab and Simulink",
    "text": "Matlab and Simulink\n\nStateFlow – finite state automata within Simulink. A nice interactive tutorial is launched directly within Simulink upon entering learning.simulink.launchOnramp(\"stateflow\") in Matlab. This is the primary tool for our course, as it extends nicely to hybrid systems. An example is shown in Fig. 1 below.\n\n\n\n\n\n\n\nFigure 1: Screenshot of a state “chart” in Simscape\n\n\n\n\nSimEvents – oriented towards one instance of the (state) automata, namely queuing systems. You may want to have a look at the series of introductory videos by the Mathworks, although we are not going to rely on this tool in our course.\n\nSeveral tools are also available outside Matlab and Simulink, and it is certainly good to be aware of these alternatives.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Software"
    ]
  },
  {
    "objectID": "des_software.html#openmodelica",
    "href": "des_software.html#openmodelica",
    "title": "Software",
    "section": "(Open)Modelica",
    "text": "(Open)Modelica\nA popular modelling language for physical systems is Modelica. Starting with version 3.3 (several years ago already), it has a support for state machines, see Chapter 17 in the language specification and the screenshot in Fig. 2 below. A readable introduction to state machines in Modelica is in [1].\n\n\n\n\n\n\nFigure 2: Screenshot of a state machine diagram in Modelica\n\n\n\nSeveral implementations of Modelica language and compiler exist. On the FOSS side, OpenModelica is a popular choice. Slides from an introdutory presentation [2] about state machines in OpenModelica are available for free download.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Software"
    ]
  },
  {
    "objectID": "des_software.html#uppaal",
    "href": "des_software.html#uppaal",
    "title": "Software",
    "section": "UPPAAL",
    "text": "UPPAAL\nDedicated software for timed automata. Not only modelling and simulation but also formal verification. Available at https://uppaal.org/. In our course we will only use it in this block/week. A tutorial is [3].",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Software"
    ]
  },
  {
    "objectID": "des_software.html#python",
    "href": "des_software.html#python",
    "title": "Software",
    "section": "Python",
    "text": "Python\nSimPy – discrete-event simulation in Python. We are not going to use it in our course, but if you are a Python enthusiast, you may want to have a look at it.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Software"
    ]
  },
  {
    "objectID": "des_software.html#julia",
    "href": "des_software.html#julia",
    "title": "Software",
    "section": "Julia",
    "text": "Julia\nTwo major packages for discrete-event simulation in Julia are:\n\nConcurrentSim.jl – discrete-event simulation in Julia.\nDiscreteEvents.jl – discrete-event simulation in Julia.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Software"
    ]
  },
  {
    "objectID": "des_software.html#umlsysml",
    "href": "des_software.html#umlsysml",
    "title": "Software",
    "section": "UML/SysML",
    "text": "UML/SysML\nIf you have been exposed to software engineering, you have probably seen UML diagrams. Their extension (and restriction at the same time) toward systems that also contain hardware is called SysML. And SysML does have support for defining state machines (by drawing the state machine diagrams), see the screenshot in Fig. 3 below.\n\n\n\n\n\n\nFigure 3: Screenshot of a state machine diagram in SysML\n\n\n\nSysML standard also augments the original concept of a state automaton with hierarchies, and some more. But we are not going to discuss it here. Should you need to follow this standard in your project, you may consider exploring some free&open-source (FOSS) tool for creating SysML diagrams such as Modelio or Eclipse Papyrus. But we are not going to use them in our course.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Software"
    ]
  },
  {
    "objectID": "des_software.html#drawing-tools",
    "href": "des_software.html#drawing-tools",
    "title": "Software",
    "section": "Drawing tools",
    "text": "Drawing tools\nLast but not least, you may want only to draw state automata (state machines). While there is no shortage of general WYSIWYG drawing and diagramming tools, you may want to consider Graphviz software that processes text description of automata in DOT language. This is what I used in this lecture. As an alternative, but still text-based, you may want to give a try to Mermaid, which can also draw what they call state diagrams.\nIf you still prefer WISYWIG tools, have a look at IPE, which I also used for some other figures in this lecture and in the rest of the course. Unlike most other tools, it also allows to enter LaTeX math.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Software"
    ]
  },
  {
    "objectID": "stability_references.html",
    "href": "stability_references.html",
    "title": "Literature",
    "section": "",
    "text": "The lecture was partly built upon the chapter 4 of the textbook [1], which in turn was (to a large extent) built upon chapter 2 of the research monograph [2]. None of these two is available online, but fortunately, the latter has a free shorter online version [3]. The chapter 4 (pages 20 through 27) give the necessary material. Possibly, the chapter 3 can serve with some recap of Lyapunov analysis of stability.\nThe lecture was also partly inspired by the sections 8.2 and 8.3 (pages 158–168) of the text [4], which used to be available online, but has resently dissapeared – most probably it is about to be publised as a textbook.\nSome more online resources, in particular for multiple (also piecewise) Lyapunov functions, are [5], [6], [7], [8]. The are all quite readable.",
    "crumbs": [
      "8. Stability",
      "Literature"
    ]
  },
  {
    "objectID": "stability_references.html#linear-matrix-inequalities",
    "href": "stability_references.html#linear-matrix-inequalities",
    "title": "Literature",
    "section": "Linear matrix inequalities",
    "text": "Linear matrix inequalities\nThe topic of linear matrix inequalities and the related semidefinite programming, which we used for analysis of stability, is dealt with in numerous resources, many of them available online. The monograph [9] was one of the first systematic treatments of the topic and still offers a relevant material. The authors also provide some shorter teaching material [10], tailored to their Matlab toolbox called CVX. Alternatively, the text [11] is even richer by two pages. Another recommendable lecture notes are also available for free: [12]. Finally, a section on Semidefinite programming in the documentation for Yalmip software can also serve as learning resource.\n\nS-procedure\nSome treatment of S-procedure is in [9], pages 23 and 24, and [13], page 655.",
    "crumbs": [
      "8. Stability",
      "Literature"
    ]
  },
  {
    "objectID": "stability_references.html#sum-of-squares-programming",
    "href": "stability_references.html#sum-of-squares-programming",
    "title": "Literature",
    "section": "Sum-of-squares programming",
    "text": "Sum-of-squares programming\nThe topic of sum-of-squares programming, which we also relied upon in analysis of stability, is a trending topic in optimization and a wealth of resources are available. As an introduction, the paper [14] is recommendable. The computational problems described in the paper can be solved in Matlab using the SOSTOOLS toolbox. Its documentation [15] can serve as yet another tutorial. Last but not least, YALMIP software contains a well-developed section on Sum-of-squares programming.",
    "crumbs": [
      "8. Stability",
      "Literature"
    ]
  },
  {
    "objectID": "petri_nets.html",
    "href": "petri_nets.html",
    "title": "Petri nets",
    "section": "",
    "text": "In this chapter we introduce another formalism for modelling discrete event systems (DES) – Petri nets. Petri nets offer an alternative perspective on discrete even systems compared to automata. And it is good to have alternatives, isn’t it? For some purposes, one framework can be more appropriate than the other.\nFurthermore, the ideas behind Petri nets even made it into international standards. Either directly or through the derived GRAFCET language, which in turn served as the basis for the Sequential Function Chart (SFC) language for PLC programming. See the references.\nLast but not least, an elegant algebraic framework based on the so-called (max,+) algebra has been developed for a subset of Petri nets (so-called event graphs) and it would be a shame not to mention it in our course (in the next chapter).",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#definition-of-a-petri-net",
    "href": "petri_nets.html#definition-of-a-petri-net",
    "title": "Petri nets",
    "section": "Definition of a Petri net",
    "text": "Definition of a Petri net\nSimilarly as in the case of automata, a Petri net (PN) can be defined as a tuple of sets and functions: \\boxed{PN = \\{\\mathcal{P}, \\mathcal{T}, \\mathcal{A}, w\\},} where\n\n\\mathcal{P} = \\{p_1, \\dots, p_n\\} is a finite set of places,\n\\mathcal{T} = \\{t_1, \\dots, t_m\\} is a finite set of transitions,\n\\mathcal{A} \\subseteq (\\mathcal{P} \\times \\mathcal{T}) \\cup (\\mathcal{T} \\times \\mathcal{P}) is a finite set of arcs, and these arcs are directed and since there are two types of nodes, there are also two types of arcs:\n\n(p_i, t_j) \\in \\mathcal{A} is from place p_i to transition t_j,\n(t_j, p_i) \\in \\mathcal{A} is from transition t_j to place p_i,\n\nw : \\mathcal{A} \\to \\mathbb{N} is a weight function.\n\nSimilarly as in the case of automata, Petri nets can be visualized using graphs. But this time, we need to invoke the concept of a weighted bipartite graph. That is, a graph with two types of nodes:\n\nplaces = circles,\ntransitions = bars.\n\nThe nodes of different kinds are connected by arcs (arrowed curves). A integer weights are associated with arcs. Alternatively, for a smaller weight (2, 3, 4), the weithg can be graphically encoded by drawing multiple arcs.\n\nExample 1 (Simple Petri net) We consider just two places, that is, \\mathcal{P} = \\{p_1, p_2\\}, and one transition, that is, \\mathcal{T} = \\{t\\}. The set of arcs is \\mathcal{A} = \\{\\underbrace{(p_1, t)}_{a_1}, \\underbrace{(t, p_2)}_{a_2}\\}, and the associated weights are w(a_1) = w((p_1, t)) = 2 and w(a_2) = w((t, p_2)) = 1. The Petri net is depicted in Fig. 1.\n\n\n\n\n\n\nFigure 1: Example of a simple Petri net\n\n\n\n\n\nAdditional definitions\n\n\\mathcal{I}(t_j) … a set of input places of the transition t_j,\n\\mathcal{O}(t_j) … a set of output places of the transition t_j.\n\n\nExample 2 (More complex Petri net)  \n\n\\mathcal{P} = \\{p_1, p_2, p_3, p_4\\},\n\\mathcal{T} = \\{t_1, t_2, t_3, t_4, t_5\\},\n\\mathcal{A} = \\{(p_1, t_1), (t_1, p_1), (p_1, t_2),\\ldots\\},\nw((p_1, t_1)) = 2, \\; w((t_1, p_1)) = 1, \\; \\ldots\n\n\n\n\n\n\n\nFigure 2: Example of a more complex Petri net\n\n\n\n\n\n\nMarking and marked Petri nets\nAn important concept that we must introduce now is that of marking. It is a function that assigns an integer to each place   x: \\mathcal{P} \\rightarrow \\mathbb{N}.\nThe vector composed of the values of the marking function for all places \\bm x = \\begin{bmatrix}x(p_1)\\\\ x(p_2)\\\\ \\vdots \\\\ x(p_n) \\end{bmatrix} can be viewed as the state vector (although the Petri nets community perhaps would not use this terminology and stick to just marking).\nMarked Petri net is then a Petri net augmented with the marking\nMPN = \\{\\mathcal{P}, \\mathcal{T}, \\mathcal{A}, w,x\\}.\n\nVisualization of marked Petri net using tokens\nMarked Petri net can also be visualized by placing tokens (dots) into the places. The number of tokens in a place corresponds to the value of the marking function for that place.\n\nExample 3 (Marked Petri net) Consider the Petri net from Example 1. The marking function is x(p_1) = 2 and x(p_2) = 1, which assembled into a vector gives \\bm x = \\begin{bmatrix}1\\\\ 0 \\end{bmatrix}. The marked Petri net is depicted in Fig. 3.\n\n\n\n\n\n\nFigure 3: Example of a marked Petri net\n\n\n\nFor another marking, namely \\bm x = \\begin{bmatrix}2\\\\ 1 \\end{bmatrix}, the marked Petri net is depicted in Fig. 4.\n\n\n\n\n\n\nFigure 4: Example of a marked Petri net with different marking\n\n\n\n\n\n\n\nEnabling and firing of a transition\nFinally, here comes the enabling (pun intended) component of the definition of a Petri net – enabled transition. A transition t_j does not just happen – we say fire – whenever it wants, it can only fire if it is enabled, and the marking is used to determine if it is enabled. Namely, the transition is enabled if the value of the marking function for each input place is greater than or equal to the weight of the arc from that place to the transition. That is, the transition t_j is enabled if \nx(p_i) \\geq w(p_i,t_j)\\quad \\forall p_i \\in \\mathcal{I}(t_j).\n\n\n\n\n\n\n\nCan but does not have to\n\n\n\nThe enabled transition can fire, but it doesn’t have to. We will exploit this in timed PN.\n\n\n\nExample 4 (Enabled transition) See the PN in Example 3: in the first marked PN the transition cannot fire, in the second it can.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#state-transition-function",
    "href": "petri_nets.html#state-transition-function",
    "title": "Petri nets",
    "section": "State transition function",
    "text": "State transition function\nWe now have a Petri net as a conceptual model with a graphical representation. But in order to use it for some quantitative analysis, it is useful to turn it into some computational form. Preferrably a familiar one. This is done by defining a state transition function. For a Petri net with n places, the state transition function is \nf: \\mathbb N^n \\times \\mathcal{T} \\rightarrow \\mathbb N^n,\n which reads that the state transition fuction assignes a new marking (state) to the Petri net after a transition is fired at some given marking (state).\nThe function is only defined for a transition t_j iff the transition is enabled.\nIf the transition t_j is enabled and fired, the state evolves as \n\\bm x^+ = f(\\bm x, t_j),\n where the individual components of \\bm x evolve according to \\boxed{\n    x^+(p_i) = x(p_i) - w(p_i,t_j) + w(t_j,p_i), \\; i = 1,\\ldots,n.}\n\nThis has a visual interpretation – a fired transition moves tokens from the input to the output places.\n\nExample 5 (Moving tokens around) Consider the PN with the initial marking (state) \\bm x_0 = \\begin{bmatrix}2\\\\ 0\\\\ 0\\\\ 1 \\end{bmatrix} (at discrete time 0), and the transition t_1 enabled\n\n\n\nExample PN in the initial state at time 0, the transition t_1 enabled, but not yet fired\n\n\n\n\n\n\n\n\nConflict in notation. Again. Sorry.\n\n\n\nWe admit the notation here is confusing, because we use the lower index 0 in \\bm x_0 to denote the discrete time, while the lower index 1 in t_1 to denote the transition and the lower indices 1 and 2 in p_1 and p_2 just number the transitions and places, respectively. We could have chosen something like \\bm x(0) or \\bm x[0], but we dare to hope that the context will make it clear.\n\n\nNow we assume that t_1 is fired\n\n\n\n\n\n\nFigure 5: Transition t_1 in the example PN fired at time 1\n\n\n\nThe state vector changes to \\bm x_1 = [1, 1, 1, 1]^\\top, the discrete time is 1 now.\nAs a result of this transition, note that t_1, t_2, t_3 are now enabled.\n\n\n\n\n\n\nNumber of tokens need not be preserved\n\n\n\nIn the example we can see for the first time, that the number of tokens need not be preserved.\n\n\nNow fire the t_2 transition\n\n\n\nTransition t_2 in the example PN fired at time 2\n\n\nThe state vector changes to \\bm x_2 = [1, 1, 0, 2]^\\top, the discrete time is 2 now.\nGood, we can see the idea. But now we go back to time 1 (as in Fig. 5) to explore the alternative evolution. With the state vector \\bm x_1 = [1, 1, 1, 1]^\\top and the transitions t_1, t_2, t_3 enabled, we fire t_3 this time.\n\n\n\nTransition t_3 in the example PN fired at time 1\n\n\nThe state changes to \\bm x_2 = [0, 1, 0, 0]^\\top, the discrete time is 2. Apparently the PN evolved into at a different state. The lesson learnt with this example is that the order of firing of enabled transitions matters.\n\n\n\n\n\n\n\nThe order in which the enabled transitions are fired does matter\n\n\n\nThe dependence of the state evolution upon the order of firing the transitions is not surprising. Wwe have already encountered it in automata when the active event set for a given state contains more then a single element.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#reachability",
    "href": "petri_nets.html#reachability",
    "title": "Petri nets",
    "section": "Reachability",
    "text": "Reachability\nWe have started talking about states and state transitions in Petri nets, which are all concepts that we are familiar with from dynamical systems. Another such concept is reachability. We explain it through an example.\n\nExample 6 (Not all states are reachable)  \n\n\n\nExample of an unreachability in a Petri net\n\n\nThe Petri net is initial in the state [2,1]^\\top. The only reachable state is [0,2]^\\top.\nBy the way, note that the weight of the arc from the place p_1 to the transition t is 2, so both tokens are removed from the place p_1 when the transition t fires. But then the arc to the place p_2 has weight 1, so only one token is added to the place p_2. The other token is “lost”.\n\n\nReachability tree and graph\nHere we introduce two tools for analysis of reachability of a Petri net.\n\nExample 7 Consider the following example of a Petri net.\n\n\n\nExample of a Petri net for reachability analysis\n\n\nIn Fig. 6 we draw a reachability tree for this Petri net.\n\n\n\n\n\n\nFigure 6: Reachability tree for an example Petri net\n\n\n\nIn Fig. 7 we draw a reachability graph for this Petri net.\n\n\n\n\n\n\nFigure 7: Reachability graph for an example Petri net",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#number-of-tokens-need-not-be-preserved-1",
    "href": "petri_nets.html#number-of-tokens-need-not-be-preserved-1",
    "title": "Petri nets",
    "section": "Number of tokens need not be preserved",
    "text": "Number of tokens need not be preserved\nWe have already commented on this before, but we emphasize it here. Indeed, it can be that \n\\sum_{p_i\\in\\mathcal{O}(t_j)}w(t_j,p_i) &lt; \\sum_{p_i\\in\\mathcal{I}(t_j)} w(p_i,t_j)\n\nor\n\n\\sum_{p_i\\in\\mathcal{O}(t_j)}w(t_j,p_i) &gt; \\sum_{p_i\\in\\mathcal{I}(t_j)} w(p_i,t_j)\n\nWith this reminder, we can now hightlight several patters that can be observed in Petri nets.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#and-convergence-and-divergence",
    "href": "petri_nets.html#and-convergence-and-divergence",
    "title": "Petri nets",
    "section": "AND-convergence, AND-divergence",
    "text": "AND-convergence, AND-divergence",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#or-convergence-and-or-divergence",
    "href": "petri_nets.html#or-convergence-and-or-divergence",
    "title": "Petri nets",
    "section": "OR-convergence and OR-divergence",
    "text": "OR-convergence and OR-divergence",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#nondeterminism-in-a-pn",
    "href": "petri_nets.html#nondeterminism-in-a-pn",
    "title": "Petri nets",
    "section": "Nondeterminism in a PN",
    "text": "Nondeterminism in a PN\nIn the four patters just enumerated, we have seen that the last one – the OR-divergence – is not deterministic. Indeed, consider the following example.\n\nExample 8  \n\n\n\nNondeterminism in a Petri net\n\n\n\nIn other words, we can incorporate a nondeterminism in a model.\n\n\n\n\n\n\nNondeterminism in automata\n\n\n\nRecall that something similar can be encountered in automata, if the active event set for a given state contains more than one element (event,transition).",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#subclasses-of-petri-nets",
    "href": "petri_nets.html#subclasses-of-petri-nets",
    "title": "Petri nets",
    "section": "Subclasses of Petri nets",
    "text": "Subclasses of Petri nets\nWe can identify two subclasses of Petri nets:\n\nevent graphs,\nstate machines.\n\n\nEvent graph\n\nEach place has just one input and one output transition (all ws equal to 1).\nNo OR-convergence, no OR-divergence.\nAlso known as Decision-free PN.\nIt can model synchronization.\n\n\nExample 9 (Event graph)  \n\n\n\nExample of an event graph\n\n\n\n\n\nState machine\n\nEach transition has just one input and one output place.\nNo AND-convergence, no AND-divergence.\nDoes not model synchronization.\nIt can model race conditions.\nWith no source (input) and sink (output) transitions, the number of tokens is preserved.\n\n\nExample 10 (State machine)  \n\n\n\nExample of a state machine\n\n\n\n\n\nIncidence matrix\nWe consider a Petri net with n places and m transitions. The incidence matrix is defined as \n\\bm A \\in \\mathbb{Z}^{n\\times m},\n where \na_{ij} = w(t_j,p_i) - w(p_i,t_j).\n\n\n\n\n\n\n\nTranspose\n\n\n\nSome define the incidence matrix as the transpose of our definition.\n\n\n\n\nState equation for a Petri net\nWith the incidence matrix defined above, the state equation for a Petri net can be written as \n\\bm x^+ = \\bm x + \\bm A \\bm u,\n where \\bm u is a firing vector for the enabled j-th transition \n\\bm u = \\bm e_j = \\begin{bmatrix}0 \\\\ \\vdots \\\\ 0 \\\\ 1\\\\ 0\\\\ \\vdots\\\\ 0\\end{bmatrix}\n with the 1 at the j-th position.\n\n\n\n\n\n\nState vector as a column rather then a row\n\n\n\nNote that in [1] they define everything in terms of the transposed quantities, but we prefer sticking to the notion of a state vector as a column.\n\n\n\nExample 11 (State equation for a Petri net) Consider the Petri net from Example 5, which we show again below in Fig. 8.\n\n\n\n\n\n\nFigure 8: Example of a Petri net\n\n\n\nThe initial state is given by the vector \n\\bm x_0\n=\n\\begin{bmatrix}\n2\\\\ 0\\\\ 0\\\\ 1\n\\end{bmatrix}\n\nThe incidence matrix is \n\\bm A = \\begin{bmatrix}\n-1 & 0 & -1\\\\\n1 & 0 & 0\\\\\n1 & -1 & -1\\\\\n0 & 1 & -1\n\\end{bmatrix}\n\nAnd the state vector evolves according to \n\\begin{aligned}\n\\bm x_1 &= \\bm x_0 + \\bm A \\bm u_1\\\\\n\\bm x_2 &= \\bm x_1 + \\bm A \\bm u_2\\\\\n\\vdots &\n\\end{aligned}\n\n\n\n\n\n\n\n\nCaution\n\n\n\nWe repeat once again just to make sure: the lower index corresponds to the discrete time.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#queueing-systems-modelled-by-pn",
    "href": "petri_nets.html#queueing-systems-modelled-by-pn",
    "title": "Petri nets",
    "section": "Queueing systems modelled by PN",
    "text": "Queueing systems modelled by PN\nAlthough Petri nets can be used to model a vast variety of systems, below we single out one particular class of systems that can be modelled by Petri nets – queueing systems. The general symbol is shown in Fig. 9.\n\n\n\n\n\n\nFigure 9: Queing systems and its components and transitions/events\n\n\n\nWe can associate the transitions with the events in the queing system:\n\na is a spontaneous transition (no input places).\ns needs a customer in the queue and the server being idle.\nc needs the server being busy.\n\nWe can now start drawing the Petri net by drawin the bars corresponding to the transitions. Then in between every two bars, we draw a circle for a place. The places can be associated with three bold-face letters above, namely:\n\\quad \\mathcal{P} = \\{Q, I, B\\}, that is, queue, idle, busy.\n\n\n\nPetri net corresponding to the queing system\n\n\n\n\n\n\n\n\nThe input transition adds tokens to the system\n\n\n\nThe transition a is an input transition – the tokens are added to the system through this transition.\n\n\nNote how we consider the token in the I place. This is not only to express that the server is initially idle, ready to serve as soon as a customer arrives to the queue, it also ensures that no serving of a new customer can start before the serving of the current customer is completed.\nThe initial state: [0,1,0]^\\top. Consider now a particular trace (of transitions/events) \\{a,s,a,a,c,s,a\\}. Verify that this leads to the final state [2,0,1]^\\top.\n\nSome more extensions\nWe can keep adding features to the model of a queing system. In particular,\n\nthe arrival transition always enabled,\nthe server can break down, and then be repaired,\ncompleting the service \\neq customer departure.\n\nThese are incorporated into the Petri net in Fig. 10.\n\n\n\n\n\n\nFigure 10: Extended model of a queueing system\n\n\n\nIn the Petri net, d is an output transition – the tokens are removed from the system.\n\nExample 12 (Beverage vending machine) Below we show a Petri net for a beverage vending machine. While building it, we find it useful to identify the events/transitions that can happen in the system.\n\n\n\nPetri net for a beverage vending machine",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "petri_nets.html#some-extensions-of-basic-petri-nets",
    "href": "petri_nets.html#some-extensions-of-basic-petri-nets",
    "title": "Petri nets",
    "section": "Some extensions of basic Petri nets",
    "text": "Some extensions of basic Petri nets\n\nColoured Petri nets (CPN): tokens can by of several types (colours), and the transitions can be enabled only if the tokens have the right colours.\n…\n\nWe do not cover these extensions in our course. But there is one particular extension that we do want to cover, and this amounts to introducing time into Petri nets, leading to timed Petri nets, which we will discuss in the next chapter.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Petri nets"
    ]
  },
  {
    "objectID": "max_plus_software.html",
    "href": "max_plus_software.html",
    "title": "Software",
    "section": "",
    "text": "MaxPlus.jl package for Julia by Quentin Quadrat.\nMax-Plus Algebra Toolbox for Matlab by Jarosław Stańczyk.\n\n\n\n\n Back to top",
    "crumbs": [
      "3. Discrete-event systems: Max-plus systems",
      "Software"
    ]
  },
  {
    "objectID": "solution_types.html",
    "href": "solution_types.html",
    "title": "Types of solutions",
    "section": "",
    "text": "Now that we know, what a hybrid arc (trajectory) needs to satisfy to be a solution of a hybrid system, we can classify the solutions into several types. And we base this classification on their hybrid time domain E:",
    "crumbs": [
      "7. Solution",
      "Types of solutions"
    ]
  },
  {
    "objectID": "solution_types.html#examples-of-types-of-solutions",
    "href": "solution_types.html#examples-of-types-of-solutions",
    "title": "Types of solutions",
    "section": "Examples of types of solutions",
    "text": "Examples of types of solutions\n\nExample 1 (Example of a (non-)maximal solution) \n\\dot x = 1, \\; x(0) = 1\n\n\n(t,j) \\in [0,1] \\times \\{0\\}\n\nNow extend the time domain to \n(t,j) \\in [0,2] \\times \\{0\\}.\n\nCan we extend the solution?\n\n\nExample 2 (Maximal but not complete continuous solution) Finite escape time\n\\dot x = x^2, \\; x(0) = 1,\nx(t) = 1/(1-t)\n\n\nExample 3 (Discontinuous right hand side) \\dot x = \\begin{cases}-1 & x&gt;0\\\\ 1 & x\\leq 0\\end{cases}, \\quad x(0) = -1 (unless the concept of Filippov solution is invoked).\n\n\nExample 4 (Zeno solution of the bouncing ball) Starting on the ground with some initial upward velocity \nh(t) = \\underbrace{h(0)}_0 + v(0)t - \\frac{1}{2}gt^2, \\quad v(0)=1\n\nWhat time will it hit the ground again? \n0 = t - \\frac{1}{2}gt^2 = t(1-\\frac{1}{2}gt)\n\nt_1=\\frac{2}{g}\nSimplify (scale) the computations just to get the qualitative picture: set g=2, which gives t_1 = 1.\nt_1=1:\nv(t_1^+) = \\gamma v(t_1) = \\gamma v(0) = \\gamma\nThe next hit will be at t_1 + \\tau_1 h(t_1 + \\tau_1) = 0 = \\gamma \\tau_1 - \\tau_1^2 = \\tau_1(\\gamma - \\tau_1) \\tau_1 = \\gamma\nt_2 = t_1+\\tau_1 = 1 + \\gamma:\\quad \\ldots\nt_k = 1 + \\gamma + \\gamma^2 + \\ldots + \\gamma^k:\\quad \\ldots \\boxed{\\lim_{k\\rightarrow \\infty} t_k = \\frac{1}{1-\\gamma} &lt; \\infty}\nInfinite number of jumps in a finite time!\n\n\nExample 5 (Water tank)  \n\n\n\nSwitching between two water tanks\n\n\n\n\\max \\{Q_\\mathrm{out,2}, Q_\\mathrm{out,2}\\} \\leq Q_\\mathrm{in} \\leq Q_\\mathrm{out,2} + Q_\\mathrm{out,2}\n\n\n\n\nHybrid automaton for switching between two water tanks\n\n\n\n\nExample 6 ((Non)blocking and (non)determinism in hybrid systemtems)  \n\n\n\nExample of an automaton exhibitting (non)blocking and (non)determinism\n\n\n\nx(0) = -3\nx(0) = -2\nx(0) = -1\nx(0) = 0",
    "crumbs": [
      "7. Solution",
      "Types of solutions"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html",
    "href": "stability_via_common_lyapunov_function.html",
    "title": "Stability via common Lyapunov function",
    "section": "",
    "text": "Having just recalled the stability analysis based on searching for a Lyapunov function, we now extend the analysis to hybrid systems, in particular, hybrid automata.",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#hybrid-system-stability-analysis-via-lyapunov-function",
    "href": "stability_via_common_lyapunov_function.html#hybrid-system-stability-analysis-via-lyapunov-function",
    "title": "Stability via common Lyapunov function",
    "section": "Hybrid system stability analysis via Lyapunov function",
    "text": "Hybrid system stability analysis via Lyapunov function\nIn contrast to continuous systems where Lyapunov functin should decrease along the state trajectory to certify asymptotic stability (or at least should not increase to certify Lyapunov stability), in hybrid systems the requirement can be relaxed a bit.\nA Lyapunov function should still decrease along the continuous state trajectory while the system resides in a given discrete state (mode), but during the transition between the modes the function can be discontinuous, and can even increase. But then upon return to the same discrete state, the function should have lower value than it had last time it entered the state to certify asymptotic stability (or at least not larger for Lyapunov stability), see Fig. 1.\n\n\n\n\n\n\nFigure 1: Example of an evolution of a Lyapunov function of a hybrid automaton in time\n\n\n\nFormally, the function V(q,\\bm x) has two variables q and \\bm x, it is smooth in \\bm x, and\n\nV(q,\\bm 0) = 0, \\quad V(q,\\bm x) &gt; 0 \\; \\text{for all nonzero} \\; \\bm x \\; \\text{and for all nonzero} \\; q,\n\n\n\\left(\\nabla_x V(q,\\bm x)\\right)^\\top \\mathbf f(q,\\bm x) &lt; 0  \\; \\text{for all nonzero} \\; \\bm x \\; \\text{and for all nonzero} \\; q,\n\nand the discontinuities at transitions must satisfy the conditions sketched in Fig. 1. If Lyapunov stability is enough, the strict inequality can be relaxed to nonstrict.\n\nStricter condition on Lyapunov function\nVerifying the properties just described is not easy. Perhaps the only way is to simulate the system, evaluate the function along the trajectory and check if the conditions are satisfied, which is hardly useful. A stricter condition is in Fig. 2. Here we require that during transitions to another mode, the fuction should not increase. Discontinuous reductions in value are allowed, but enforcing continuity introduced yet another simplification that can be plausible for analysis.\n\n\n\n\n\n\nFigure 2: Example of an evolution of a restricted Lyapunov function of a hybrid automaton in time",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#further-restricted-set-of-candidate-functions-common-lyapunov-function-clf",
    "href": "stability_via_common_lyapunov_function.html#further-restricted-set-of-candidate-functions-common-lyapunov-function-clf",
    "title": "Stability via common Lyapunov function",
    "section": "Further restricted set of candidate functions: common Lyapunov function (CLF)",
    "text": "Further restricted set of candidate functions: common Lyapunov function (CLF)\nIn the above, we have considered a Lyapunov function V(q,\\bm x) that is mode-dependent. But what if we could find a single Lyapunov function V(\\bm x) that is common for all modes q? This would be a great simplification.\nThis, however, implies that at a given state \\bm x, arbitrary transition to another mode q is possible. We add and adjective uniform the stabilty (either Lyapunov or asymptotic) to emphasize that the function is common for all modes.\nIn terminology of switched systems, we say that arbitrary switching is allowed. And staying in the domain of switched systems, the analysis can be interpreted within the framework of differential inclusions \n\\dot{\\bm x} \\in \\{f_1(\\bm x), f_2(\\bm x),\\ldots,f_m(\\bm x)\\}.",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#global-uniform-asymptotic-stability",
    "href": "stability_via_common_lyapunov_function.html#global-uniform-asymptotic-stability",
    "title": "Stability via common Lyapunov function",
    "section": "(Global) uniform asymptotic stability",
    "text": "(Global) uniform asymptotic stability\nHaving agreed that we are now searching for a single function V(\\bm x), the function must satisfy \\boxed{\\kappa_1(\\|\\bm x\\|) \\leq V(\\bm x) \\leq \\kappa_2(\\|\\bm x\\|),} where \\kappa_1(\\cdot), \\kappa_2(\\cdot) are class \\mathcal{K} comparison functions, and \\kappa_1(\\cdot)\\in\\mathcal{K}_\\infty if global asymptotic stability is needed, and \n\\boxed{\\left(\\nabla V(\\bm x)\\right)^\\top \\mathbf f_q(\\bm x) \\leq -\\rho(\\|\\bm x\\|),\\quad q\\in\\mathcal{Q},}\n where \\rho(\\cdot) is a positive definite continuous function, zero at the origin. If all these are satisfied, the system is (globally) uniformly asymptotically stable (GUAS).\nSimilarly as we did in continuous systems, we must ask if stability implies existence of a common Lyapunov function. An affirmative answer comes in the form of a converse theorem for global uniform asymptotic stability (GUAS).\nThis is great, a CLF exists for a GUAS system, but how do we find it? We must restrict the set of candidate functions and then search within the set. Obviously, if we fail to find a function in the set, we must extend the set and search again…",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#common-quadratic-lyapunov-function-cqlf",
    "href": "stability_via_common_lyapunov_function.html#common-quadratic-lyapunov-function-cqlf",
    "title": "Stability via common Lyapunov function",
    "section": "Common quadratic Lyapunov function (CQLF)",
    "text": "Common quadratic Lyapunov function (CQLF)\nAn immediate restriction of a set of Lyapunov functions is to quadratic functions \nV(\\bm x) = \\bm x^\\top \\mathbf P \\bm x,\n where \\mathbf P=\\mathbf P^\\top \\succ 0.\nThis restriction is also quite natural because for linear systems, it is known that we do not have to consider anything more complicated than quadratic functions. This does not hold in general for nonlinear and hybrid systems. But it is a good start. If we succeed in finding a quadratic Lyapunov function, we can be sure that the system is stable.\nHere we start by considering a hybrid automaton for which at each mode the dynamics is linear. We consider r continuous-time LTI systems parameterized by the system matrices \\mathbf A_i for i=1,\\ldots, r as \n\\dot{\\bm x} = \\mathbf A_i \\bm x(t).\n\nTime derivatives of V(\\bm x) along the trajectory of the i-th system \n  \\nabla V(\\bm x)^\\top \\left.\\frac{\\mathrm d \\bm x}{\\mathrm d t}\\right|_{\\dot{\\bm x} = \\mathbf A_i \\bm x} = \\bm x^\\top(\\mathbf A_i^\\top \\mathbf P + \\mathbf P\\mathbf A_i)\\bm x,\n\nwhich, upon introduction of new matrix variables \\mathbf Q_i=\\mathbf Q_i^\\top given by\n\n  \\mathbf A_i^\\top \\mathbf P + \\mathbf P\\mathbf A_i = \\mathbf Q_i,\\qquad i=1,\\ldots, r\n yields\n\n  \\dot V(\\bm x) = \\bm x^\\top \\mathbf Q_i\\bm x,\n from which it follows that \\mathbf Q_i (for all i=1,\\ldots,r) must satisfy\n\n  \\bm x^\\top \\mathbf Q_i \\bm x \\leq 0,\\qquad i=1,\\ldots, r\n\nfor (Lyapunov) stability and\n\n  \\bm x^\\top \\mathbf Q_i \\bm x &lt; 0,\\qquad i=1,\\ldots, r\n\nfor asymptotic stability.\nAs a matter of fact, we could proceeded without introducing new variables \\mathbf Q_i and just write the conditions directly in terms of \\mathbf A_i and \\mathbf P \n  \\bm x^\\top (\\mathbf A_i^\\top \\mathbf P + \\mathbf P\\mathbf A_i) \\bm x \\leq 0,\\qquad i=1,\\ldots, r\n\nfor (Lyapunov) stability and\n\n  \\bm x^\\top (\\mathbf A_i^\\top \\mathbf P + \\mathbf P\\mathbf A_i) \\bm x &lt; 0,\\qquad i=1,\\ldots, r\n\nfor asymptotic stability.",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#linear-matrix-inequality-lmi",
    "href": "stability_via_common_lyapunov_function.html#linear-matrix-inequality-lmi",
    "title": "Stability via common Lyapunov function",
    "section": "Linear matrix inequality (LMI)",
    "text": "Linear matrix inequality (LMI)\nThe conditions of quadratic stability that we have just derived are conditions on functions. However, in this case of a quadratic Lyapunov function and linear systems, the condition can also be written directly in terms of matrices. For that we use the concept of a linear matrix inequality (LMI).\nRecall that a linear inequality is an inequality of the form \\underbrace{a_0 a_1x_1 + a_2x_2 + \\ldots + a_rx_r}_{a(\\bm x)} &gt; 0.\n\n\n\n\n\n\nLinear vs. affine\n\n\n\nWe could perhaps argue that as the function a(x) is an affine and not linear, the inequality should be called an affine inequality. However, the term linear inequality is well established in the literature. It can be perhaps justified by moving the constant term to the right-hand side, in which case we have a linear function on the left and a constant term on the right, which is the same situation as in the \\mathbf A\\bm x=\\mathbf b equation, which we call linear without hesitation.\n\n\nA linear matrix inequality is a generalization of this concept where the coefficients are matrices.\n\n\\underbrace{\\mathbf A_0 + \\mathbf A_1\\bm x_1 + \\mathbf A_2\\bm x_2 + \\ldots + \\mathbf A_r\\bm x_r}_{\\mathbf A(\\bm x)} \\succ 0.\n\nBesides having matrix coefficients, another crucial difference is the meaning of the inequality. In this case it should not be interpreted component-wise but rather \\mathbf A(\\bm x)\\succ 0 means that the matrix \\mathbf A(\\bm x) is positive definite.\nAlternatively, the individual scalar variables can be assembled into matrices, in which case the LMI can have the form with matrix variables \n\\mathbf F(\\bm X) = \\mathbf F_0 + \\mathbf F_1\\bm X\\mathbf G_1 + \\mathbf F_2\\bm X\\mathbf G_2 + \\ldots + \\mathbf F_k\\bm X\\mathbf G_k \\succ 0,\n but the meaning of the inequality remains the same.\nThe use of LMIs is widespread in control theory. Here we formulate the LMI feasibility problem: does \\bm X=\\bm X^\\top exist such that the LMI \\mathbf F(\\bm X)\\succ 0 is satisfied?",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#cqlf-as-an-lmi",
    "href": "stability_via_common_lyapunov_function.html#cqlf-as-an-lmi",
    "title": "Stability via common Lyapunov function",
    "section": "CQLF as an LMI",
    "text": "CQLF as an LMI\nHaving formulated the problem of asymptotic stability using functions, we now rewrite it using matrices as an LMI: \n\\begin{aligned}\n\\mathbf P &\\succ 0,\\\\\n\\mathbf A_1^\\top \\mathbf P + \\mathbf P\\mathbf A_1 &\\prec 0,\\\\\n\\mathbf A_2^\\top \\mathbf P + \\mathbf P\\mathbf A_2 &\\prec 0,\\\\\n& \\vdots \\\\\n\\mathbf A_r^\\top \\mathbf P + \\mathbf P\\mathbf A_r &\\prec 0.\n\\end{aligned}",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#solving-in-matlab-using-yalmip-or-cvx",
    "href": "stability_via_common_lyapunov_function.html#solving-in-matlab-using-yalmip-or-cvx",
    "title": "Stability via common Lyapunov function",
    "section": "Solving in Matlab using YALMIP or CVX",
    "text": "Solving in Matlab using YALMIP or CVX\nMost numerical solvers for semidefinite programs (SDP) can only handle nonstrict inequalities. We can enforce strict inequality by introducing some small \\epsilon&gt;0: \n\\begin{aligned}\n\\mathbf P &\\succeq \\epsilon I,\\\\\n\\mathbf A_1^\\top \\mathbf P + \\mathbf P\\mathbf A_1 &\\preceq \\epsilon I,\\\\\n\\mathbf A_2^\\top \\mathbf P + \\mathbf P\\mathbf A_2 &\\preceq \\epsilon \\mathbf I,\\\\\n& \\vdots \\\\\n\\mathbf A_r^\\top \\mathbf P + \\mathbf P\\mathbf A_r &\\preceq \\epsilon \\mathbf I.\n\\end{aligned}\n\nFor LMIs with no affine term, we can multiply them (by 1/\\epsilon) to get the identity matrix on the right-hand side: \n\\begin{aligned}\n\\mathbf P &\\succeq \\mathbf I,\\\\\n\\mathbf A_1^\\top \\mathbf P + \\mathbf P\\mathbf A_1 &\\preceq \\mathbf I,\\\\\n\\mathbf A_2^\\top \\mathbf P + \\mathbf P\\mathbf A_2 &\\preceq \\mathbf I,\\\\\n& \\vdots \\\\\n\\mathbf A_r^\\top \\mathbf P + \\mathbf P\\mathbf A_r &\\preceq \\mathbf I.\n\\end{aligned}",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#solution-set-of-an-lmi-is-convex",
    "href": "stability_via_common_lyapunov_function.html#solution-set-of-an-lmi-is-convex",
    "title": "Stability via common Lyapunov function",
    "section": "Solution set of an LMI is convex",
    "text": "Solution set of an LMI is convex\nAn important property of a solution set of an LMI is that it is convex. Indeed, it is a crucial property. An implication is that if a solution \\mathbf P exists for the r inequalities, then it is also a solution for an inequality given by and convex combination of the matrices \\mathbf A_i. That is, if a solution \\mathbf P=\\mathbf P^\\top \\succ 0 exists such that \n\\begin{aligned}\n\\mathbf A_1^\\top \\mathbf P + \\mathbf P\\mathbf A_1 &\\prec 0,\\\\\n\\mathbf A_2^\\top \\mathbf P + \\mathbf P\\mathbf A_2 &\\prec 0,\\\\\n& \\vdots \\\\\n\\mathbf A_r^\\top \\mathbf P + \\mathbf P\\mathbf A_r &\\prec 0,\n\\end{aligned}\n then \\mathbf P also solves the convex combination \n\\left(\\sum_{i=1}^r\\alpha_i \\mathbf A_i\\right)^\\top \\mathbf P + \\mathbf P\\left(\\sum_{i=1}^r\\alpha_i \\mathbf A_i\\right) \\prec 0,\n where \\alpha_1, \\alpha_2, \\ldots, \\alpha_r \\geq 0 and \\sum_i \\alpha_i = 1.\nThis leads to an interesting interpretation of the requirement of (asymptotic) stability in presence of arbitrary switching – every convex combination of the systems is stable. While we do not exploit it in our course, note that it can be used in robust control design – an uncertain system is modelled by a convex combination of some vertex models. When designing a single (robust) controller, it is sufficient to guarantee stability of the vertex models using a single Lyapunov function, and the convexity property ensures that the controller is also robust with respect to the uncertain system. A powerful property! On the other hand, rather too strong because it allows arbitrarily fast changes of parameters.\nNote that we can use the convexity property when formulating this problem equivalently as the problem of stability analysis of the linear differential inclusion \n\\dot{\\bm x} \\in \\mathcal{F}(\\bm x),\n where \\mathcal{F}(\\bm x) = \\overline{\\operatorname{co}}\\{\\mathbf A_1\\bm x, \\mathbf A_2\\bm x, \\ldots, \\mathbf A_r\\bm x\\}.",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#what-if-quadratic-lf-is-not-enough",
    "href": "stability_via_common_lyapunov_function.html#what-if-quadratic-lf-is-not-enough",
    "title": "Stability via common Lyapunov function",
    "section": "What if quadratic LF is not enough?",
    "text": "What if quadratic LF is not enough?\nSo far we considered quadratic Lyapunov functions – and tt may be useful to display their prescription explicitly in the scalar form \n\\begin{aligned}\nV(\\bm x) &= \\bm x^\\top \\mathbf P \\bm x\\\\\n&= \\begin{bmatrix}x_1 & x_2\\end{bmatrix} \\begin{bmatrix} p_{11} & p_{12}\\\\ p_{12} & p_{22}\\end{bmatrix} \\begin{bmatrix}x_1\\\\ x_2\\end{bmatrix}\\\\\n&= p_{11}x_1^2 + 2p_{12}x_1x_2 + p_{22}x_2\n\\end{aligned}\n to show that, indeed, a quadratic Lyapunov function is a (multivariate) quadratic polynomial.\nNow, if quadratic polynomials are not enough, it is natural to consider polynomials of a higher degree. The crucial question is, however: how do we enforce positive definiteness?",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#positivenonnegative-polynomials",
    "href": "stability_via_common_lyapunov_function.html#positivenonnegative-polynomials",
    "title": "Stability via common Lyapunov function",
    "section": "Positive/nonnegative polynomials",
    "text": "Positive/nonnegative polynomials\nThe question that we ask is this: is the polynomial p(\\bm x), \\; \\bm x\\in \\mathbb R^n, positive (or at least nonnegative) on the whole \\mathbb R^n? That is, we ask if \np(\\bm x) &gt; 0,\\quad (\\text{or}\\quad p(\\bm x) \\geq 0)\\; \\forall \\bm x\\in\\mathbb R^n.\n\n\nExample 1 Consider the polynomial p(\\bm x)= 2x_1^4 + 2x_1^3x_2 - x_1^2x_2^2 + 5x_2^4. Is it nonnegative for all x_1\\in\\mathbb R, x_2\\in\\mathbb R?\n\nAdditionally, \\bm x can be restricted to some \\mathcal X\\sub \\mathbb R^n and we ask if\n\n  p(\\bm x) \\geq 0 \\;\\forall\\; \\bm x\\in \\mathcal X.\n\nOnce we started working with polynomials, semialgebraic sets \\mathcal X are often considered, asthese are defined by polynomial inequalities such as \ng_j(\\bm x) \\geq 0, \\; j=1,\\ldots, m.\n\nBut this we are only going to need in the next chapter, when we consider Multiple Lyapunov Functions (MLF) approach to stability analysis.\n\nHow can we check positivity/nonnegativity of polynomials?\nGridding is certainly not the way to go – we need conditions on the coefficients of the polynomial so that we can do some optimization later.\n\nExample 2 Consider a univariate polynomial \np(x) = x^4 - 4x^3 + 13x^2 - 18x + 17.\n Does it hold that p(x)\\geq 0 \\; \\forall x\\in \\mathbb R? Without plotting (hence gridding) we can hardly say. But what if we learn that the polynomial can be written as \np = (x-1)^2 + (x^2 - 2x + 4)^2\n\nObviously, whatever the two squared polynomials are, after squaring they become nonnegative. And summing nonnegative numbers yields a nonnegative result. Let’s generalize this.",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#sum-of-squares-sos-polynomials",
    "href": "stability_via_common_lyapunov_function.html#sum-of-squares-sos-polynomials",
    "title": "Stability via common Lyapunov function",
    "section": "Sum of squares (SOS) polynomials",
    "text": "Sum of squares (SOS) polynomials\nIf we can express the polynomial as a sum of squares (SOS) of some other polynomials, the original polynomial is nonnegative, that is, \n\\boxed{p(\\bm x) = \\sum_{i=1}^k p_i(\\bm x)^2\\; \\Rightarrow \\; p(\\bm x) \\geq 0,\\; \\forall \\bm x\\in \\mathbb R^n.}\n\nThe converse does not hold in general – not every nonnegative polynomial is SOS! There are only three cases, for which SOS is a necessary and sufficient condition of nonnegativeness:\n\nn=1: univariate polynomials. The degree (the highest power) d can be arbitrarily high (but even, obviously),\nd = 2 and n is arbitrary: multivariate polynomials of degree two (note that for p(\\bm x) = x_1^2 + x_1x_2^2 the degree d=3).\nn=2 and d = 4: bivariate polynomials of degree 4 (at maximum).\n\nFor all other cases all we can say is that p(\\bm x)\\, \\text{is}\\, \\mathrm{SOS} \\Rightarrow p(\\bm x)\\geq 0\\, \\forall \\bm x\\in \\mathbb R^n.\n\n\n\n\n\n\nNote\n\n\n\nHilbert conjectured in 1900 in the 17th problem that every nonnegative polynomial can be written as a sum of squares of rational functions. This was later proved correct. It turns out, that this fact is not as useful as the SOS using polynomials because of impossibility to state apriori the bounds on the degrees of the polynomials defining those rational functions.",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#how-to-get-an-sos-representation-of-a-polynomial-or-prove-that-none-exist",
    "href": "stability_via_common_lyapunov_function.html#how-to-get-an-sos-representation-of-a-polynomial-or-prove-that-none-exist",
    "title": "Stability via common Lyapunov function",
    "section": "How to get an SOS representation of a polynomial (or prove that none exist)?",
    "text": "How to get an SOS representation of a polynomial (or prove that none exist)?\n\nUnivariate case\nBack to the univariate example first. And we do it through an example.\n\nExample 3 We consider the polynomial in the Example 2. One of the two squared polynomials is x^2 - 2x + 4. We can write it as x^2 - 2x + 4 = \\underbrace{\\begin{bmatrix}4 & -2 & 1\\end{bmatrix}}_{\\bm v^\\top} \\underbrace{\\begin{bmatrix} 1 \\\\ x \\\\ x^2\\end{bmatrix}}_{\\bm z}.\n\nThen the squared polynomial can be written as \n(x^2 - 2x + 4)^2 = \\bm z^\\top \\bm v \\bm v^\\top \\bm z.\n\nNote that the the product \\bm v \\bm v^\\top is a positive semidefinite matrix of rank one.\nWe can similarly express the second squared polynomial \nx-1 = \\underbrace{\\begin{bmatrix} -1 & 1 & 0\\end{bmatrix}}_{\\bm v^\\top} \\underbrace{\\begin{bmatrix} 1 \\\\ x \\\\ x^2\\end{bmatrix}}_{\\bm z}\n and then \n(x - 1)^2 = \\bm z^\\top \\begin{bmatrix} -1 \\\\ 1 \\\\ 0\\end{bmatrix} \\begin{bmatrix} -1 & 1 & 0\\end{bmatrix} \\bm z.\n\nSumming the two squares we get the original polynomial. But while doing this, we can sum the two rank-one matrices. \n\\begin{aligned}\np(x) &= x^4 - 4x^3 + 13x^2 - 18x + 17\\\\\n&= \\begin{bmatrix} 1 & x & x^2\\end{bmatrix} \\bm P \\begin{bmatrix} 1 \\\\ x \\\\ x^2\\end{bmatrix}\n\\end{aligned},\n where \\bm P\\succeq 0 is \n\\bm P = \\underbrace{\\begin{bmatrix} 4 \\\\ -2 \\\\ 1\\end{bmatrix} \\begin{bmatrix} 4 & -2 & 1\\end{bmatrix}}_{\\mathbf P_1} + \\underbrace{\\begin{bmatrix} -1 \\\\ 1 \\\\ 0\\end{bmatrix} \\begin{bmatrix} -1 & 1 & 0\\end{bmatrix}}_{\\mathbf P_2}\n\nThe matrix that defines the quadratic form is positive semidefinite and of rank 2. Indeed, the rank of the matrix is given by the number of squared terms in the SOS decomposition.\n\n\n\nMultivariate case\nIn a general multivariate case we can proceed similarly. Just form the vector \\bm z from all possible monomials: \n  \\bm z = \\begin{bmatrix}1 \\\\ x_1 \\\\ x_2 \\\\  \\\\ \\vdots \\\\ x_n\\\\ x_1^2 \\\\ x_1 x_2 \\\\ \\vdots \\\\ x_n^2\\\\\\vdots \\\\x_1x_2\\ldots x_n^{2}\\\\ \\vdots \\\\ x_n^d \\end{bmatrix}\n\nBut how to determine the coefficients of the matrix? We again show it by means of an example.\n\nWe consider the polynomial p(x_1,x_2)=2x_1^4 +2x_1^3x_2 − x_1^2x_2^2 +5x_2^4. We define the vector \\bm z as \n\\bm z = \\begin{bmatrix} x_1^2 \\\\ x_1x_2 \\\\ x_2^2\\end{bmatrix}.\n\nNote that we could also write it fully as \n\\bm z = \\begin{bmatrix} 1 \\\\ x_1\\\\ x_2\\\\ x_1^2 \\\\ x_1x_2 \\\\ x_2^2\\end{bmatrix},\n but we can see that the first three terms are not going to be needed. If you still cannot see it, feel free to continue with the full version of \\bm z, no problem.\nThen the polynomial can be written as \np(x_1,x_2)=\\begin{bmatrix} x_1^2 \\\\ x_1x_2 \\\\ x_2^2\\end{bmatrix}^\\top \\begin{bmatrix} p_{11} & p_{12} & p_{13}\\\\ p_{12} & p_{22} & p_{23}\\\\p_{13} & p_{23} & p_{33}\\end{bmatrix} \\begin{bmatrix} x_1^2 \\\\ x_1x_2 \\\\ x_2^2\\end{bmatrix}.\n\nAfter multiplying the producs out, we get \n\\begin{aligned}\np(x_1,x_2)&={\\color{blue}p_{11}}x_1^4 + {\\color{blue}p_{33}}x_2^4 \\\\\n&\\quad + {\\color{blue}2p_{12}}x_1^3x_2 + {\\color{blue}2p_{23}}x_1x_2^3\\\\\n&\\quad + {\\color{blue}(2p_{13} + p_{22})}x_1^2x_2^2\n\\end{aligned}\n\nThere are now 5 coefficients in the above polynomial (they are highlighted in blue). Equating them to some particular values gives 5 equations.\nBut the matrix \\mathbf P is parameterized by 6 coefficients. Hence we need one more equation. The sixth is the LMI condition \\mathbf P\\succeq 0.",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#searching-for-a-sos-polynomial-lyapunov-function",
    "href": "stability_via_common_lyapunov_function.html#searching-for-a-sos-polynomial-lyapunov-function",
    "title": "Stability via common Lyapunov function",
    "section": "Searching for a SOS polynomial Lyapunov function",
    "text": "Searching for a SOS polynomial Lyapunov function\nWe can now formulate the search for a nonnegative polynomial function V(\\bm x) as a search within the set of SOS polynomials of a prescribed degree d.\nHowever, for a Lyapunov function, we need positiveness (actually positive definiteness), not just nonnegativeness.Therefore, instead of V(\\bm x) \\; \\text{is SOS}, we are going to impose the condition \n\\boxed{\nV(\\bm x) - \\phi(\\bm x) \\; \\text{is SOS},}\n where \\phi(\\bm x) = \\gamma \\sum_{i=1}^n\\sum_{j=1}^{d} x_i^{2j} for some (typically very small) \\gamma &gt; 0. This is pretty much the same trick that we used in the LMI formulation when we needed enforce strict inequalities.\nWhat remains to complete the conditions for Lyapunov stability, is to express the requirement that the time derivative of V(\\bm x) is nonpositive. This can also be done by requiring that minus the time derivative of the polynomial Lyapunov function, which is a polynomial too, is SOS too.\n\n\\boxed\n{-\\nabla V(\\bm x)^\\top \\mathbf f(\\bm x)\\; \\text{is SOS}.}\n\nIf asymptotic stability is required instead of just Lyapunov one, the condition is that the time derivative is strictly negative, that is, we can require that \n\\boxed\n{-\\nabla V(\\bm x)^\\top \\mathbf f(\\bm x) - \\phi(\\bm x)\\; \\text{is SOS}.}",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "stability_via_common_lyapunov_function.html#searching-for-a-sos-polynomial-common-lyapunov-function",
    "href": "stability_via_common_lyapunov_function.html#searching-for-a-sos-polynomial-common-lyapunov-function",
    "title": "Stability via common Lyapunov function",
    "section": "Searching for a SOS polynomial common Lyapunov function",
    "text": "Searching for a SOS polynomial common Lyapunov function\nBack to hybrid systems. For Lyapunov stability, the problem is to find V(\\bm x) such that\n\n\\boxed{\n\\begin{aligned}  \nV(\\bm x) - \\phi(\\bm x) \\; &\\text{is SOS},\\\\\n-\\nabla V(\\bm x)^\\top \\mathbf f_1(\\bm x)\\; &\\text{is SOS},\\\\\n-\\nabla V(\\bm x)^\\top \\mathbf f_2(\\bm x)\\; &\\text{is SOS},\\\\\n\\vdots\\\\\n-\\nabla V(\\bm x)^\\top \\mathbf f_r(\\bm x)\\; &\\text{is SOS},\n\\end{aligned}\n}\n while for asymptotic stability, the conditions are \n\\boxed{\n\\begin{aligned}  \nV(\\bm x) - \\phi(\\bm x) \\; &\\text{is SOS},\\\\\n-\\nabla V(\\bm x)^\\top \\mathbf f_1(\\bm x) - \\phi(\\bm x)\\; &\\text{is SOS},\\\\\n-\\nabla V(\\bm x)^\\top \\mathbf f_2(\\bm x) - \\phi(\\bm x)\\; &\\text{is SOS},\\\\\n\\vdots\\\\\n-\\nabla V(\\bm x)^\\top \\mathbf f_r(\\bm x) - \\phi(\\bm x)\\; &\\text{is SOS}.\n\\end{aligned}\n}",
    "crumbs": [
      "8. Stability",
      "Stability via common Lyapunov function"
    ]
  },
  {
    "objectID": "mld_logic_vs_inequalities.html",
    "href": "mld_logic_vs_inequalities.html",
    "title": "Logic vs inequalities",
    "section": "",
    "text": "Our goal is to reformulate the logical conditions (such as IF-THEN-ELSE) encountered in the discrete hybrid model (DHA) as inequalities (and possibly equations), which will allow us to formulate the model as a mathematical program, actually a mixed-integer program (MIP). In order to get there, we are going to recap some fundamentals of logic and then we are going to show how various logical conditions can be reformulated as linear inequalities.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Logic vs inequalities"
    ]
  },
  {
    "objectID": "mld_logic_vs_inequalities.html#propositional-logic-and-connectives",
    "href": "mld_logic_vs_inequalities.html#propositional-logic-and-connectives",
    "title": "Logic vs inequalities",
    "section": "Propositional logic and connectives",
    "text": "Propositional logic and connectives\nPropositions (also logical formulas) are either true or false. They are composed of elementary or atomic propositions (also Boolean variables) and connectives.\n\nBoolean variable (or elementary proposition)\nX evaluates to true or false. Oftentimes values 0 and 1 are used, but it should be clear that these are not numbers but symbols that represent logical values.\n\n\nConnectives\n\nConjunction (logical and): X_1 \\land X_2\nDisjunction (logical or): X_1 \\lor X_2\nNegation: \\neg X_2\nImplication: X_1 \\rightarrow X_2\nEquivalence: X_1 \\leftrightarrow X_2\nLogical XOR: X_1 \\oplus X_2",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Logic vs inequalities"
    ]
  },
  {
    "objectID": "mld_logic_vs_inequalities.html#equivalences-of-logical-propositions",
    "href": "mld_logic_vs_inequalities.html#equivalences-of-logical-propositions",
    "title": "Logic vs inequalities",
    "section": "Equivalences of logical propositions",
    "text": "Equivalences of logical propositions\nWe will heavily used the following equivalences between logical propositions: \n\\begin{aligned}\nX_1 \\rightarrow X_2 \\qquad  &\\equiv \\qquad \\neg X_2 \\rightarrow \\neg X_1,\\\\\nX_1 \\leftrightarrow X_2 \\qquad  &\\equiv \\qquad (X_1 \\rightarrow X_2) \\land (X_2 \\rightarrow X_1),\\\\\nX_1 \\land X_2 \\qquad  &\\equiv \\qquad \\neg (\\neg X_1 \\lor \\neg X_2),\\\\\nX_1 \\rightarrow X_2 \\qquad  &\\equiv \\qquad \\neg X_1 \\lor X_2.\n\\end{aligned}\n\nThe first three are certainly well known. If the last one does not look familiar, it can be seen as follows: for no X_1 and X_2 does X1 \\land \\neg X2 evaluate to true. In other words, \\neg(X1 \\land \\neg X2) is true. De Morgan then gives \\neg X1 \\lor X2.\n\n\n\n\n\n\nTwo kinds of equivalence\n\n\n\nIt may be confusing that we use the term equivalence in two different meanings here and with two different symbols. Indeed, the symbol \\leftrightarrow (sometimes also called material equivalence or biconditional) is a part of the logical proposition, while the symbol \\equiv is used to relate two logical propositions. While this is well established and described in the literature, the notation varies wildly. In particular, beware that the symbol \\iff can frequently be encountered in both contexts (that is why we avoid it here). On the other hand, we take the liberty to refer to both cases just as the equivalence, hoping that the context will make it clear which one is meant.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Logic vs inequalities"
    ]
  },
  {
    "objectID": "mld_logic_vs_inequalities.html#binary-variables-related-to-the-boolean-ones",
    "href": "mld_logic_vs_inequalities.html#binary-variables-related-to-the-boolean-ones",
    "title": "Logic vs inequalities",
    "section": "Binary variables related to the Boolean ones",
    "text": "Binary variables related to the Boolean ones\nUltimately we want to use numerical solvers to solve optimization problems. In order to do that, we need to associate with the Boolean variable X a binary (integer) variable \\delta\\in\\{0,1\\} such that \n\\delta =\n\\begin{cases}\n0 & \\text{if} \\; \\neg X,\\\\\n1 & \\text{if} \\; X.\n\\end{cases}\n\nIn other words, have the the following equivalence X \\quad \\leftrightarrow \\quad [\\delta = 1].\n\n\n\n\n\n\nRedudant (but convenient) use of brackets\n\n\n\nStrictly speaking, the brackets are redundant here. We can equally well write X \\leftrightarrow \\delta = 1, assuming precedence of = over \\leftrightarrow. In this regard, the role of the brackets is really just to emphasize the precedence visually. There is also nothing special about the square brackets, we could equally well write X \\leftrightarrow (\\delta = 1).",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Logic vs inequalities"
    ]
  },
  {
    "objectID": "mld_logic_vs_inequalities.html#integer-equations-and-inequalities-related-to-the-logical-formulas",
    "href": "mld_logic_vs_inequalities.html#integer-equations-and-inequalities-related-to-the-logical-formulas",
    "title": "Logic vs inequalities",
    "section": "Integer equations and (in)equalities related to the logical formulas",
    "text": "Integer equations and (in)equalities related to the logical formulas\nHaving introduced binary variables, we now aim at reformulating logical formulas into equivalent integer equalities or inequalities. Let’s investigage one logical connective after another.\n\nAnd (conjunction)\nWe first consider the conjunction of two logical variables X_1 and X_2: X_1 \\land X_2.\nInvoking binary variables, we can rewrite this as [\\delta_1=1] \\land [\\delta_2=1], which ultimately translates to the system of two (trivial) equations \n\\begin{aligned}\n\\delta_1&=1,\\\\\n\\delta_2&=1.\n\\end{aligned}\n\nAnother possibility is \n\\delta_1 + \\delta_2 = 2.\n From the perspective of subsequent optimization for which this constitutes a constraint, hardly anything can be gained by this formulation compared to the previous one.\nYet another possibility is \\delta_1 \\delta_2 = 1, but we discard it immediately, because it is nonlinear and it provides not advantage over the previous linear formulation.\n\n\nOr (disjunction)\nAnother logical formula is X_1 \\lor X_2,  which with binary variables becomes [\\delta_1=1] \\lor [\\delta_2=1].\nIt can be equivalently expressed as \\delta_1 + \\delta_2\\geq 1.\n\n\nNegation\nThe negation \\neg X_1 expressed using a binary variable as in \\neg [\\delta_1=1] leads to the equation \\delta_1 = 0.\n\n\nXor\nThe exclusive OR X_1 \\oplus X_2,\n[\\delta_1=1] \\oplus [\\delta_2=1],\nleads to the equation \\delta_1 + \\delta_2 = 1.\n\n\nImplication\nWe now consider the implication X_1 \\rightarrow X_2,\n[\\delta_1=1] \\rightarrow [\\delta_2=1].\nWe can take advantage of the equivalent formula \\neg X_1 \\lor X_2, which in terms of binary variables is \\neg [\\delta_1=1] \\lor [\\delta_2=1], which can be equivalently expressed as an inequality (1-\\delta_1) + \\delta_2\\geq 1, which further simplifies to \\delta_1 - \\delta_2 \\leq 0.\n\n\nEquivalence\nThe equivalence X_1 \\leftrightarrow X_2, [\\delta_1=1] \\leftrightarrow [\\delta_2=1] can be viewed as a conjunction of two implications, which then gives \\delta_1 - \\delta_2 = 0.\n\n\nAssignment (product)\nWe now investigate the following logical formula X_3 \\leftrightarrow (X_1 \\land X_2), which after introducing binary variables becomes [\\delta_3=1] \\leftrightarrow ([\\delta_1=1] \\land [\\delta_2=1]).\nThe motivation as well as the justification of the name(s) will become clear later in this section when we discuss the interplay between logic and continuous variables (the IF-THEN-ELSE case).\nExpressing the equivalence using implications (X_3 \\rightarrow X_1) \\land (X_3\\rightarrow X_2) \\land ((X_1 \\land X_2) \\rightarrow X_3).\nThe last of the tree terms connected by the \\land connective is equivalent to \\neg (X_1 \\land X_2) \\lor X_3, which can be simplified to \\neg X_1 \\lor \\neg X_2 \\lor X_3, which is represented with binary variables as \\neg [\\delta_1=1] \\lor \\neg [\\delta_2 = 1] \\lor [\\delta_3 = 1], which finally leads to the linear inequality (1-\\delta_1) + (1-\\delta_2) + \\delta_3 \\geq 1.\nAfter simplification, and brinding in also the inequality formulations for the other two terms, we get \n\\begin{aligned}\n\\delta_1 + \\delta_2 - \\delta_3 &\\leq 1,\\\\\n-\\delta_1 + \\delta_3 &\\leq 0,\\\\\n-\\delta_2 + \\delta_3 &\\leq 0.\n\\end{aligned}\n\\tag{1}\n\n\nGeneral transformation of Boolean expressions to integer inequalities\nWhile logical formulas can be fairly diverse, it is often advantageous to use equivalences to reformulate them into some special forms. One particular form that we prefer here is the Conjunctive Normal Form (CNF) \n\\bigwedge_{j=1}^m \\left[\\left(\\lor_{i\\in \\mathcal{P}_j} X_i\\right) \\lor \\left(\\lor_{i\\in \\mathcal{N}_j} \\neg X_i\\right)\\right].\n\nThe reason for our preference has already been displayed in Eq. 1 above. Namely, the logical conjunction \\land translates to the requirement of a simultaneous satisfaction of inequalities or equations as in \n\\begin{aligned}\n\\sum_{i\\in \\mathcal{P}_1} \\delta_i + \\sum_{i\\in \\mathcal{N}_1} (1-\\delta_i) &\\geq 1,\\\\\n&\\vdots\\\\\n\\sum_{i\\in \\mathcal{P}_m} \\delta_i + \\sum_{i\\in \\mathcal{N}_m} (1-\\delta_i) &\\geq 1.\n\\end{aligned}",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Logic vs inequalities"
    ]
  },
  {
    "objectID": "hybrid_equations.html",
    "href": "hybrid_equations.html",
    "title": "Hybrid equations",
    "section": "",
    "text": "Here we introduce a major alternative framework to hybrid automata for modelling hybrid systems. It is called hybrid equations, sometimes also hybrid state equations to emphasize that what we are after is some kind of analogy with state equations \\dot{x}(t) = f(x(t), u(t)) and x_{k+1} = g(x_k, u_k) that we are familiar with from (continuous-valued) dynamical systems. Sometimes it is also called event-flow equations or jump-flow equations.\nThese are the key ideas:\nThe major advantage of this modeling framework is that we do not have to distinguish between the two types of state variables. This is in contrast with hybrid automata, where we have to start by classifying the state variables as either continuous or discrete before moving on. In the current framework we treat all the variables identically – they mostly flow and occasionally (perhaps never, which is OK) jump.",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Hybrid equations"
    ]
  },
  {
    "objectID": "hybrid_equations.html#hybrid-equations",
    "href": "hybrid_equations.html#hybrid-equations",
    "title": "Hybrid equations",
    "section": "Hybrid equations",
    "text": "Hybrid equations\nIt is high time to introduce hybrid (state) equations – here they come \n\\begin{aligned}\n\\dot{x} &= f(x), \\quad x \\in \\mathcal{C},\\\\\nx^+ &= g(x), \\quad x \\in \\mathcal{D},\n\\end{aligned}\n where\n\nf: \\mathcal{C} \\rightarrow \\mathbb R^n is the flow map,\n\\mathcal{C}\\subset \\mathbb R^n is the flow set,\ng: \\mathcal{D} \\rightarrow \\mathbb R^n is the jump map,\n\\mathcal{D}\\subset \\mathbb R^n is the jump set.\n\nThis model of a hybrid system is thus parameterized by the quadruple \\{f, \\mathcal C, g, \\mathcal D\\}.",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Hybrid equations"
    ]
  },
  {
    "objectID": "hybrid_equations.html#hybrid-inclusions",
    "href": "hybrid_equations.html#hybrid-inclusions",
    "title": "Hybrid equations",
    "section": "Hybrid inclusions",
    "text": "Hybrid inclusions\nWe now extend the presented framework of hybrid equations a bit. Namely, the functions on the right-hand sides in both the differential and the difference equations are no longer assigning just a single value (as well-behaved functions do), but they assign sets! \n\\begin{aligned}\n\\dot{x} &\\in \\mathcal F(x), \\quad x \\in \\mathcal{C},\\\\\nx^+ &\\in \\mathcal G(x), \\quad x \\in \\mathcal{D}.\n\\end{aligned}\n where\n\n\\mathcal{F} is the set-valued flow map,\n\\mathcal{C} is the flow set,\n\\mathcal{G} is the set-valued jump map,\n\\mathcal{D} is the jump set.",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Hybrid equations"
    ]
  },
  {
    "objectID": "hybrid_equations.html#output-equations",
    "href": "hybrid_equations.html#output-equations",
    "title": "Hybrid equations",
    "section": "Output equations",
    "text": "Output equations\nTypically a full model is only formed upon defining some output variables (oftentimes just a subset of possibly scaled state variables or their linear combinations). These output variables then obey some output equation \ny(t) = h(x(t)),\n\nor \ny(t) = h(x(t),u(t)).\n\n\nExample 1 (Bouncing ball) This is the “hello world example” for hybrid systems with state jumps (pun intended). The state variables are the height and the vertical speed of the ball. \n\\bm x \\in \\mathbb{R}^2, \\qquad \\bm x = \\begin{bmatrix}x_1 \\\\ x_2\\end{bmatrix}.\n\nThe quadruple defining the hybrid equations is \n\\mathcal{C} = \\{\\bm x \\in \\mathbb{R}^2 \\mid x_1&gt;0 \\lor (x_1 = 0, x_2\\geq 0)\\},\n \nf(\\bm x) = \\begin{bmatrix}x_2 \\\\ -g\\end{bmatrix}, \\qquad g = 9.81,\n \n\\mathcal{D} = \\{\\bm x \\in \\mathbb{R}^2 \\mid x_1 = 0, x_2 &lt; 0\\},\n \ng(\\bm x) = \\begin{bmatrix}x_1 \\\\ -\\alpha x_2\\end{bmatrix}, \\qquad \\alpha = 0.8.\n\nThe two sets and two maps are illustrated below.\n\n\n\n\n\n\nFigure 1: Maps and sets for the bouncing ball example\n\n\n\n\n\nExample 2 (Bouncing ball on a controlled piston) We now extend the simple bouncing ball example by adding a vertically moving piston. The piston is controlled by a force.\n\n\n\nExample of a ball bouncing on a vertically moving piston\n\n\nIn our analysis we neglect the sizes (for simplicity).\nThe collision happens when x_\\mathrm{b} = x_\\mathrm{p}, and v_\\mathrm{b} &lt; v_\\mathrm{p}.\nThe conservation of momentum after a collision reads \nm_\\mathrm{b}v_\\mathrm{b}^+ + m_\\mathrm{p}v_\\mathrm{p}^+ = m_\\mathrm{b}v_\\mathrm{b} + m_\\mathrm{p}v_\\mathrm{p}.\n\\tag{1}\nThe collision is modelled using a restitution coefficient \nv_\\mathrm{p}^+ - v_\\mathrm{b}^+ = -\\gamma (v_\\mathrm{p} - v_\\mathrm{b}).\n\\tag{2}\nFrom the momentum conservation Eq. 1 \nv_\\mathrm{p}^+ = \\frac{m_\\mathrm{b}}{m_\\mathrm{p}}v_\\mathrm{b} + v_\\mathrm{p} - \\frac{m_\\mathrm{b}}{m_\\mathrm{p}}v_\\mathrm{b}^+\n\nwe substitute to Eq. 2 to get \n\\frac{m_\\mathrm{b}}{m_\\mathrm{p}}v_\\mathrm{b} + v_\\mathrm{p} - \\frac{m_\\mathrm{b}}{m_\\mathrm{p}}v_\\mathrm{b}^+ - v_\\mathrm{b}^+ = -\\gamma (v_\\mathrm{p} - v_\\mathrm{b}),\n from which we express v_\\mathbb{b}^+ \n\\begin{aligned}\nv_\\mathrm{b}^+ &= \\frac{1}{1+\\frac{m_\\mathrm{b}}{m_\\mathrm{p}}}\\left(\\frac{m_\\mathrm{b}}{m_\\mathrm{p}}v_\\mathrm{b} + v_\\mathrm{p} + \\gamma (v_\\mathrm{p} - v_\\mathrm{b})\\right)\\\\\n&= \\frac{m_\\mathrm{p}}{m_\\mathrm{p}+m_\\mathrm{b}}\\left(\\frac{m_\\mathrm{b}-\\gamma m_\\mathrm{p}}{m_\\mathrm{p}}v_\\mathrm{b} + (1+\\gamma)v_\\mathrm{p}\\right)\\\\\n&= \\frac{m_\\mathrm{b}-\\gamma m_\\mathrm{p}}{m_\\mathrm{b}+m_\\mathrm{p}}v_\\mathrm{b} + \\frac{(1+\\gamma)m_\\mathrm{p}}{m_\\mathrm{p}+m_\\mathrm{b}}v_\\mathrm{p}\n\\end{aligned}.\n\nSubstitute to the expression for v_\\mathbb{p}^+ to get \n\\begin{aligned}\nv_\\mathrm{p}^+ &= \\frac{m_\\mathrm{b}}{m_\\mathrm{p}}v_\\mathrm{b} + v_\\mathrm{p} - \\frac{m_\\mathrm{b}}{m_\\mathrm{p}}\\left(\\frac{m_\\mathrm{b}-\\gamma m_\\mathrm{p}}{m_\\mathrm{b}+m_\\mathrm{p}}v_\\mathrm{b} + \\frac{(1+\\gamma)m_\\mathrm{p}}{m_\\mathrm{p}+m_\\mathrm{b}}v_\\mathrm{p}\\right)\\\\\n&= \\frac{m_\\mathrm{b}}{m_\\mathrm{p}}\\left(1-\\frac{m_\\mathrm{b}-\\gamma m_\\mathrm{p}}{m_\\mathrm{b}+m_\\mathrm{p}}\\right) v_\\mathrm{b} \\\\\n&\\qquad\\qquad + \\left(1-\\frac{m_\\mathrm{b}}{m_\\mathrm{p}}\\frac{(1+\\gamma)m_\\mathrm{p}}{m_\\mathrm{p}+m_\\mathrm{b}}\\right) v_\\mathrm{p}\\\\\n&= \\frac{m_\\mathrm{b}}{m_\\mathrm{b}+m_\\mathrm{p}}(1+\\gamma) v_\\mathrm{b} + \\frac{m_\\mathrm{p}-\\gamma m_\\mathrm{b}}{m_\\mathrm{p}+m_\\mathrm{b}} v_\\mathrm{p}.\n\\end{aligned}\n\nFinally we can simplify the expressions a bit by introducing m=\\frac{m_\\mathrm{b}}{m_\\mathrm{b}+m_\\mathrm{p}}. The jump equation is then \n\\begin{bmatrix}\nv_\\mathrm{b}^+\\\\\nv_\\mathrm{p}^+\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nm - \\gamma (1-m) & (1+\\gamma)(1-m)\\\\\nm(1+\\gamma) & 1-m-\\gamma m\n\\end{bmatrix}\n\\begin{bmatrix}\nv_\\mathrm{b}\\\\\nv_\\mathrm{p}\n\\end{bmatrix}.\n\n\n\nExample 3 (Synchronization of fireflies) This is a famous example in synchronization. We consider n fireflies, x_i is the i-th firefly’s clock, normalized to [0,1]. The clock resets (to zero) when it reaches 1. Each firefly can see the flashing of all other fireflies. As soon as it observes a flash, it increases its clock by \\varepsilon \\%.\nHere is how we model the problem using the four-tuple \\{f, \\mathcal C, g, \\mathcal D\\}: \n\\mathcal{C} = [0,1)^n = \\{\\bm x \\in \\mathbb R^n\\mid x_i \\in [0,1),\\; i=1,\\ldots,n \\},\n \n\\bm f = [f_1, f_2, \\ldots, f_n]^\\top,\\quad f_i = 1, \\quad i=1,\\ldots,n,\n \n\\mathcal{D} = \\{\\bm x \\in [0,1]^n \\mid \\max_i x_i = 1 \\},\n\n\n\\begin{aligned}\n\\bm g &= [g_1, \\ldots, g_n]^\\top,\\\\\n& \\qquad g_i(x_i) =\n\\begin{cases}\n(1 + \\varepsilon)x_i, & \\text{if } (1+\\varepsilon)x_i &lt; 1, \\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\end{aligned}\n\n\n\nExample 4 (Thyristor control) Consider the circuit below.\n\n\n\n\n\n\nFigure 2: Example of a thyristor control\n\n\n\nWe consider a harmonic input voltage, that is, \n\\begin{aligned}\n\\dot v_0 &= \\omega v_1\\\\\n\\dot v_1 &= -\\omega v_0.\n\\end{aligned}\n\nThe thyristor can be on (discrete state q=1) or off (q=0). The firing time \\tau is given by the firing angle \\alpha \\in (0,\\pi).\nThe state vector is \n\\bm x =\n\\begin{bmatrix}\nv_0\\\\ v_1 \\\\ i_\\mathrm{L} \\\\ v_\\mathrm{C} \\\\ q \\\\ \\tau\n\\end{bmatrix}.\n\nThe flow map is \n\\bm f(\\bm x)\n=\n\\begin{bmatrix}\n\\omega v_1\\\\\n-\\omega v_0\\\\\nq \\frac{v_\\mathrm{C}-Ri_\\mathrm{L}}{L}\\\\\n-\\frac{1}{CR}v_\\mathrm{C} + \\frac{1}{CR}v_\\mathrm{0} - \\frac{1}{C}i_\\mathrm{L}\\\\\n0\\\\\n1\n\\end{bmatrix}.\n\nThe flow set is \n\\begin{aligned}\n\\mathcal{C} &= \\{\\bm x \\mid q=0,\\, \\tau&lt;\\frac{\\alpha}{\\omega},\\, i_\\mathrm{L}=0\\}\\\\ &\\qquad \\cup \\{\\bm x \\mid q=1,\\, i_\\mathrm{L}&gt;0\\}\n\\end{aligned}.\n\nThe jump set is \n\\begin{aligned}\n\\mathcal{D} &= \\{\\bm x \\mid q=0,\\, \\tau\\geq \\frac{\\alpha}{\\omega},\\, i_\\mathrm{L}=0,\\, v_\\mathrm{C}&gt;0\\}\\\\ &\\qquad \\cup \\{\\bm x \\mid q=1,\\, i_\\mathrm{L}=0,\\, v_\\mathrm{C}&lt;0\\}\n\\end{aligned}.\n\nThe jump map is \n\\bm g(\\bm x) =\n\\begin{bmatrix}\nu_0\\\\ u_1 \\\\ i_\\mathrm{L} \\\\ v_\\mathrm{C} \\\\ {\\color{red} 1-q} \\\\ {\\color{red} 0}\n\\end{bmatrix}.\n\nThe last condition in the jump set comes from the requirement that not only must the current through the inductor be zero, but also it must be decreasing. And from the state equation it follows that the voltage on the capacitor must be negative.\n\n\nExample 5 (Sampled-data feedback control) Another example of a dynamical system that fits nicely into the hybrid equations framework is sampled-data feedback control system. Within the feedback loop in Fig. 3, we recognize a continuous-time plant and a discrete-time controller.\n\n\n\n\n\n\nFigure 3: Sampled data feedback control\n\n\n\nThe plant is modelled by \\dot x_\\mathrm{p} = f_\\mathrm{p}(x_\\mathrm{p},u), \\; y = h(x_\\mathrm{p}). The controller samples the output T-periodically and computes its own output as a nonlinear function u = \\kappa(r-y).\nThe closed-loop model is then \n\\dot x_\\mathrm{p} = f_\\mathrm{p}(x_\\mathrm{p},\\kappa(r-h(x_\\mathrm{p}))), \\; y = h(x_\\mathrm{p}).\n\nThe closed-loop state vector is \n\\bm x =\n\\begin{bmatrix}\nx_\\mathrm{p}\\\\ u \\\\ \\tau\n\\end{bmatrix}\n\\in\n\\mathbb R^n \\times \\mathbb R^m \\times \\mathbb R.\n\nThe flow set is \n\\begin{aligned}\n\\mathcal{C} &= \\{\\bm x \\mid \\tau \\in [0,T)\\}\n\\end{aligned}\n\nThe flow map is \n\\bm f(\\bm x)\n=\n\\begin{bmatrix}\nf_\\mathrm{p}(x_\\mathrm{p},u)\\\\\n0\\\\\n1\n\\end{bmatrix}\n\nThe jump set is \n\\begin{aligned}\n\\mathcal{D} &= \\{\\bm x \\mid \\tau = T\\}\n\\end{aligned}\n or rather \n\\begin{aligned}\n\\mathcal{D} &= \\{\\bm x \\mid \\tau \\geq T\\}\n\\end{aligned}\n\nThe jump map is \n\\bm g(\\bm x) =\n\\begin{bmatrix}\nx_\\mathrm{p}\\\\\n\\kappa(r-y)\\\\\n0\n\\end{bmatrix}\n\nYou may wonder why we bother with modelling this system as a hybrid system at all. When it comes to analysis of the closed-loop system, implementation of the model in Simulink allows for seemless mixing of continuous-time and dicrete-time blocks. And when it comes to control design, we can either discretize the plant and design a discrete-time controller, or design a continuous-time controller and then discretize it. No need for new theoris. True, but still, it is nice to have a rigorous framework for analysis of such systems. The more so that the sampling time T may not be constant – it can either vary randomly or perhaps the samling can be event-triggered. All these scenarios are easily handled within the hybrid equations framework.",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Hybrid equations"
    ]
  },
  {
    "objectID": "hybrid_equations.html#hybridness-after-closing-the-loop",
    "href": "hybrid_equations.html#hybridness-after-closing-the-loop",
    "title": "Hybrid equations",
    "section": "Hybridness after closing the loop",
    "text": "Hybridness after closing the loop\nWe have defined hybrid systems, but what exactly is hybrid when we close a feedback loop? There are three possibilities:\n\nHybrid plant + continuous controller.\nHybrid plant + hybrid controller.\nContinuous plant + hybrid controller.\n\nThe first case is encountered when we use a standard controller such as a PID controller to control a system whose dynamics can be characterized/modelled as hybrid. The second scenario considers a controller that mimicks the behavior of a hybrid system. The third case is perhaps the least intuitive: although the plant to be controller is continuous(-valued), it may still make sense to design and implement a hybrid controller, see the next paragraph.",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Hybrid equations"
    ]
  },
  {
    "objectID": "hybrid_equations.html#impossibility-to-stabilize-without-a-hybrid-controller",
    "href": "hybrid_equations.html#impossibility-to-stabilize-without-a-hybrid-controller",
    "title": "Hybrid equations",
    "section": "Impossibility to stabilize without a hybrid controller",
    "text": "Impossibility to stabilize without a hybrid controller\n\nExample 6 (Unicycle stabilization) We consider a unicycle model of a vehicle in a plane, characterized by the position and orientation, with the controlled forward speed v and the yaw (turning) angular rate \\omega.\n\n\n\n\n\n\nFigure 4: Unicycle vehicle\n\n\n\nThe vehicle is modelled by \n\\begin{aligned}\n\\dot x &= v \\cos \\theta,\\\\\n\\dot y &= v \\sin \\theta,\\\\\n\\dot \\theta &= \\omega,\n\\end{aligned}\n\n\n\\bm x = \\begin{bmatrix}\nx\\\\ y\\\\ \\theta\n\\end{bmatrix},\n\\quad\n\\bm u = \\begin{bmatrix}\nv\\\\ \\omega\n\\end{bmatrix}.\n\nIt is known that this system cannot be stabilized by a continuous feedback controller. The general result that applies here was published in [1]. The condition of stabilizability by a time-invariant continuous state feedback is that the image of every neighborhood of the origin under (\\bm x,\\bm u) \\mapsto \\bm f(\\bm x, \\bm u) contains some neighborhood of the origin. This is not the case here. The map from the state-control space to the velocity space is\n\n\\begin{bmatrix}\nx\\\\ y\\\\ \\theta\\\\ v\\\\ \\omega\n\\end{bmatrix}\n\\mapsto\n\\begin{bmatrix}\nv \\cos \\theta\\\\\nv \\sin \\theta \\\\\n\\omega\n\\end{bmatrix}.\n\nNow consider a neighborhood of the origin such that |\\theta|&lt;\\frac{\\pi}{2}. It is impossible to get \\bm f(\\bm x, \\bm u) = \\begin{bmatrix}\n0\\\\ f_2 \\\\ 0\\end{bmatrix}, \\; f_2\\neq 0. Hence, stabilization by a continuous feedback \\bm u = \\kappa (\\bm x) is impossible.\nBut it is possible to stabilize the vehicle using a discontinuous feedback. And discontinuous feedback controllr can be viewed as switching control, which in turn can be seen as instance of a hybrid controller.\n\n\nExample 7 (Global asymptotic stabilization on a circle) We now give a demonstration of a general phenomenon of stabilization on a manifold. We will see that even if asymptotic stabilization by a continuous feedback is possible, it may not be possible to guarantee it globally.\n\n\n\n\n\n\nWhy control on manifolds?\n\n\n\nFirst, recall that a manifold is a solution set for a system of nonlinear equations. A prominent example is a unit circle \\mathbb S_1 = \\{\\bm x \\in \\mathbb R^2 \\mid x_1^2 + x_2^2 - 1 = 0\\}. An extension to two variables is then \\mathbb S_2 = \\{\\bm x \\in \\mathbb R^4  \\mid x_1^2 + x_2^2 - 1 = 0, \\, x_3^2 + x_4^2 - 1 = 0\\}. Now, why shall we bother to study control within this type of a state space? It turns out that such models of state space are most appropriate in mechatronic/robotic systems wherein angular variables range more than 360^\\circ. We worked on this kind of a system some time ago when designing a control system for inertially stabilized gimballed camera platforms.\n\n\n\nIn this example we restrict the motion of of a particle to sliding around a unit circle \\mathbb S_1 is modelled by\n\n\\dot{\\bm x} = u\\begin{bmatrix}0 & -1\\\\ 1 & 0\\end{bmatrix}\\bm x,\n where \\bm x \\in \\mathbb S^1,\\quad u\\in \\mathbb R.\nThe point to be stabilized is \\bm x^* = \\begin{bmatrix}1\\\\ 0\\end{bmatrix}.\n\n\n\n\n\n\nFigure 5: Asymptotic stabilization on a circle\n\n\n\nWhat is required from a globally asymptotically stabilizing controller?\n\nSolutions stay in \\mathbb S^1,\nSolutions converge to \\bm x^*,\nIf a solution starts near \\bm x^*, it stays near.\n\nOne candidate is \\kappa(\\bm x) = -x_2.\nDefine the (Lyapunov) function V(\\bm x) = 1-x_1.\nIndeed, it does qualify as a Lyapunov function because it is zero at \\bm x^* and positive elsewhere. Furthermore, its time derivative along the solution trajectory is \n\\begin{aligned}\n\\dot V &= \\left(\\nabla_{\\bm{x}}V\\right)^\\top \\dot{\\bm x}\\\\\n&= \\begin{bmatrix}-1 & 0\\end{bmatrix}\\left(-x_2\\begin{bmatrix}0 & -1\\\\ 1 & 0\\end{bmatrix}\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}\\right)\\\\\n&= -x_2^2\\\\\n&= -(1-x_1^2),\n\\end{aligned}\n from which it follows that \n\\dot V &lt; 0 \\quad \\forall \\bm x \\in \\mathbb S^1 \\setminus \\{-1,1\\}.\n\nWith u=-x_2 the point \\bm x^* is stable but not globally atractive, hence it is not globally asymptotically stable.\nCan we do better?\nYes, we can. But we need to incorporate some switching into the controller. Loosely speaking anywhere except for the state (-1,0), we can apply the previously designed controller, and at the troublesome state (-1,0), or actually in some region around it, we need to switch to another controller that would drive the system away from the problematic region.\nBut we will take this example as an opportunity to go one step further and instead of just a switching controller we design a hybrid controller. The difference is that within a hybrid controller we can incorporate some hysteresis, which is a robustifying feature. In order to do that, we need to introduce a new state variable q\\in\\{0,1\\}. Determination of the flow and jump sets is sketched in Fig. 6.\n\n\n\n\n\n\nFigure 6: Definition of the sets defining a hybrid controller\n\n\n\nNote that there is no hysteresis if c_0=c_1, in which case the hybrid controller reduces to a switching controller (but more on switching controllers in the next chapter).\nThe two feedback controllers are given by \n\\begin{aligned}\n\\kappa(\\bm x,0) &= \\kappa_0(\\bm x) = -x_2,\\\\\n\\kappa(\\bm x,1) &= \\kappa_1(\\bm x) = -x_1.\n\\end{aligned}\n\nThe flow map is (DIY) \nf(\\bm x, q) = \\ldots\n\nThe flow set is \n\\mathcal{C} = (\\mathcal C_0 \\times \\{0\\}) \\cup (\\mathcal C_1 \\times \\{1\\}).\n\nThe jump set is \n\\mathcal{D} = (\\mathcal D_0 \\times \\{0\\}) \\cup (\\mathcal D_1 \\times \\{1\\}).\n\nThe jump map is \ng(\\bm x, q) = 1-q \\quad \\forall [\\bm x, q]^\\top \\in \\mathcal D.\n\nSimulation using Julia is provided below.\n\n\nShow the code\nusing OrdinaryDiffEq\n\n# Defining the sets and functions for the hybrid equations\n\nc₀, c₁ = -2/3, -1/3\n\nC(x,q) = (x[1] &gt;= c₀ && q == 0) || (x[1] &lt;= c₁ && q == 1) # Actually not really needed, just a complement of D.\nD(x,q) = (x[1] &lt; c₀ && q == 0) || (x[1] &gt; c₁ && q == 1) \n\ng(x,q) = 1-q\n\nκ(x,q) = q==0 ? -x[2] : -x[1] \n\nfunction f!(dx,x,q,t)               # Already in the format for the ODE solver.\n    A = [0.0 -1.0; 1.0 0.0] \n    dx .= A*x*κ(x,q)\nend\n\n# Defining the initial conditions for the simulation\n\ncᵢ = (c₀+c₁)/2\nx₀ = [cᵢ,sqrt(1-cᵢ^2)]\nq₀ = 1\n\n# Setting up the simulation problem\n\ntspan = (0.0,10.0)\nprob = ODEProblem(f!,x₀,tspan,q₀)\n\nfunction condition(x,t,integrator)\n    q = integrator.p \n    return D(x,q)\nend\n\nfunction affect!(integrator)\n    q = integrator.p\n    x = integrator.u \n    integrator.p = g(x,q)\nend\n\ncb = DiscreteCallback(condition,affect!)\n\n# Solving the simulation problem\n\nsol = solve(prob,Tsit5(),callback=cb,dtmax=0.1) # ContinuousCallback more suitable here\n\n# Plotting the results of the simulation\n\nusing Plots\ngr(tickfontsize=12,legend_font_pointsize=12,guidefontsize=12)\n\nplot(sol,label=[\"x₁\" \"x₂\"],xaxis=\"t\",yaxis=\"x\",lw=2)\nhline!([c₀], label=\"c₀\")\nhline!([c₁], label=\"c₁\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Simulation of stabilization on a circle using a hybrid controller\n\n\n\n\nThe solution can also be visualized in the state space.\n\n\nShow the code\nplot(sol,idxs=(1,2),label=\"\",xaxis=\"x₁\",yaxis=\"x₂\",lw=2,aspect_ratio=1)\nvline!([c₀], label=\"c₀\")\nvline!([c₁], label=\"c₁\")\nscatter!([x₀[1]],[x₀[2]],label=\"x init\")\nscatter!([1],[0],label=\"x ref\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Simulation of stabilization on a circle using a hybrid controller",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Hybrid equations"
    ]
  },
  {
    "objectID": "hybrid_equations.html#supervisory-control",
    "href": "hybrid_equations.html#supervisory-control",
    "title": "Hybrid equations",
    "section": "Supervisory control",
    "text": "Supervisory control\nYet another problem that can benefit from being formulated as a hybrid system is supervisory control.\n\n\n\n\n\n\nFigure 9: Supervisory control",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Hybrid equations"
    ]
  },
  {
    "objectID": "hybrid_equations.html#combining-local-and-global-controllers-subset-supervisory-control",
    "href": "hybrid_equations.html#combining-local-and-global-controllers-subset-supervisory-control",
    "title": "Hybrid equations",
    "section": "Combining local and global controllers \\subset supervisory control",
    "text": "Combining local and global controllers \\subset supervisory control\nAs a subset of supervisory control we can view a controller that switches between a global and a local controller.\n\n\n\n\n\n\nFigure 10: Combining global and local controllers\n\n\n\nLocal controllers have good transient response but only work well in a small region around the equilibrium state. Global controllers have poor transient response but work well in a larger region around the equilibrium state.\nA useful example is that of swinging up and stabilization of a pendulum: the local controller can be designer for a linear model obtained by linearization about the upright orientation of the pendulum. But such controller can only be expected to perform well in some small region around the upright orientation. The global controller is designed to bring the pendulum into that small region.\nThe flow and jump sets for the local and global controllers are in Fig. 11. Can you tell, which is which? Remember that by introducing the discrete variable q, some hysteresis is in the game here.\n\n\n\n\n\n\nFigure 11: Flow and jump sets for a local and a global controller",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Hybrid equations"
    ]
  },
  {
    "objectID": "des_references.html",
    "href": "des_references.html",
    "title": "Literature",
    "section": "",
    "text": "Literature for discrete-event systems is vast, but within the control systems community the classical (and award-winning) reference is [1]. Note that an electronic version of the previous edition (perfectly acceptable for us) is accessible through the NTK library (possibly upon CTU login). This book is rather thick too and covering its content can easily need a full semestr. However, in our course we will only need the very basics of the theory of (finite state) automata and such basics are presented in Chapters 1 and 2. The extension to timed automata is then presented in Chapter 5.2, but the particular formalism for timed automata that we use follows [2], or perhaps even better [3].\n\nThe basics are also presented in the tutorial paper by the same author(s) [4]. A very short (but sufficient for us) intro to discrete-event systems that adheres to Cassandras’s style is given in the first chapter of the recent hybrid systems textbook [5].\nAlternatively, there are some other recent textbooks that contain decent introductions to the theory of (finite state) automata. These are often surfing on the wave of popularity of the recently fashionable buzzword of cyberphysical or embedded systems, but in essence these deal with the same hybrid systems as we do in our course. The fact is, however, that the modeling formalism can be a bit different from the one in Cassandras (certainly when it comes to notation but also some concepts). One such textbook is [6], for which an electronic version accessible through the NTK library (upon CTU login). Another one is [7]. In particular, Chapter 2 serves as an intro to the automata theory. Last but not least, we mention [8], for which an electronic version is freely downloadable.\n\n\n\n\n Back to topReferences\n\n[1] C. G. Cassandras and S. Lafortune, Introduction to Discrete Event Systems, 3rd ed. Cham: Springer, 2021. Available: https://doi.org/10.1007/978-3-030-72274-6\n\n\n[2] R. Alur and D. L. Dill, “A theory of timed automata,” Theoretical Computer Science, vol. 126, no. 2, pp. 183–235, Apr. 1994, doi: 10.1016/0304-3975(94)90010-8.\n\n\n[3] R. Alur, “Timed Automata,” in Computer Aided Verification, N. Halbwachs and D. Peled, Eds., in Lecture Notes in Computer Science. Berlin, Heidelberg: Springer, 1999, pp. 8–22. doi: 10.1007/3-540-48683-6_3.\n\n\n[4] S. Lafortune, “Discrete Event Systems: Modeling, Observation, and Control,” Annual Review of Control, Robotics, and Autonomous Systems, vol. 2, no. 1, pp. 141–159, 2019, doi: 10.1146/annurev-control-053018-023659.\n\n\n[5] H. Lin and P. J. Antsaklis, Hybrid Dynamical Systems: Fundamentals and Methods. in Advanced Textbooks in Control and Signal Processing. Cham: Springer, 2022. Accessed: Jul. 09, 2022. [Online]. Available: https://doi.org/10.1007/978-3-030-78731-8\n\n\n[6] R. Alur, Principles of Cyber-Physical Systems. Cambridge, MA, USA: MIT Press, 2015. Available: https://mitpress.mit.edu/9780262029117/principles-of-cyber-physical-systems/\n\n\n[7] S. Mitra, “A verification framework for hybrid systems,” PhD thesis, Massachusetts Institute of Technology, 2007. Accessed: Sep. 04, 2022. [Online]. Available: https://dspace.mit.edu/handle/1721.1/42238\n\n\n[8] E. A. Lee and S. A. Seshia, Introduction to Embedded Systems: A Cyber-Physical Systems Approach, 2nd ed. Cambridge, MA, USA: MIT Press, 2017. Available: https://ptolemy.berkeley.edu/books/leeseshia//",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "Literature"
    ]
  },
  {
    "objectID": "hybrid_automata_references.html",
    "href": "hybrid_automata_references.html",
    "title": "Literature",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "4. Hybrid systems: Hybrid automata",
      "Literature"
    ]
  },
  {
    "objectID": "solution_references.html",
    "href": "solution_references.html",
    "title": "Literature",
    "section": "",
    "text": "Any discussion of the concept(s) of solution of a hybrid system must start with the concept of a hybrid time and hybrid time domain. Within the hybrid automata framework this is discussed in the references that we have already made. A particularly popular and recommendable are the (online available) lecture notes [1]. Its updated and extended version [2] is no longer available online – we can only guess that the authors are turning it into a printed textbook. Another hybrid automata textbook that discusses these concepts is [3] (section 2.2.3), but it is not available online either. Anyway, the same concept is also discussed within the hybrid equations framework as introduced, for example, in [4], which can be downloaded (within institutional subscription). In fact, we find their version of hybrid time and hybrid time domain even more (visually) appealing.\nA transition from one discrete state to another, even if not accompanied by a jump (or reset) of the continuous state variable can be modeled as a discontinuity of the functions on right hand side of the differential equation. Depending on circumstances, more or less peculiar phenomena can occur due to these discontinuities.These issues are discussed in quite some detail in the (fairly readable) paper [5]. Very much recommendable.\n\n\n\n\n Back to topReferences\n\n[1] J. Lygeros, Lecture Notes on Hybrid Systems. 2004. Available: https://people.eecs.berkeley.edu/~sastry/ee291e/lygeros.pdf\n\n\n[2] J. Lygeros, S. Sastry, and C. Tomlin, “Hybrid Systems: Foundations, advanced topics and applications,” Jan. 2020. Available: https://www-inst.eecs.berkeley.edu/~ee291e/sp21/handouts/hybridSystems_monograph.pdf\n\n\n[3] H. Lin and P. J. Antsaklis, Hybrid Dynamical Systems: Fundamentals and Methods. in Advanced Textbooks in Control and Signal Processing. Cham: Springer, 2022. Accessed: Jul. 09, 2022. [Online]. Available: https://doi.org/10.1007/978-3-030-78731-8\n\n\n[4] R. Goebel, R. G. Sanfelice, and A. R. Teel, “Hybrid dynamical systems,” IEEE Control Systems Magazine, vol. 29, no. 2, pp. 28–93, Apr. 2009, doi: 10.1109/MCS.2008.931718.\n\n\n[5] J. Cortes, “Discontinuous dynamical systems: A tutorial on solutions, nonsmooth analysis, and stability,” IEEE Control Systems Magazine, vol. 28, no. 3, pp. 36–73, Jun. 2008, doi: 10.1109/MCS.2008.919306.",
    "crumbs": [
      "7. Solution",
      "Literature"
    ]
  },
  {
    "objectID": "solution_concepts.html",
    "href": "solution_concepts.html",
    "title": "Solution concepts",
    "section": "",
    "text": "Now that we know how to model hybrid systems, we need to define what we mean by a solution to a hybrid system. The definitions are not as straightforward as in the continuous-time or discrete-time case and mastering them is not only of theoretical value.",
    "crumbs": [
      "7. Solution",
      "Solution concepts"
    ]
  },
  {
    "objectID": "solution_concepts.html#hybrid-time-and-hybrid-time-domain",
    "href": "solution_concepts.html#hybrid-time-and-hybrid-time-domain",
    "title": "Solution concepts",
    "section": "Hybrid time and hybrid time domain",
    "text": "Hybrid time and hybrid time domain\nEven before we start discussing the concepts of a solution, we need to discuss the concept of time in hybrid systems. Of course, hybrid systems live in the same world as we do, and therefore they evolve in the same physical time, but it turns out that we can come up with an artificial concept of hybrid time that makes modelling and analysis of hybrid systems convenient.\nRecall that in continuous-time systems, the continuous time t\\in\\mathbb R_{\\geq 0}, and in discrete-time systems, the discrete “time” k\\in\\mathbb N. We put the latter in quotation marks since k is not really the time but rather it should be read as the kth transition of the system. Now, the idea is to combine these two concepts of time into one, and we call it the hybrid time (t,j), \\; t\\in \\mathbb R_{\\geq 0},\\, j\\in \\mathbb N.\nIf you think that it is redundant, note that since hybrid systems can exhibit discrete-event system behaviour, a transition from one discrete state to another can happen instantaneously. In fact, several such transitions can take no time at all. It sounds weird, but that is what the mathematical model allows. That is why determining t need not be enought and we also need to specify j.\nThe set of all hybrid times for a given hybrid system is called hybrid time domain \nE \\subset [0,T] \\times \\{0,1,2,\\ldots, J\\},\n where T and J can be finite or \\infty.\nIn particular, \nE = \\bigcup_{j=0}^J \\left([t_j,t_{j+1}] \\times \\{j\\}\\right)\n\\tag{1}\nwhere 0=t_0 &lt; t_1 &lt; \\ldots &lt; t_J = T.\nThe meaning of Eq. 1 can be best explained using Fig. 1 below.\n\n\n\n\n\n\nFigure 1: Example of a hybrid time domain\n\n\n\nNote that if two hybrid times are from the same hybrid domain, we can decide if (t,j) \\leq (t',j'). In other words, the set of hybrid times is totally ordered.",
    "crumbs": [
      "7. Solution",
      "Solution concepts"
    ]
  },
  {
    "objectID": "solution_concepts.html#hybrid-arc",
    "href": "solution_concepts.html#hybrid-arc",
    "title": "Solution concepts",
    "section": "Hybrid arc",
    "text": "Hybrid arc\nHybrid arc is just a terminology used in the literature for hybrid state trajectory. It is a function that assigns a state vector x to a given hybrid time (t,j) \nx: E \\rightarrow \\mathbb R^n.\n\nFor each j the function t \\mapsto x(t,j) is absolutely continuous on the interval I^j = \\{t \\mid (t,j) \\in E\\}.\n\n\n\n\n\n\nInconsitent notation\n\n\n\nWe admit here that we are not going to be 100% consistent in the usage of the notation x(t,j) in the rest of our course. Oftentimes use x(t) even within hybrid systems when we do not need to index the jumps.\n\n\nIt is perhaps clear now, that hybrid time domain can only be determined once the solution (the arc, the trajectory) is known. This is in sharp contrast with the continuous-time or discrete-time system – we can formulate the problem of finding solution to \\dot x(t) = 3x(t), \\, x(0) = 1 on the interval [0,2], where the interval was set even before we know how the solution looks like.",
    "crumbs": [
      "7. Solution",
      "Solution concepts"
    ]
  },
  {
    "objectID": "solution_concepts.html#solutions-of-autonomous-no-input-systems",
    "href": "solution_concepts.html#solutions-of-autonomous-no-input-systems",
    "title": "Solution concepts",
    "section": "Solutions of autonomous (no-input) systems",
    "text": "Solutions of autonomous (no-input) systems\nFinally we can formalize the concept of a solution. A hybrid arc x(\\cdot,\\cdot) is a solution to the hybrid equations given by the common quadruple \\{\\mathcal{C},\\mathcal{D},f,g\\} (or \\{\\mathcal{C},\\mathcal{D},\\mathcal{F},\\mathcal{G}\\} for inclusions), if\n\nthe initial state x(0,0) \\in \\overline{\\mathcal{C}} \\cup \\mathcal{D}, and\nfor all j such that I^j = \\{t\\mid (t,j)\\in E\\} has a nonempty interior \\operatorname{int}I^j\n\nx(t,j) \\in \\mathcal C \\; \\forall t\\in \\operatorname{int}I^j,\n\\dot x(t,j) = f(x(t,j)) \\; \\text{for almost all}\\; t\\in I^j, and\n\nfor all (t,j)\\in E such a (t,j+1)\\in E\n\nx(t,j) \\in \\mathcal{D}, and\nx(t,j+1) = g(x(t,j)).\n\n\nMake the modifications for the \\{\\mathcal{C},\\mathcal{D},\\mathcal{F},\\mathcal{G}\\} version by yourself.\n\nExample 1 (Solution) En example of a solution is in Fig. 2. Follow the solution with your finger and make sure you understand what and why is happing. In particular, in the overlapping region, the solution is not unique. While it can continue flowing, it can also jump.\n\n\n\n\n\n\nFigure 2: Example of a solution",
    "crumbs": [
      "7. Solution",
      "Solution concepts"
    ]
  },
  {
    "objectID": "solution_concepts.html#hybrid-input",
    "href": "solution_concepts.html#hybrid-input",
    "title": "Solution concepts",
    "section": "Hybrid input",
    "text": "Hybrid input\nSimilarly as we considered the state as a function of the hybrid time, we can consider the input as a function of the hybrid time. With its own hybrid domain E_\\mathrm{u}, the input is \nu: E_\\mathrm{u} \\rightarrow \\mathbb R^m.\n\nFor each j the function t \\mapsto u(t,j) must be… well-behaved… For example, piecewise continuous on the interval I^j = \\{t \\mid (t,j) \\in E_\\mathrm{u}\\}.",
    "crumbs": [
      "7. Solution",
      "Solution concepts"
    ]
  },
  {
    "objectID": "solution_concepts.html#solutions-of-systems-with-inputs",
    "href": "solution_concepts.html#solutions-of-systems-with-inputs",
    "title": "Solution concepts",
    "section": "Solutions of systems with inputs",
    "text": "Solutions of systems with inputs\nWe assume that hybrid time domains for the arcs and inputs are the same. A solution must satisfy the same conditions as in the case of autonomous systems, but with the input taken into account. For completeness we state the conditions here:\n\nThe initial state-control pair (x(0,0),u(0,0)) \\in \\overline{\\mathcal{C}} \\cup \\mathcal{D}, and\nfor all j such that I^j = \\{t\\mid (t,j)\\in E\\} has a nonempty interior \\operatorname{int}I^j\n\n(x(t,j),u(t,j)) \\in \\mathcal C \\; \\forall t\\in \\operatorname{int}I^j,\n\\dot x(t,j) = f(x(t,j),u(t,j)) \\; \\text{for almost all}\\; t\\in I^j, and\n\nfor all (t,j)\\in E such a (t,j+1)\\in E\n\n(x(t,j),u(t,j)) \\in \\mathcal{D}, and\nx(t,j+1) = g(x(t,j),u(t,j)).",
    "crumbs": [
      "7. Solution",
      "Solution concepts"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "What is a hybrid system?",
    "section": "",
    "text": "The adjective “hybrid” is used in a common language to express that the subject under consideration has a bit of this and a bit of that… When talking about hybridness of systems, we modify this vague “definition” into a more descriptive one: a hybrid system has a bit of this and an atom of that… By this bon mot we mean that hybrid systems contain some physical subsystems and components combined with if-then-else and/or timing rules that are mostly (but not always) implemented in software. This definition is certainly not the most precise one, but it is a good starting point.\nEven better a definition is that hybrid systems are composed of subsystems whose evolution is driven by time (discrete or continuous) and some other subsystems that evolve as dictated by (discrete) events. The former are modelled by ordinary differential equations (ODE) or differential-algebraic equations (DAE) in continuous time cases and by difference equations in the discrete time cases. The are latter are modelled by state automata or Petri nets, and they implement some propositonal (aka sentential or statement), predicate and/or temporal logics. Let’s stick to this definition of hybrid systems. As we will progress with modelling frameworks, the definition will become a bit more operational.\n\n\n\n\n\n\nHybrid systems vs sampled-data systems\n\n\n\nIt may be a bit confusing that we are introducing a new framework for the situation that we can already handle – a physical plant evolving in continuous time (and modelled by an ODE) controlled in discrete-time by a digital controller/computer. Indeed, this situation does qualify as a hybrid system. In introductory course we have learnt to design such controllers (by discretizing the system and then designing a controller for a discrete-time model, relying on ) and there was no need to introduce whatever new framework. However, this standard scenario assumes that the sampling period is constant. Only then can the standard techniques based on z-transform be applied. As soon as the sampling period is not constant, we need some more general framework – the framework of hybrid systems.\n\n\n\n\n\n\n\n\nHybrid systems vs cyberphysical systems\n\n\n\nRecently systems containing both the computer/software/algorithmic parts and physical parts are also studied under the fancy name cyberphysical systems. The two concepts can hardly be distinguished, to be honest. I also confess I am unhappy with the narrowing of the concept of cybernetics to just computers. Cybernetics, as introduced by Norbert Wiener, already encompasses physical and biological systems among others. Anyway, that is how it is and the take-away leeson is that these days a great deal of material relevant for our course on hybrid systems can also be found in resources adopting the name cyberphysical systems.",
    "crumbs": [
      "0. Introduction",
      "What is a hybrid system?"
    ]
  },
  {
    "objectID": "intro.html#definition-of-a-hybrid-system",
    "href": "intro.html#definition-of-a-hybrid-system",
    "title": "What is a hybrid system?",
    "section": "",
    "text": "The adjective “hybrid” is used in a common language to express that the subject under consideration has a bit of this and a bit of that… When talking about hybridness of systems, we modify this vague “definition” into a more descriptive one: a hybrid system has a bit of this and an atom of that… By this bon mot we mean that hybrid systems contain some physical subsystems and components combined with if-then-else and/or timing rules that are mostly (but not always) implemented in software. This definition is certainly not the most precise one, but it is a good starting point.\nEven better a definition is that hybrid systems are composed of subsystems whose evolution is driven by time (discrete or continuous) and some other subsystems that evolve as dictated by (discrete) events. The former are modelled by ordinary differential equations (ODE) or differential-algebraic equations (DAE) in continuous time cases and by difference equations in the discrete time cases. The are latter are modelled by state automata or Petri nets, and they implement some propositonal (aka sentential or statement), predicate and/or temporal logics. Let’s stick to this definition of hybrid systems. As we will progress with modelling frameworks, the definition will become a bit more operational.\n\n\n\n\n\n\nHybrid systems vs sampled-data systems\n\n\n\nIt may be a bit confusing that we are introducing a new framework for the situation that we can already handle – a physical plant evolving in continuous time (and modelled by an ODE) controlled in discrete-time by a digital controller/computer. Indeed, this situation does qualify as a hybrid system. In introductory course we have learnt to design such controllers (by discretizing the system and then designing a controller for a discrete-time model, relying on ) and there was no need to introduce whatever new framework. However, this standard scenario assumes that the sampling period is constant. Only then can the standard techniques based on z-transform be applied. As soon as the sampling period is not constant, we need some more general framework – the framework of hybrid systems.\n\n\n\n\n\n\n\n\nHybrid systems vs cyberphysical systems\n\n\n\nRecently systems containing both the computer/software/algorithmic parts and physical parts are also studied under the fancy name cyberphysical systems. The two concepts can hardly be distinguished, to be honest. I also confess I am unhappy with the narrowing of the concept of cybernetics to just computers. Cybernetics, as introduced by Norbert Wiener, already encompasses physical and biological systems among others. Anyway, that is how it is and the take-away leeson is that these days a great deal of material relevant for our course on hybrid systems can also be found in resources adopting the name cyberphysical systems.",
    "crumbs": [
      "0. Introduction",
      "What is a hybrid system?"
    ]
  },
  {
    "objectID": "intro.html#example-of-a-hybrid-system",
    "href": "intro.html#example-of-a-hybrid-system",
    "title": "What is a hybrid system?",
    "section": "Example of a hybrid system",
    "text": "Example of a hybrid system\n\n\n\nExample of a hybrid system (from [1])",
    "crumbs": [
      "0. Introduction",
      "What is a hybrid system?"
    ]
  },
  {
    "objectID": "intro.html#hybrid-system-is-an-open-and-unbounded-concept",
    "href": "intro.html#hybrid-system-is-an-open-and-unbounded-concept",
    "title": "What is a hybrid system?",
    "section": "Hybrid system is an open and unbounded concept",
    "text": "Hybrid system is an open and unbounded concept\nPartly because hybrid systems are investigated by many\n\nComputer science\nModeling & simulation\nControl systems\n\n\nHybrid systems in computer science\n\nThey start with discrete-event systems, typically modelled by finite state automata and/or timed automata, and add some (typically simple) continuous-time dynamics.\nMainly motivated by analysis (verification, model checking, …): safety, liveness, fairness, …\n\n\n\nHybrid systems in modeling and simulation\n\nEven when modeling purely physical systems, it can be beneficial to approximate some fast dynamics with discontinuous transitions – jumps (diodes and other semiconductor switches, computer networks, mechanical impacts, …).\n\n\n\n\n\n\n\nSystems vs models\n\n\n\nStrictly speaking, we should speak about hybrid models, because modeling a given system as hybrid is already a modeller’s decision. But the terminology is already settled. After all, we also speak about “second-order systems” when we actually mean “second-order models”, or “LTI systems” when we actually mean “LTI models”.\n\n\n\n\nHybrid systems in control systems\n\nTypically focused on continuous-time dynamical systems to be controlled but introducing some logic through a controller (switching control, relay control, PLC, …)\nBesides synthesis (aka control design), properties such as stability, controllability, robustness.\nThere is yet another motivation for explicitly dealing with hybridness in control systems: some systems can only be stabilized by switching and switching can be formulated within the hybrid system framework.",
    "crumbs": [
      "0. Introduction",
      "What is a hybrid system?"
    ]
  },
  {
    "objectID": "hybrid_equations_software.html",
    "href": "hybrid_equations_software.html",
    "title": "Software",
    "section": "",
    "text": "There is a well-developed and actively maintained Matlab toolbox\n\nSanfelice, Ricardo, and Pablo Nanez. ‘Hybrid Equations (HyEQ) Toolbox for Matlab’. Version 3.0, 15 October 2022. https://github.com/pnanez/HyEQ_Toolbox. Documentation at https://hyeq.github.io.\n\nThe toolbox can also be installed directly from Matlab through their Add-Ons Explorer. As the stable version is already two years old and they also offer a beta version 3.1.0.04, which was last updated on April 28, 2024, the beta version seems the way to go for our purposes. The authors will certainly appreciate any feedback.\nOther programming languages seem to be missing a similar toolbox/package. How about developing one in Julia?\n\n\n\n Back to top",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Software"
    ]
  },
  {
    "objectID": "classes_reset.html",
    "href": "classes_reset.html",
    "title": "Reset systems",
    "section": "",
    "text": "We have introduced two major modeling frameworks for hybrid systems – hybrid automata and hybrid equations. Now we are ready to model any hybrid system. It turns out useful, however, to define a few special classes of hybrid systems. Their special features are reflected in the structure of their models (hybrid automata or hybrid equations). The special classes of hybrid systems that we are going to discuss are",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Reset systems"
    ]
  },
  {
    "objectID": "classes_reset.html#reset-systems",
    "href": "classes_reset.html#reset-systems",
    "title": "Reset systems",
    "section": "Reset systems",
    "text": "Reset systems\nThey are also called impulsive systems (the reason is going to be clear soon). They are conveniently defined within the hybrid automata framework. In a hybrid automaton modelling a reset system we can only identify a single discrete state (mode), not more. In the digraph representation, we can only observe a single node.\n\n\n\n\n\n\nFigure 1: Reset system\n\n\n\nWithin the hybrid equations framework, in a reset system some variables reset (jump) and flow, others only flow, but there are no variables that only reset… Well, this definition is not perfect, because as we have discussed earlier, even when staying constant between two jumps, the state variable is, technically speaking, also flowing. What we want to express is that there are not discrete variables in such model, but the hybrid equations framework intentionally does not distinguish between continuous and discrete variables.\nWe can recognize the bouncing ball as a prominent example of a reset system. Another example follows.\n\nExample 1 (Reset oscillator) We consider a hybrid system state-space modelled by the following hybrid equations: \n\\begin{aligned}\n\\begin{bmatrix}\n\\dot x_1\\\\ \\dot x_2\n\\end{bmatrix}\n&=\n\\begin{bmatrix}\n0 & 1\\\\ -1 & 2\\delta\n\\end{bmatrix}\n\\begin{bmatrix}\nx_1\\\\x_2\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n0\\\\1\n\\end{bmatrix},\n\\quad \\bm x \\in \\mathcal C,\\\\\nx_1^+ &= -x_1, \\quad \\bm x \\in \\mathcal D,\n\\end{aligned}\n where \n\\begin{aligned}\n\\mathcal D &= \\{\\bm x \\in \\mathbb R^2 \\mid x_1&lt;0, x_2=0\\},\\\\\n\\mathcal C &= \\mathbb R^2\\setminus\\mathcal D.\n\\end{aligned}\n\nSimulation outcomes for some concrete value of the small positive parameter \\delta are shown in the following figure.\n\n\nShow the code\nusing OrdinaryDiffEq\n\nδ = 0.1\nA = [0.0 1.0;\n    -1.0 2δ]\nb = [0.0; 1.0]\n\nx0 = [0.2, 0.0]\ntspan = (0.0, 100)\nf(x, p, t) = A*x + b\ncond_fcn(x, t, integrator) = x[1]&lt;0 ? x[2] : 1.0\naffect!(integrator) = integrator.u[1] = -integrator.u[1]\ncb = ContinuousCallback(cond_fcn, affect!)\nprob = ODEProblem(f, x0, tspan)\n\nsol = solve(prob, Tsit5(),callback=cb, reltol = 1e-6, abstol = 1e-6, saveat = 0.1)\n\nusing Plots\nplot(sol[1,:],sol[2,:],lw=2,legend=false, tickfontsize=12, xtickfontsize=12, ytickfontsize=12)\nxlabel!(\"x₁\")\nylabel!(\"x₂\")\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIsn’t it fascinating that a linear system augmented with resetting can exhibit such a complex behavior?",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Reset systems"
    ]
  },
  {
    "objectID": "classes_reset.html#cleggs-integrator-ci",
    "href": "classes_reset.html#cleggs-integrator-ci",
    "title": "Reset systems",
    "section": "Clegg’s integrator (CI)",
    "text": "Clegg’s integrator (CI)\nClegg’s integrator is a reset element that can be used in control systems.\nIts function is as follows. As soon as the sign of the input changes, the integrator resets to zero. As a consequence, the integrator keeps the sign of its input and output identical.\nUnlike the traditional (linear) integrator, the CI exhibits much smaller phase lag (some 38 vs 90 deg).\n\nExample 2 (Response of Clegg’s integrator to a sinusoidal input) Here is a response of the Clegg’s integrator to a sinusoidal input.\n\n\nShow the code\nusing OrdinaryDiffEq\nf(x, u, t) = u(t)                               # We adhere to the control systems notation that x is the state variable and u is the input.\nx0 = 0.0                                        # The initial state.\ntspan = (0.0, 10)                               # The time span.\nu = t -&gt; 1.0*sin(t)                             # The (control) input.\ncond_fcn(x, t, integrator) = integrator.p(t)    # The condition function. If zero, the event is triggered.\naffect!(integrator) = integrator.u = 0.0        # Beware that internally, u is the state variable. Here, the state variable is reset to zero.\ncb = ContinuousCallback(cond_fcn, affect!)\nprob = ODEProblem(f, x0, tspan, u)\nsol = solve(prob, Tsit5(),callback=cb, reltol = 1e-6, abstol = 1e-6, saveat = 0.1)\n\nusing Plots\nt = sol.t\nplot(sol.t,u.(t),label=\"u\",lw=2)\nplot!(sol,lw=2,label=\"x\", tickfontsize=12, xtickfontsize=12, ytickfontsize=12)\nxlabel!(\"t\")\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt may be of historical curiosity that originally the concept was presented in the form of an analog circuit (opamps, diodes, resistors, capacitors). See the references if you are interested.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Reset systems"
    ]
  },
  {
    "objectID": "classes_reset.html#first-order-reset-element-fore",
    "href": "classes_reset.html#first-order-reset-element-fore",
    "title": "Reset systems",
    "section": "First-order reset element (FORE)",
    "text": "First-order reset element (FORE)\nAnother simple reset element that can be used in control systems is known as FORE (first-order reset element) described by \n\\begin{array}{lr}\n\\dot u = a u + k e, & \\mathrm{when}\\; e\\neq 0,\\\\\nu^+ = 0, & \\mathrm{when}\\; e = 0.\n\\end{array}\n\n\nExample 3 (FORE) Consider a plant modelled by G(s) = \\frac{s+1}{s(s+0.2)} and a first-order controller C=\\frac{1}{s+1} in the feedback loop as in Fig. 2.\n\n\n\n\n\n\nFigure 2: First-order controller in a feedback loop\n\n\n\nThe response of the closed-loop system to a step reference input is shown using the following code.\n\n\nShow the code\nusing ModelingToolkit, Plots, OrdinaryDiffEq\nusing ModelingToolkit: t_nounits as t\nusing ModelingToolkit: D_nounits as D\n\nfunction plant(; name)\n    @variables x₁(t)=0 x₂(t) = 0 u(t) y(t)\n    eqs = [D(x₁) ~ x₂\n           D(x₂) ~ -0.2x₂ + u\n           y ~ x₁ + x₂]\n    ODESystem(eqs, t; name = name)\nend\n\nfunction controller(; name) \n    @variables x(t)=0 u(t) y(t)\n    eqs = [D(x) ~ -x + u\n           y ~ x]\n    ODESystem(eqs, t, name = name)\nend\n\n@named C = controller()\n@named P = plant()\n\nt_of_step = 1.0\nr(t) = t &gt;= t_of_step ? 1.0 : 0.0\n@register_symbolic r(t)\n\nconnections = [C.u ~ r(t) - P.y\n               C.y ~ P.u]\n\n@named T = ODESystem(connections, t, systems = [C, P])\n\nT = structural_simplify(T)\nequations(T)\nobserved(T)\n\nusing DifferentialEquations: solve\nprob = ODEProblem(complete(T), [], (0.0, 30.0), [])\nsol = solve(prob, Tsit5(), saveat = 0.1)\n\nusing Plots\nplot(sol.t, sol[P.y], label = \"\", xlabel = \"t\", ylabel = \"y\", lw = 2)\n\n\nNow we turn the first-order controller into a FORE controller by augumenting it with the above described resetting functionality. The feedback loop is in Fig. 3.\n\n\n\n\n\n\nFigure 3: First-order reset element (FORE) in a feedback loop\n\n\n\nThe response of the closed-loop system to a step reference input is shown using the following code.\n\n\nShow the code\nusing ModelingToolkit, Plots, OrdinaryDiffEq\nusing ModelingToolkit: t_nounits as t\nusing ModelingToolkit: D_nounits as D\n\nfunction plant(; name)\n    @variables x₁(t)=0 x₂(t) = 0 u(t) y(t)\n    eqs = [D(x₁) ~ x₂\n           D(x₂) ~ -0.2x₂ + u\n           y ~ x₁ + x₂]\n    ODESystem(eqs, t; name = name)\nend\n\nfunction controller(; name) \n    @variables x(t)=0 u(t) y(t)\n    eqs = [D(x) ~ -x + u\n           y ~ x]\n    ODESystem(eqs, t, name = name)\nend\n\n@named C = controller()\n@named P = plant()\n\nt_of_step = 1.0\nr(t) = t &gt;= t_of_step ? 1.0 : 0.0\n@register_symbolic r(t)\n\nconnections = [C.u ~ r(t) - P.y\n               C.y ~ P.u]\n\nzero_crossed = [C.u ~ 0]\nreset = [C.x ~ 0]               \n\n@named T = ODESystem(connections, t, systems = [C, P], continuous_events = zero_crossed =&gt; reset)\n\nT = structural_simplify(T)\nequations(T)\nobserved(T)\n\nusing DifferentialEquations: solve\nprob = ODEProblem(complete(T), [], (0.0, 30.0), [])\nsol = solve(prob, Tsit5(), saveat = 0.1)\n\nusing Plots\nplot(sol.t, sol[P.y], label = \"\", xlabel = \"t\", ylabel = \"y\", lw = 2)\n\n\nObviously the introduction of the resetting functionality into the first order controller had a positive effect on the transient response of the closed-loop system.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Reset systems"
    ]
  },
  {
    "objectID": "classes_reset.html#when-not-to-use-reset-control",
    "href": "classes_reset.html#when-not-to-use-reset-control",
    "title": "Reset systems",
    "section": "When (not) to use reset control?",
    "text": "When (not) to use reset control?\nHowever conceptually simple, reset control is not a panacea. Analysis and design of reset control systems is not straightforward compared to the traditional linear control systems. In particular, guaranteeing closed-loop stability upon introduction of resetting into a linear controller is not easy and may require advanced concepts (some of them we are going to introduce later in the course). Therefore we should use reset control with care. We should always do our best to find (another) linear controller that has a performance comparable or even better than reset control system.\nBut reset control can be helfpul if the plant is subject to fundamental limitations of achievable control performance such as\n\nintegrators and unstable poles,\nzeros in the right half-plane (non-minimum phase),\ndelays,\n…\n\nIn these situations reset control can be a way to beat the so-called waterbed effect.",
    "crumbs": [
      "6. Some classes of hybrid systems",
      "Reset systems"
    ]
  },
  {
    "objectID": "complementarity_systems.html",
    "href": "complementarity_systems.html",
    "title": "Complementarity systems",
    "section": "",
    "text": "Having introduced the complementarity constraints and optimization problems with these constraints, we can now show how these constraints can be used to model a certain class of dynamical systems – complementarity dynamical systems. We start with linear ones, namely, linear complementarity systems (LCS). These are also called in the literature as Linear dynamical complementarity problems (LDCP).\nLinear complementarity system is modelled by \\boxed{\n\\begin{aligned}\n\\dot{\\bm x}(t) &= \\mathbf A \\bm x(t) + \\mathbf B\\bm u(t)\\\\\n\\bm y(t) &= \\mathbf C \\bm x(t) + \\mathbf D\\bm u(t)\\\\\n\\mathbf 0&\\leq \\bm u(t) \\perp \\bm y(t) \\geq \\mathbf 0.\n\\end{aligned}}\n\\tag{1}\n\nExample 1 (Electrical circuit with a diode as an LCS)  \n\n\n\nElectrical circuit to be modelled as an LCS\n\n\nNote the upside-down orientation of the voltage and the current for the capacitor – we wanted the diode current identical to the capacitor current.\nFollowing the charge formalism within Lagrangian modelling, we can choose the generalized coordinates as \n      \\bm q = \\begin{bmatrix}\n      q_L \\\\ q_C\n      \\end{bmatrix}.\n\nThat this is indeed a sufficient number is obvious, but we can also check the classical formula B-N+1 = 4-3+1 = 2. But we can also choose the state variables as \n      \\bm x = \\begin{bmatrix}\n      i_L\\\\ q_c\n      \\end{bmatrix}.\n\nThe resulting state equations are \n\\begin{aligned}\ni_L' &= -\\frac{1}{LC}q_C - \\frac{1}{L}u_D\\\\\nq_C' &= i_L - \\frac{1}{RC} q_C - \\frac{1}{R} u_D.\n\\end{aligned}\n\nThe idealized volt-ampere characteristics of the diode is\n\n\n\nIdeal volt-ampere characteristic of a diode\n\n\nFlipping the axes to get the current as the horizontal axis, we get\n\n\n\nFlipped volt-ampere characteristic of a diode\n\n\nFinally, after introducing an auxiliary variable (the reverse voltage of the diode) \\bar u_D = -u_D , we get the desired dependence\n\n\n\nYet another reformatted VA characteristic of a diode\n\n\nwhich can be modelled as a complementarity constraint\n\n0\\leq i_D \\perp \\bar u_D \\geq 0.\n\nNow, upon replacing the diode voltage with its reverse \\bar u_D while using i_D=i_C, we get \n\\begin{aligned}\ni_L' &= -\\frac{1}{LC}q_C + \\frac{1}{L} \\bar u_D\\\\\nq_C' &= i_L - \\frac{1}{RC} q_C + \\frac{1}{R} \\bar u_D\\\\\n0&\\leq q_C' \\perp \\bar u_D \\geq 0.\n\\end{aligned}\n\nWe are not there yet – there is a derivative in the complementarity constraint. But just substitute for it: \n\\begin{aligned}\ni_L' &= -\\frac{1}{LC}q_C + \\frac{1}{L} \\bar u_D\\\\\nq_C' &= i_L - \\frac{1}{RC} q_C + \\frac{1}{R} \\bar u_D\\\\\n0&\\leq i_L - \\frac{1}{RC} q_C + \\frac{1}{R} \\bar u_D \\perp \\bar u_D \\geq 0,\n\\end{aligned}\n\nand voila, we finally got the LCS description. We can also reformat it into the matrix-vector form \n\\begin{aligned}\n\\begin{bmatrix}\ni_L' \\\\ q_C'\n\\end{bmatrix} &=\n\\begin{bmatrix}\n0 &-\\frac{1}{LC}\\\\\n1  & - \\frac{1}{RC}\n\\end{bmatrix}\n\\begin{bmatrix}\ni_L \\\\ q_C\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\frac{1}{L}\\\\\n\\frac{1}{R}\n\\end{bmatrix}\n\\bar u_D\\\\\n0 &\\leq \\left(\\begin{bmatrix}\n1  & - \\frac{1}{RC}\n\\end{bmatrix}\n\\begin{bmatrix}\ni_L \\\\ q_C\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\frac{1}{L}\\\\\n\\frac{1}{R}\n\\end{bmatrix}\n\\bar u_D\\right ) \\bot \\bar u_D \\geq 0.\n\\end{aligned}\n\n\n\nExample 2 (Mass-spring system with a hard stop as a linear complementarity system) Two carts moving horitontally (left or right) are interconnected through a spring. The left cart is also interconnected with the wall through a another spring. Furthemore, the motion of the left cart is constrained in that there is a hard stop that prevents the cart from moving further to the left. Another natural constraint is that the right cart cannot get to the left of the other vehicle. The setup is shown in Fig. 1.\n\n\n\n\n\n\nFigure 1: Mass-spring system with a hard stop to be modelled as a LCS\n\n\n\nThe variables x_1 and x_2 give deviations of the two carts from their equilibrium positions. As we are considering negligible sizes of the two carts, the equilibrium position for both is 0. The derivatives of the two positions are also introduced as state variables x_3 and x_4, respectively.\nThe hard stop is located at the equilibrium position of the left cart.\nThe input u_1 corresponds to the reaction force of the hard stop applied to the left cart. Another input is u_2 that corresponds to the force exerted by the left cart onto the right cart.\nThe state equations are \n\\begin{aligned}\n\\dot x_1(t) &= x_3,\\\\\n\\dot x_2(t) &= x_4,\\\\\n\\dot x_3(t) &= -\\frac{k_1+k_2}{m_1}x_1(t) + \\frac{k_2}{m_1}x_2(t) + \\frac{1}{m_1}u_1(t) - \\frac{1}{m_1}u_2(t),\\\\\n\\dot x_4(t) &= \\frac{k_2}{m_2}x_1(t) - \\frac{k_2}{m_2} x_2(t) + \\frac{1}{m_2}u_2(t).\n\\end{aligned}\n\nThe presence of the hard stop can be modelled as an inequality constraint on the state x_1(t) \\geq  0.\nSimilarly, the fact that the right cart cannot get to the left of the left cart can be expressed as \nx_2(t) - x_1(t) \\geq 0.\n\nThis motivates us to define two output variables as \n\\begin{aligned}\ny_1(t) &= x_1(t),\\\\\ny_2(t) &= x_2(t)-x_1(t).\n\\end{aligned}\n\nNow, the reaction force u_1 exerted by the hard stop onto the left cart can only be nonnegative \nu_1(t) \\geq 0,\n\nand it is positive if and only if the left cart hits the hard stop\n\n      y_1(t) u_1(t) = 0.\n\nThe condition can be written compactly as \n0\\leq y_1(t) \\perp u_1(t) \\geq 0.\n\nSimilarly for the force u_2 exerted by the left cart onto the right cart \n0\\leq y_2(t) \\perp u_2(t) \\geq 0.\n\nFor convenience, we now give a full model in the matrix-vector form. \n\\begin{aligned}\n\\begin{bmatrix} \\dot x_1\\\\ \\dot x_2\\\\ \\dot x_3\\\\ \\dot x_4 \\end{bmatrix}\n&=\n\\begin{bmatrix}\n0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & 1\\\\\n{\\color{blue}-\\frac{k_1+k_2}{m_1}} & {\\color{blue}\\frac{k_2}{m_1}} & 0 & 0\\\\\n{\\color{blue}\\frac{k_2}{m_2}} & {\\color{blue}-\\frac{k_2}{m_2}} & 0 & 0\n\\end{bmatrix}\n\\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\\\ x_4 \\end{bmatrix} +\n\\begin{bmatrix} 0 & 0\\\\ 0 & 0\\\\ {\\color{blue}\\frac{1}{m_1}} & {\\color{blue}-\\frac{1}{m_1}}\\\\ {\\color{blue}0} & {\\color{blue}\\frac{1}{m_2}}\\end{bmatrix} \\begin{bmatrix} u_1\\\\u_2\\end{bmatrix},\\\\\n\\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix} &= \\begin{bmatrix} {\\color{blue}1} & {\\color{blue}0} & 0 & 0\\\\ {\\color{blue}-1} & {\\color{blue}1} & 0 & 0\\end{bmatrix} \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\\\ x_4 \\end{bmatrix},\\\\\n\\mathbf 0 &\\leq \\bm y \\perp \\bm u \\geq \\mathbf 0.\n\\end{aligned}\n\\tag{2}\nNote that we highlighted in blue three submatrices that will come in handy in the next section.",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity systems"
    ]
  },
  {
    "objectID": "complementarity_systems.html#linear-complementarity-system-lcs",
    "href": "complementarity_systems.html#linear-complementarity-system-lcs",
    "title": "Complementarity systems",
    "section": "",
    "text": "Having introduced the complementarity constraints and optimization problems with these constraints, we can now show how these constraints can be used to model a certain class of dynamical systems – complementarity dynamical systems. We start with linear ones, namely, linear complementarity systems (LCS). These are also called in the literature as Linear dynamical complementarity problems (LDCP).\nLinear complementarity system is modelled by \\boxed{\n\\begin{aligned}\n\\dot{\\bm x}(t) &= \\mathbf A \\bm x(t) + \\mathbf B\\bm u(t)\\\\\n\\bm y(t) &= \\mathbf C \\bm x(t) + \\mathbf D\\bm u(t)\\\\\n\\mathbf 0&\\leq \\bm u(t) \\perp \\bm y(t) \\geq \\mathbf 0.\n\\end{aligned}}\n\\tag{1}\n\nExample 1 (Electrical circuit with a diode as an LCS)  \n\n\n\nElectrical circuit to be modelled as an LCS\n\n\nNote the upside-down orientation of the voltage and the current for the capacitor – we wanted the diode current identical to the capacitor current.\nFollowing the charge formalism within Lagrangian modelling, we can choose the generalized coordinates as \n      \\bm q = \\begin{bmatrix}\n      q_L \\\\ q_C\n      \\end{bmatrix}.\n\nThat this is indeed a sufficient number is obvious, but we can also check the classical formula B-N+1 = 4-3+1 = 2. But we can also choose the state variables as \n      \\bm x = \\begin{bmatrix}\n      i_L\\\\ q_c\n      \\end{bmatrix}.\n\nThe resulting state equations are \n\\begin{aligned}\ni_L' &= -\\frac{1}{LC}q_C - \\frac{1}{L}u_D\\\\\nq_C' &= i_L - \\frac{1}{RC} q_C - \\frac{1}{R} u_D.\n\\end{aligned}\n\nThe idealized volt-ampere characteristics of the diode is\n\n\n\nIdeal volt-ampere characteristic of a diode\n\n\nFlipping the axes to get the current as the horizontal axis, we get\n\n\n\nFlipped volt-ampere characteristic of a diode\n\n\nFinally, after introducing an auxiliary variable (the reverse voltage of the diode) \\bar u_D = -u_D , we get the desired dependence\n\n\n\nYet another reformatted VA characteristic of a diode\n\n\nwhich can be modelled as a complementarity constraint\n\n0\\leq i_D \\perp \\bar u_D \\geq 0.\n\nNow, upon replacing the diode voltage with its reverse \\bar u_D while using i_D=i_C, we get \n\\begin{aligned}\ni_L' &= -\\frac{1}{LC}q_C + \\frac{1}{L} \\bar u_D\\\\\nq_C' &= i_L - \\frac{1}{RC} q_C + \\frac{1}{R} \\bar u_D\\\\\n0&\\leq q_C' \\perp \\bar u_D \\geq 0.\n\\end{aligned}\n\nWe are not there yet – there is a derivative in the complementarity constraint. But just substitute for it: \n\\begin{aligned}\ni_L' &= -\\frac{1}{LC}q_C + \\frac{1}{L} \\bar u_D\\\\\nq_C' &= i_L - \\frac{1}{RC} q_C + \\frac{1}{R} \\bar u_D\\\\\n0&\\leq i_L - \\frac{1}{RC} q_C + \\frac{1}{R} \\bar u_D \\perp \\bar u_D \\geq 0,\n\\end{aligned}\n\nand voila, we finally got the LCS description. We can also reformat it into the matrix-vector form \n\\begin{aligned}\n\\begin{bmatrix}\ni_L' \\\\ q_C'\n\\end{bmatrix} &=\n\\begin{bmatrix}\n0 &-\\frac{1}{LC}\\\\\n1  & - \\frac{1}{RC}\n\\end{bmatrix}\n\\begin{bmatrix}\ni_L \\\\ q_C\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\frac{1}{L}\\\\\n\\frac{1}{R}\n\\end{bmatrix}\n\\bar u_D\\\\\n0 &\\leq \\left(\\begin{bmatrix}\n1  & - \\frac{1}{RC}\n\\end{bmatrix}\n\\begin{bmatrix}\ni_L \\\\ q_C\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\frac{1}{L}\\\\\n\\frac{1}{R}\n\\end{bmatrix}\n\\bar u_D\\right ) \\bot \\bar u_D \\geq 0.\n\\end{aligned}\n\n\n\nExample 2 (Mass-spring system with a hard stop as a linear complementarity system) Two carts moving horitontally (left or right) are interconnected through a spring. The left cart is also interconnected with the wall through a another spring. Furthemore, the motion of the left cart is constrained in that there is a hard stop that prevents the cart from moving further to the left. Another natural constraint is that the right cart cannot get to the left of the other vehicle. The setup is shown in Fig. 1.\n\n\n\n\n\n\nFigure 1: Mass-spring system with a hard stop to be modelled as a LCS\n\n\n\nThe variables x_1 and x_2 give deviations of the two carts from their equilibrium positions. As we are considering negligible sizes of the two carts, the equilibrium position for both is 0. The derivatives of the two positions are also introduced as state variables x_3 and x_4, respectively.\nThe hard stop is located at the equilibrium position of the left cart.\nThe input u_1 corresponds to the reaction force of the hard stop applied to the left cart. Another input is u_2 that corresponds to the force exerted by the left cart onto the right cart.\nThe state equations are \n\\begin{aligned}\n\\dot x_1(t) &= x_3,\\\\\n\\dot x_2(t) &= x_4,\\\\\n\\dot x_3(t) &= -\\frac{k_1+k_2}{m_1}x_1(t) + \\frac{k_2}{m_1}x_2(t) + \\frac{1}{m_1}u_1(t) - \\frac{1}{m_1}u_2(t),\\\\\n\\dot x_4(t) &= \\frac{k_2}{m_2}x_1(t) - \\frac{k_2}{m_2} x_2(t) + \\frac{1}{m_2}u_2(t).\n\\end{aligned}\n\nThe presence of the hard stop can be modelled as an inequality constraint on the state x_1(t) \\geq  0.\nSimilarly, the fact that the right cart cannot get to the left of the left cart can be expressed as \nx_2(t) - x_1(t) \\geq 0.\n\nThis motivates us to define two output variables as \n\\begin{aligned}\ny_1(t) &= x_1(t),\\\\\ny_2(t) &= x_2(t)-x_1(t).\n\\end{aligned}\n\nNow, the reaction force u_1 exerted by the hard stop onto the left cart can only be nonnegative \nu_1(t) \\geq 0,\n\nand it is positive if and only if the left cart hits the hard stop\n\n      y_1(t) u_1(t) = 0.\n\nThe condition can be written compactly as \n0\\leq y_1(t) \\perp u_1(t) \\geq 0.\n\nSimilarly for the force u_2 exerted by the left cart onto the right cart \n0\\leq y_2(t) \\perp u_2(t) \\geq 0.\n\nFor convenience, we now give a full model in the matrix-vector form. \n\\begin{aligned}\n\\begin{bmatrix} \\dot x_1\\\\ \\dot x_2\\\\ \\dot x_3\\\\ \\dot x_4 \\end{bmatrix}\n&=\n\\begin{bmatrix}\n0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & 1\\\\\n{\\color{blue}-\\frac{k_1+k_2}{m_1}} & {\\color{blue}\\frac{k_2}{m_1}} & 0 & 0\\\\\n{\\color{blue}\\frac{k_2}{m_2}} & {\\color{blue}-\\frac{k_2}{m_2}} & 0 & 0\n\\end{bmatrix}\n\\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\\\ x_4 \\end{bmatrix} +\n\\begin{bmatrix} 0 & 0\\\\ 0 & 0\\\\ {\\color{blue}\\frac{1}{m_1}} & {\\color{blue}-\\frac{1}{m_1}}\\\\ {\\color{blue}0} & {\\color{blue}\\frac{1}{m_2}}\\end{bmatrix} \\begin{bmatrix} u_1\\\\u_2\\end{bmatrix},\\\\\n\\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix} &= \\begin{bmatrix} {\\color{blue}1} & {\\color{blue}0} & 0 & 0\\\\ {\\color{blue}-1} & {\\color{blue}1} & 0 & 0\\end{bmatrix} \\begin{bmatrix} x_1\\\\ x_2\\\\ x_3\\\\ x_4 \\end{bmatrix},\\\\\n\\mathbf 0 &\\leq \\bm y \\perp \\bm u \\geq \\mathbf 0.\n\\end{aligned}\n\\tag{2}\nNote that we highlighted in blue three submatrices that will come in handy in the next section.",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity systems"
    ]
  },
  {
    "objectID": "complementarity_systems.html#complementarity-system-as-a-feedback-interconnection",
    "href": "complementarity_systems.html#complementarity-system-as-a-feedback-interconnection",
    "title": "Complementarity systems",
    "section": "Complementarity system as a feedback interconnection",
    "text": "Complementarity system as a feedback interconnection\nA complementarity system Eq. 1 can be seen as a feedback interconnection of a linear system and a complementarity constraint.\n\n\n\nComplementarity system as a feedback interconnection",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity systems"
    ]
  },
  {
    "objectID": "complementarity_systems.html#complementarity-systems-vs-pwa-and-max-plus-linear-systems",
    "href": "complementarity_systems.html#complementarity-systems-vs-pwa-and-max-plus-linear-systems",
    "title": "Complementarity systems",
    "section": "Complementarity systems vs PWA and max-plus linear systems",
    "text": "Complementarity systems vs PWA and max-plus linear systems\nConsider the feedback interconnection of a dynamical system and the max(y,u) function in the feedback loop as in Fig. 2.\n\n\n\n\n\n\nFigure 2: Feedback interconnection of a dynamical system and a nonlinearity\n\n\n\nWe now express the original y as a difference of two nonnegative variable satisfying the complementarity constraint \ny = y^+ - y^-,\\quad 0 \\leq y^+ \\bot y^- \\geq 0.\n\nThe motivation for this was that with the new variables y^+ and y^-, the max function can be expressed as \n\\max(y,0) = \\max(y^+ - y^-, 0) = y^+.\n\nNow, set y^+ = u and then \ny = u - y^-,\n from which \ny^- = u - y\n and therefore the original feedback interconnection can be rewritten as\n\n\n\nFeedback interconnection equivalent to the one with max(y,0)",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity systems"
    ]
  },
  {
    "objectID": "complementarity_systems.html#more-complicated-pwa-functions-in-feedback",
    "href": "complementarity_systems.html#more-complicated-pwa-functions-in-feedback",
    "title": "Complementarity systems",
    "section": "More complicated PWA functions in feedback",
    "text": "More complicated PWA functions in feedback\nThe function \\max(y,0) that we have just considered is a very simple piecewise affine (PWA) function. But we can consider more complicated PWA functions. Only a little bit complicated PWA function is in Fig. 3.\n\n\n\n\n\n\nFigure 3: A simple piecewise affine function\n\n\n\nThe function is defined by shifting and scaling the original \\max(y,0) function: \nu(y) = k_1 \\max(y-y_1,0) = \\max(k_1(y-y_1),0).\n\nWe can now enforce complementarity based on this function in the feedback loop, see Fig. 4.\n\n\n\n\n\n\nFigure 4: Feedback system with a shifted PWA function modelled as complementarity constraint\n\n\n\nThis procedure can be extended towards PWA functions composed of several segments, see Fig. 5.\n\n\n\n\n\n\nFigure 5: PWA function with multiple segments\n\n\n\nThe function is defined as \n\\begin{aligned}\nu(y) &= k_0 y + u_0 + (k_1-k_0) \\max(y-y_1,0) \\\\\n&\\qquad + (k_2-k_1) \\max(y-y_2,0)\\\\\n&= k_0 y + u_0 + \\underbrace{\\max((k_1-k_0)(y-y_1),0)}_{u_1}\\\\\n&\\qquad + \\underbrace{\\max((k_2-k_1)(y-y_2),0)}_{u_2}\n\\end{aligned}\n and the feedback interconnection now contain several parallel paths with complementarity constraints as in Fig. 6\n\n\n\n\n\n\nFigure 6: Feedback system with multiple-segment PWA modelled as complementarity constraints",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity systems"
    ]
  },
  {
    "objectID": "mpc_mld_online.html",
    "href": "mpc_mld_online.html",
    "title": "Online MPC for hybrid systems",
    "section": "",
    "text": "First, we need to set the cost function for the optimal control problem. As usual in optimal control, we want to impose different weights on invididual state and control variables. The most popular is the quadratic cost function well known from the LQ-optimal control\n\nJ_0(x(0),U_0) = x_N^T S_N x_N + \\sum_{k=0}^{N-1} \\left( x_k^T Q x_k + u_k^T R u_k \\right)\n\nBut other (weighted) norms can also be used, in particular 1-norm and infinity-norm\n\nJ_0(x(0),U_0) = \\|S_N x_N\\|_1 + \\sum_{k=0}^{N-1} \\left( \\|Q x_k\\|_1 + \\|R u_k\\|_1 \\right),\n\n\nJ_0(x(0),U_0) = \\|S_N x_N\\|_{\\infty} + \\sum_{k=0}^{N-1} \\left( \\|Q x_k\\|_{\\infty} + \\|R u_k\\|_{\\infty} \\right).",
    "crumbs": [
      "11. Model predictive control (MPC) for MLD systems",
      "Online MPC for hybrid systems"
    ]
  },
  {
    "objectID": "mpc_mld_online.html#optimal-control-on-a-finite-horizon",
    "href": "mpc_mld_online.html#optimal-control-on-a-finite-horizon",
    "title": "Online MPC for hybrid systems",
    "section": "",
    "text": "First, we need to set the cost function for the optimal control problem. As usual in optimal control, we want to impose different weights on invididual state and control variables. The most popular is the quadratic cost function well known from the LQ-optimal control\n\nJ_0(x(0),U_0) = x_N^T S_N x_N + \\sum_{k=0}^{N-1} \\left( x_k^T Q x_k + u_k^T R u_k \\right)\n\nBut other (weighted) norms can also be used, in particular 1-norm and infinity-norm\n\nJ_0(x(0),U_0) = \\|S_N x_N\\|_1 + \\sum_{k=0}^{N-1} \\left( \\|Q x_k\\|_1 + \\|R u_k\\|_1 \\right),\n\n\nJ_0(x(0),U_0) = \\|S_N x_N\\|_{\\infty} + \\sum_{k=0}^{N-1} \\left( \\|Q x_k\\|_{\\infty} + \\|R u_k\\|_{\\infty} \\right).",
    "crumbs": [
      "11. Model predictive control (MPC) for MLD systems",
      "Online MPC for hybrid systems"
    ]
  },
  {
    "objectID": "mpc_mld_online.html#optimization-problem",
    "href": "mpc_mld_online.html#optimization-problem",
    "title": "Online MPC for hybrid systems",
    "section": "Optimization problem",
    "text": "Optimization problem\nCombining the cost function with the MLD model, and perhaps we some extra constraints imposed on the control inputs as well as state variables, we get \n\\operatorname*{minimize}_{u_0, u_1, \\ldots, u_{N-1}} J_0(x(0),(u_0, u_1, \\ldots, u_{N-1}))\n\nsubject to \n\\begin{aligned}\nx_{k+1} &= Ax_k + B_u u_k + B_\\delta\\delta_k + B_z z_k + B_0\\\\\ny_k &= Cx_k + D_u u_k + D_\\delta \\delta_k + D_z z_k + D_0\\\\\nE_\\delta \\delta_k &+ E_z z_k \\leq E_u u_k + E_x x_k + E_0 \\\\\nu_{\\min} &\\leq u_k \\leq u_{\\max} \\\\\nx_{\\min} &\\leq x_k \\leq x_{\\max} \\\\\nP x_N &\\leq r \\\\\nx_0 &= x(0)\n\\end{aligned}",
    "crumbs": [
      "11. Model predictive control (MPC) for MLD systems",
      "Online MPC for hybrid systems"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "B(E)3M35HYS – Hybrid systems",
    "section": "",
    "text": "This website constitutes the online lecture notes for the graduate course Hybrid Systems (B3M35HYS, BE3M35HYS) taught within Cybernetics and Robotics graduate program at Faculty of Electrical Engineering, Czech Technical University in Prague.\nOrganizational instructions, description of grading policy, assignments of homework problems and other course related material relevant for officially enrolled students are located elsewhere (the course page within the FEL Moodle).\n\n\n\n Back to top"
  },
  {
    "objectID": "petri_nets_software.html",
    "href": "petri_nets_software.html",
    "title": "Software",
    "section": "",
    "text": "Petri nets constitute a powerful and flexible framework for modelling discrete-event systems, and yet the selection of mature and well-maintained software tools is not particularly wide. How come? Petri nets have already inspired a few other frameworks such as Grafcet and SFC for PLC programming, as we discuss in the overview of the literature. The “vanilla version” of Petri nets then serves mainly for academic research.",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Software"
    ]
  },
  {
    "objectID": "petri_nets_software.html#matlab",
    "href": "petri_nets_software.html#matlab",
    "title": "Software",
    "section": "Matlab",
    "text": "Matlab\n\nPetri Net Toolbox (probably commercial, not immediately available for download)",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Software"
    ]
  },
  {
    "objectID": "petri_nets_software.html#python",
    "href": "petri_nets_software.html#python",
    "title": "Software",
    "section": "Python",
    "text": "Python\nSNAKES (github)",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Software"
    ]
  },
  {
    "objectID": "petri_nets_software.html#julia",
    "href": "petri_nets_software.html#julia",
    "title": "Software",
    "section": "Julia",
    "text": "Julia\n\nPetri.jl\nAlgebraicPetri.jl\nTimedPetriNetEditor.jl",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Software"
    ]
  },
  {
    "objectID": "petri_nets_software.html#standalone",
    "href": "petri_nets_software.html#standalone",
    "title": "Software",
    "section": "Standalone",
    "text": "Standalone\n\nTimedPetriNetEditor\npn-editor (It uses pnrs, a safe rust wrapper for pns written in C)",
    "crumbs": [
      "2. Discrete-event systems: Petri nets",
      "Software"
    ]
  },
  {
    "objectID": "complementarity_constraints.html",
    "href": "complementarity_constraints.html",
    "title": "Complementarity constraints",
    "section": "",
    "text": "In this chapter we are going to present yet another framework for modelling hybrid systems, which comes with a rich theory and efficient algorithms. It is based on complementarity constraints. Before we introduce the modelling framework in the next section, we first explain the very concept of complementarity constraints and the related optimization problems.",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#why-complementarity-constraints",
    "href": "complementarity_constraints.html#why-complementarity-constraints",
    "title": "Complementarity constraints",
    "section": "",
    "text": "In this chapter we are going to present yet another framework for modelling hybrid systems, which comes with a rich theory and efficient algorithms. It is based on complementarity constraints. Before we introduce the modelling framework in the next section, we first explain the very concept of complementarity constraints and the related optimization problems.",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#definition-of-complementarity-constraints",
    "href": "complementarity_constraints.html#definition-of-complementarity-constraints",
    "title": "Complementarity constraints",
    "section": "Definition of complementarity constraints",
    "text": "Definition of complementarity constraints\nTwo variables x\\in\\mathbb R and y\\in\\mathbb R satisfy the complementarity constraint if x or y is equal to zero and both are nonnegative\nxy=0, \\; x\\geq 0,\\; y\\geq 0,\nor, using a dedicated compact notation\n\\boxed{0\\leq x \\perp y \\geq 0.}\n\n\n\n\n\n\nBoth variables can be zero simultaneously\n\n\n\nThe or in the above definition is not exclusive, therefore it is possible that both x and y are zero.\n\n\nThe concept and notation extends to vectors x\\in\\mathbb R^n and y\\in\\mathbb R^n, in which case the constraint is interpreted componentwise \\boxed{\\bm 0\\leq \\bm x \\perp \\bm y \\geq \\bm 0.}",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#geometric-interpretation-of-complementarity-constraints",
    "href": "complementarity_constraints.html#geometric-interpretation-of-complementarity-constraints",
    "title": "Complementarity constraints",
    "section": "Geometric interpretation of complementarity constraints",
    "text": "Geometric interpretation of complementarity constraints\nThe set of admissible pairs (x,y) in the \\mathbb R^2 plane is constrained to the L-shaped subset given by the nonnegative x and y semi-axes (including the origin) as in Fig. 1.\n\n\n\n\n\n\nFigure 1: The set of solutions satisfying a complementarity constraint\n\n\n\nOptimization over these constraints is difficult, and not only because the feasible set is nonconvex, but also because constraint qualification conditions are not satisfied. Still, some results and tools are available for some classes of optimization problems with these constraints.",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#linear-complementarity-problem-lcp",
    "href": "complementarity_constraints.html#linear-complementarity-problem-lcp",
    "title": "Complementarity constraints",
    "section": "Linear complementarity problem (LCP)",
    "text": "Linear complementarity problem (LCP)\nFor a given square matrix \\mathbf M and a vector \\mathbf q , the linear complementarity problem (LCP) asks for finding two vectors \\bm w and \\bm z satisfying \n  \\begin{aligned}\n  \\bm w-\\mathbf M\\bm z &= \\mathbf q, \\\\\n  \\bm 0 \\leq \\bm w &\\perp \\bm z \\geq \\bm 0.\n  \\end{aligned}\n\nJust by moving all the provided data to the right-hand side we get \\bm w = \\underbrace{\\mathbf M\\bm z + \\mathbf q}_{\\mathbf f(\\bm z)} and we can write the linear complementarity constraint compactly as \\boxed{\n\\mathbf 0 \\leq \\mathbf M\\bm z + \\mathbf q \\perp \\bm z \\geq \\mathbf 0.}\n\\tag{1}",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#existence-of-a-unique-solution",
    "href": "complementarity_constraints.html#existence-of-a-unique-solution",
    "title": "Complementarity constraints",
    "section": "Existence of a unique solution",
    "text": "Existence of a unique solution\nA unique solution exists for every vector \\mathbf q if and only if the matrix \\mathbf M is a P-matrix (something like positive definite, but not exactly, look it up yourself).",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#lcp-related-to-lp-and-qp",
    "href": "complementarity_constraints.html#lcp-related-to-lp-and-qp",
    "title": "Complementarity constraints",
    "section": "LCP related to LP and QP",
    "text": "LCP related to LP and QP\nNote that the KKT conditions for LP and QP come in the form of LCP.\nConsider the QP problem with inequality constraints \\text{minimize} \\quad \\frac{1}{2}\\bm x^\\top \\mathbf Q \\bm x + \\mathbf c^\\top \\bm x \\text{subject to} \\quad \\mathbf A\\bm x \\geq \\mathbf b,\\quad \\bm x\\geq \\mathbf 0,\nThe KKT conditions can be written (and compare these to the conditions for the equality-constrained QP) \n\\begin{aligned}\n\\mathbf 0\\leq \\bm x &\\perp \\mathbf Q\\bm x - \\mathbf A^\\top \\bm \\lambda + \\mathbf c \\geq \\mathbf 0\\\\\n\\mathbf 0\\leq \\bm \\lambda &\\perp \\mathbf A\\bm x -\\mathbf b \\geq \\mathbf 0.\n\\end{aligned}\n\nThese can be reformatted as \n\\mathbf 0\\leq \\underbrace{\\begin{bmatrix}\\bm x\\\\ \\bm \\lambda\\end{bmatrix}}_{\\bm z}\n\\perp\n\\underbrace{\\begin{bmatrix} \\mathbf Q & -\\mathbf A^\\top \\\\ \\mathbf A & \\mathbf 0\\end{bmatrix}\\begin{bmatrix}\\bm x\\\\ \\bm \\lambda\\end{bmatrix} + \\begin{bmatrix} \\mathbf c \\\\ -\\mathbf b \\end{bmatrix}}_{\\mathbf M\\bm z+\\mathbf q}\\geq 0.",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#nonlinear-complementarity-problem-nlcp",
    "href": "complementarity_constraints.html#nonlinear-complementarity-problem-nlcp",
    "title": "Complementarity constraints",
    "section": "Nonlinear complementarity problem (NLCP)",
    "text": "Nonlinear complementarity problem (NLCP)\nRecall that when deriving Eq. 1, we denoted the right-hand side by \\mathbf f(\\bm x). The motivation for this was to help define a general nonlinear complementarity problem (NLCP): given a vector function \\mathbf f: \\mathbb R^n\\rightarrow \\mathbb R^n, find a vector \\bm x\\in\\mathbb R^n satisfying \\boxed{\n\\bm 0\\leq \\bm x \\perp \\mathbf f(\\bm x) \\geq \\bm 0.}\n\\tag{2}",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#mixed-complementarity-problem-mcp",
    "href": "complementarity_constraints.html#mixed-complementarity-problem-mcp",
    "title": "Complementarity constraints",
    "section": "Mixed complementarity problem (MCP)",
    "text": "Mixed complementarity problem (MCP)\nWe now provide an extension of a complementarity constraint to the situation in which the variable x is lower- and upper-bounded. In particular, it can be stated as \\boxed{\n  l \\leq x \\leq u \\perp f(x),}\n\\tag{3}\nwhere l and u are vectors of lower and upper bounds, respectively, and f(x) is a vector function which reads that\n\nif x is strictly within the interval, that is, l &lt; x &lt; u , then f(x)=0,\nif x= l , then f(x)\\geq 0,\nif x= u , then f(x)\\leq 0,\n\nwith elementwise interpretation in the vector case.",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "complementarity_constraints.html#extensions-and-related-problems",
    "href": "complementarity_constraints.html#extensions-and-related-problems",
    "title": "Complementarity constraints",
    "section": "Extensions and related problems",
    "text": "Extensions and related problems\nLCP and MCP are all we need in our course, but let’s mentions some extensions and related problems.\n\nExtended linear complementarity problem (ELCP)\nGiven some matrices \\mathbf A and \\mathbf B , vectors \\mathbf c and \\mathbf d , and m subsets \\phi_j \\sub \\{1,2,\\ldots,p\\} , find a vector \\bm x such that \n  \\begin{aligned}\n  \\sum_{j=1}^m\\prod_{i\\in\\phi_j}(\\mathbf A\\bm x - \\mathbf c)_i &= 0,\\\\\n  \\mathbf A\\bm x &\\geq \\mathbf c,\\\\\n  \\mathbf B\\bm x &= \\mathbf d,\n  \\end{aligned}\n\nor show that no such \\bm x exists.\nThe first equation is equivalent to \n\\forall j \\in \\{1, \\ldots, m\\} \\; \\exist i \\in \\phi_j \\;\\text{such that} \\; (\\mathbf A\\bm x − \\mathbf c)_i = 0.\n\nGeometric interpretation: union of some faces of a polyhedron.\n\n\nMathematical program with complementarity constraints (MPCC)\nThe mathematical program with complementarity constraints (MPCC) is \n  \\begin{aligned}\n  \\operatorname*{minimize}_{\\bm x\\in\\mathbb R^n} & \\;f(\\bm x)\\\\\n  \\text{subject to} & \\;\\mathbf 0\\leq \\mathbf h(\\bm x) \\perp \\mathbf g(\\bm x) \\geq \\mathbf 0.\n  \\end{aligned}\n\nIt is a special case of Mathematical program with equilibrium constraints (MPEC).\n\n\nMathematical program with equilibrium constraints (MPEC)\nOptimization problem in which some variable should satisfy equilibrium constraints: \n  \\begin{aligned}\n  \\operatorname*{minimize}_{x_1,x_2} &\\; f(x_1,x_2)\\\\\n  \\text{subject to}&\\; \\nabla_{x_2} \\phi(x_1,x_2) = 0.\n  \\end{aligned}\n\nFor convex \\phi() it can be reformulated into a Bilevel optimization problem.\n\n\nBilevel optimization\nOptimization problem in which some variables are constrained to be results of some inner optimization. In the simplest form \n\\begin{aligned}\n  \\operatorname*{minimize}_{x_1,x_2} &\\; f(x_1,x_2)\\\\\n  \\text{subject to}\\ &\\; x_2 = \\text{arg}\\,\\min_{x_2} \\;\\phi(x_1,x_2).\n\\end{aligned}\n\n\n\nDisjunctive constraints\nDisjunctive constraints are given by a number of conditions induced by affine constraints and connected with \\lor and \\land logical operators\n\nT_1 \\lor T_2 \\lor \\ldots \\lor T_m,\n where \nT_i = T_{i1} \\land T_{i1} \\land \\ldots \\land T_{in_{i}},\n where \nT_{ij} = \\left[\\mathbf c_{ij}\\bm x + \\mathbf d_{ij} \\in \\mathcal D_{ij}\\right].\n\nThe connection of disjunctive constraints with complementarity constraints is straightforward:\n\n\\underbrace{(x\\geq 0)}_{T_{11}} \\land \\underbrace{(xy = 0)}_{T_{12}} \\land \\underbrace{(y\\geq 0)}_{T_{13}}.\n\n\n\nVariational inequality (VI)\nGiven a set \\mathcal K and a function F: \\mathcal K \\rightarrow \\mathbb R^n, find a vector \\bm x\\in\\mathcal K such that \n\\langle \\mathbf F(\\bm x), \\bm y-\\bm x \\rangle \\geq 0 \\quad \\forall \\bm y\\in\\mathcal K.\n\nIf \\mathbf F(\\bm x) = \\nabla f(\\bm x) , VI is a convex optimization problem, that is, the problem of finding a vector \\bm x\\in\\mathcal K such that\n\n\\langle \\nabla f(\\bm x), \\bm y-\\bm x \\rangle \\geq 0 \\quad \\forall \\bm y\\in\\mathcal K.\n\nBut there may also be \\mathbf F(\\bm x) that is not the gradient of any function f(\\bm x). In this regards, VI is a broader class of problems than convex optimization.\nThe reason why we include this problem class here is that if \\mathcal K is a nonnegative orthant \\mathbb R_{++}^n, that is, x_i \\geq 0, \\; i=1, \\ldots, n , then the VI specializes to finding \\bm x\\geq \\mathbf 0 such that \n\\langle \\mathbf F(\\bm x), \\bm y-\\bm x \\rangle \\geq 0 \\quad \\forall \\bm y\\geq \\mathbf 0,\n and it can be shown that it is equivalent to the NCP or LCP, depending on \\mathbf F().\n\nProof. For \\bm y=\\bm 0, we get \\langle \\mathbf F(\\bm x), -\\bm x \\rangle \\geq 0, which is equivalent to \\langle \\mathbf F(\\bm x), \\bm x \\rangle \\leq 0. For \\bm y = 2\\bm x, we get \\langle \\mathbf F(\\bm x), \\bm x \\rangle \\geq 0. Reconciling the two inequalities, we get \\langle \\mathbf F(\\bm x), \\bm x \\rangle = 0. Invoking the linearity of the inner product, we get \\langle \\mathbf F(\\bm x), \\bm y-\\bm x \\rangle = \\langle \\mathbf F(\\bm x), \\bm y\\rangle \\geq 0 \\; \\forall \\bm y\\geq \\mathbf 0, from which it follows that \\mathbf F(\\bm x)\\geq 0.\n\nSimilarly, if \\mathcal K is a “box” in \\mathbb R^n, that is, -\\infty\\leq l_i \\leq x_i \\leq u_i\\leq \\infty, \\; i=1, \\ldots, n, then VI is equivalent to the MCP. #TODO: sketch the explanation, if not a full proof.",
    "crumbs": [
      "9. Complementarity systems",
      "Complementarity constraints"
    ]
  },
  {
    "objectID": "verification_intro.html",
    "href": "verification_intro.html",
    "title": "What is verification?",
    "section": "",
    "text": "It has become nearly a tradition in our course that the terminology we use is often heavily overloaded. The term verification is no exception. Although we provide a definition below, to which which are going to adhere in this course, it is important to be aware that the term is also used in many different contexts and with different meanings.",
    "crumbs": [
      "12. Formal verification",
      "What is verification?"
    ]
  },
  {
    "objectID": "verification_intro.html#verification-vs-validation",
    "href": "verification_intro.html#verification-vs-validation",
    "title": "What is verification?",
    "section": "Verification vs validation",
    "text": "Verification vs validation\nOne particular opportunity for confusion is the related term validation. According to PMBOK Guide:\n\nValidation\n\nThe assurance that a product, service, or system meets the needs of the customer and other identified stakeholders. It often involves acceptance and suitability with external customers.\n\nVerification\n\nThe evaluation of whether or not a product, service, or system complies with a regulation, requirement, specification, or imposed condition. It is often an internal process.\n\n\nUndoubtedly, other definitions can be found, but we are going to stick to viewing verification as the process of checking if a system satisfies the given specifications or requirements. Whether these correctly capture the needs of the customer is a different question.",
    "crumbs": [
      "12. Formal verification",
      "What is verification?"
    ]
  },
  {
    "objectID": "verification_intro.html#approches-to-verification",
    "href": "verification_intro.html#approches-to-verification",
    "title": "What is verification?",
    "section": "Approches to verification",
    "text": "Approches to verification\n\nTesting – just run the system and see if it behaves as expected. Disadvantages are obvious: cost, time, coverage.\nSimulation – reduces these disadvantages, but not completely – the coverage issue remains.\nAnalytical techniques, also known as formal verification – the aim is to prove satisfaction of specifications for all possible conditions/evolutions of the system. The specifications (or requirements) are given in a formal (mathematical) language. Formal (mathematical) methods are then used.",
    "crumbs": [
      "12. Formal verification",
      "What is verification?"
    ]
  },
  {
    "objectID": "verification_intro.html#model-checking-as-one-of-formal-verification-approaches",
    "href": "verification_intro.html#model-checking-as-one-of-formal-verification-approaches",
    "title": "What is verification?",
    "section": "Model checking as one of formal verification approaches",
    "text": "Model checking as one of formal verification approaches\nThere are several classes of formal verification techniques. One of them is model checking. It is based on a model of the system. For discrete-event and hybrid system the model is in the form of Labelled Transition System (LTS). The outcome of the model checking is a proof or a counterexample.",
    "crumbs": [
      "12. Formal verification",
      "What is verification?"
    ]
  },
  {
    "objectID": "verification_intro.html#labelled-transition-system-lts",
    "href": "verification_intro.html#labelled-transition-system-lts",
    "title": "What is verification?",
    "section": "Labelled Transition system (LTS)",
    "text": "Labelled Transition system (LTS)\nLabelled transition system (LTS) is essentially a variant of a (hybrid) automaton. Labels are attached to the states rather than the transitions. The labels come from the set \\mathcal{P} of atomic propositions \\mathcal{P} = \\{p_1, p_2, \\ldots, p_n\\}.\nLabelling function l: \\mathcal X \\to 2^\\mathcal{P} assigns a set of atomic propositions to each state.\n\nExample 1 (LTS for a beverage vending machine) We consider our good old friend – the beverage vending machine. We draw (again) its automaton, but also consider the set of atomic propositions \\mathcal{P} = \\{\\text{pending},\\text{paid},\\text{delivered}\\} and we label the states with these.\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nwaiting\n\n{}\nwaiting\n\n\n\ninit-&gt;waiting\n\n\n\n\n\nswiped\n\n{pending}\nswiped\n\n\n\nwaiting-&gt;swiped\n\n\nswipe card\n\n\n\nswiped-&gt;waiting\n\n\nreject payment\n\n\n\npaid\n\n{paid}\npaid\n\n\n\nswiped-&gt;paid\n\n\naccept payment\n\n\n\ncoke_dispensed\n\n{paid, delivered}\ncoke\ndispensed\n\n\n\npaid-&gt;coke_dispensed\n\n\nchoose coke\n\n\n\nfanta_dispensed\n\n{paid, delivered}\nfanta\ndispensed\n\n\n\npaid-&gt;fanta_dispensed\n\n\nchoose fanta\n\n\n\ncoke_dispensed-&gt;waiting\n\n\ntake coke\n\n\n\nfanta_dispensed-&gt;waiting\n\n\ntake fanta\n\n\n\n\n\n\nFigure 1: LTS for a beverage vending machine\n\n\n\n\n\nHaving the states labelled with atomic propositions, we can now formulate specifications in terms of these propositions. For example, we can express the following two specifications:\n\nSpecification #1: The machine never dispenses a beverage without being paid, that is, \n\\text{delivered} \\Rightarrow \\text{paid}.\n\nSpecification #2: If the user pays, the machine will eventually dispenses a beverage.\n\nThe trouble with the latter specification is: how do we formally express the “eventually” part? It turns out that the classical propositional logic is not enough. We will need to introduce temporal logic(s). This we will do in one of the next sections.\n\nBefore we move on, we can highlight two common types of specifications that can do without temporal logics.",
    "crumbs": [
      "12. Formal verification",
      "What is verification?"
    ]
  },
  {
    "objectID": "verification_intro.html#two-special-types-of-specifications",
    "href": "verification_intro.html#two-special-types-of-specifications",
    "title": "What is verification?",
    "section": "Two special types of specifications",
    "text": "Two special types of specifications\n\nSafety (also invariance)\nLiveness (also progress)\n\n\nSafety (also invariance)\nSafety (yikes, another rather overloaded term) means that “something bad never happens”. Within state models (state automata and hybrid automata), this can be formulated as the system never entering the bad (unsafe) region of the state space.\nEquivalently, it can be phrased as “something good always holds”. With the state perspective, the system always stays in a good (safe) region of the state space.\nHow do we check safety? There are several techniques. In our course we are going to introduce two that are very popular in the control systems community:\n\nReachability analysis,\nBarrier certificates.\n\n\n\nLiveness (also progress)\nIt can be phrased as “something good will eventually happen”. Liveness (or progress) specifications be formulated in the state spacee too. The system is required to eventually reach a certain state or a subset in the state space. Depending on the flavour of the liveness specification, the initial set may be specified or not.\nControl systems community must immediately recognize here one fundamental property that does clasify as a liveness property: stability. A stable system will eventually reach a certain state – the equlibrium.",
    "crumbs": [
      "12. Formal verification",
      "What is verification?"
    ]
  },
  {
    "objectID": "des_automata.html",
    "href": "des_automata.html",
    "title": "State automata",
    "section": "",
    "text": "Having just discussed the concept of a discrete-event system, we now introduce the most popular modeling framework for such systems: a state automaton, or just an automaton (plural automata). It is also known as a state machine or a (discrete) transition system.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#marked-states",
    "href": "des_automata.html#marked-states",
    "title": "State automata",
    "section": "Marked states",
    "text": "Marked states\nIn some literature, the definition of the automaton also includes a set \\mathcal X_\\mathrm{m} \\subseteq \\mathcal X of marked or accepting states, in which case the definition of an automaton now includes three (sub)sets of states: \\mathcal X, \\mathcal X_0 and \\mathcal X_\\mathrm{m}. \\boxed{\nG = \\{\\mathcal X,\\mathcal X_0,\\mathcal E,\\mathcal F, \\mathcal X_\\mathrm{m}\\}.}\n\nThe marked states are just some states with special roles in the system. Namely, these are the states into which the system should be controlled. I do not particularly like this idea of mixing the model of the system with the requirements, but some part of the community likes it this way.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#automaton-as-a-digraph-also-a-state-transition-diagram",
    "href": "des_automata.html#automaton-as-a-digraph-also-a-state-transition-diagram",
    "title": "State automata",
    "section": "Automaton as a (di)graph (also a state transition diagram)",
    "text": "Automaton as a (di)graph (also a state transition diagram)\nSo far the definition of an automaton was not particularly visual. This can be changes by viewing the automaton as a directed graph (digraph) with. These are the basic rules\n\nState is represented as a node of the graph.\nTransition from a given state to another state is represented as an edge connecting the two nodes.\nEvents (actions) are the labels attached to the edges. It is not necessary that each edge has its unique label.\n\n\nExample 1 (Automaton as a digraph) Consider an automaton defined by these sets: \\mathcal X = \\{x_1,x_2,x_3\\}, \\mathcal X_0 = \\{x_1\\}, \\mathcal E = \\{e_1,e_2,e_3\\}, \\mathcal F = \\{(x_1,e_1,x_2),(x_2,e_2,x_1),(x_1,e_3,x_3),(x_2,e_2,x_3)\\}.\nThe corresponding digraph is in Fig. 1.\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nx₁\n\nx₁\n\n\n\ninit-&gt;x₁\n\n\n\n\n\nx₂\n\nx₂\n\n\n\nx₁-&gt;x₂\n\n\ne₁\n\n\n\nx₃\n\nx₃\n\n\n\nx₁-&gt;x₃\n\n\ne₂\n\n\n\nx₂-&gt;x₁\n\n\ne₂\n\n\n\nx₂-&gt;x₃\n\n\ne₃\n\n\n\n\n\n\nFigure 1: An example automaton as a digraph\n\n\n\n\n\n\nWe may also encounter the following term.\n\nDefinition 2 (Active event function and set) Active event function (actually a multivalued function) \\Gamma: \\mathcal X \\rightarrow 2^\\mathcal{E} assigns to each state a set of active events. Active event set \\Gamma(x) is the set of active events in a particular state x.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#finite-state-automaton-fsa",
    "href": "des_automata.html#finite-state-automaton-fsa",
    "title": "State automata",
    "section": "Finite state automaton (FSA)",
    "text": "Finite state automaton (FSA)\nThis may be regarded as a rather superfluous definition – a finite state automaton (FSA) is a state automaton with a finite set \\mathcal X of states. It is also known as a finite state machine (FSM).",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#execution-of-an-automaton",
    "href": "des_automata.html#execution-of-an-automaton",
    "title": "State automata",
    "section": "Execution of an automaton",
    "text": "Execution of an automaton\n\nx_1\\xrightarrow{e_1} x_2\\xrightarrow{e_2} x_1 \\xrightarrow{e_1} x_2 \\xrightarrow{e_4} x_3\\ldots\nSometimes also written as x_1,e_1,x_2,e_2,\\ldots\n\n\n\n\n\n\n\n\nNotational confusion\n\n\n\nHere x_k for some k is the name of a particular state. It is not the name of a (yet to be introduced) state variable; In fact, it can be viewed as its value (also valuation).\n\n\n\nSome authors strictly distinguish between the state variable and the state (variable valuation),\n\nsimilarly as in probability theory random variable X vs its value x, as in F(x) = P(X\\leq x);\n\nsome do not, but then it may lead to confusion;\nyet some others avoid the problem by not introducing state variables and only working with enumerated states.\n\n\n\n\n\n\n\n\nNotational confusion 2\n\n\n\nEven worse, it is also tempting to interpret the lower index k as (discrete) time, but nope, in the previous k is not the time index.\nAgain, some authors do not distinguish…",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#path-of-an-automaton",
    "href": "des_automata.html#path-of-an-automaton",
    "title": "State automata",
    "section": "Path of an automaton",
    "text": "Path of an automaton\nCorresponding to the execution\nx_1\\xrightarrow{e_1} x_2\\xrightarrow{e_2} x_1 \\xrightarrow{e_1} x_2 \\xrightarrow{e_4} x_3\\ldots\nthe path is just the sequence of visited states:\nx_1,x_2,x_1,x_2,x_3,\\ldots\n\nIn continuous-valued dynamical systems, we have a state trajectory, but then time stamps are attached to each visited state.\n\n\nExample 2 (Beverage vending machine)  \n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nwaiting\n\nwaiting\n\n\n\ninit-&gt;waiting\n\n\n\n\n\nswiped\n\nswiped\n\n\n\nwaiting-&gt;swiped\n\n\nswipe card\n\n\n\nswiped-&gt;waiting\n\n\nreject payment\n\n\n\npaid\n\npaid\n\n\n\nswiped-&gt;paid\n\n\naccept payment\n\n\n\ncoke_dispensed\n\ncoke_dispensed\n\n\n\npaid-&gt;coke_dispensed\n\n\nchoose coke\n\n\n\nfanta_dispensed\n\nfanta_dispensed\n\n\n\npaid-&gt;fanta_dispensed\n\n\nchoose fanta\n\n\n\ncoke_dispensed-&gt;waiting\n\n\ntake coke\n\n\n\nfanta_dispensed-&gt;waiting\n\n\ntake fanta\n\n\n\n\n\n\nFigure 2: Example of a digraph representation of the automaton for a beverage vending machine\n\n\n\n\n\n\nState sequence (path): waiting, swiped, paid, coke_dispensed, waiting\nEvents sequence: swipe card, accept payment, choose coke, take coke\nIndeed, the two states coke_dispensed and fanta_dispensed can be merged into just beverage_dispensed.\nHow about other paths? Longer? Shorter?\n\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nwaiting\n\n\nwaiting\n\n\n\ninit-&gt;waiting\n\n\n\n\n\nswiped\n\nswiped\n\n\n\nwaiting-&gt;swiped\n\n\nswipe card\n\n\n\nswiped-&gt;waiting\n\n\nreject payment\n\n\n\npaid\n\npaid\n\n\n\nswiped-&gt;paid\n\n\naccept payment\n\n\n\ncoke_dispensed\n\ncoke_dispensed\n\n\n\npaid-&gt;coke_dispensed\n\n\nchoose coke\n\n\n\nfanta_dispensed\n\nfanta_dispensed\n\n\n\npaid-&gt;fanta_dispensed\n\n\nchoose fanta\n\n\n\ncoke_dispensed-&gt;waiting\n\n\ntake coke\n\n\n\nfanta_dispensed-&gt;waiting\n\n\ntake fanta\n\n\n\n\n\n\nFigure 3: Example of a digraph representation of the automaton for a beverage vending machine with a marked state\n\n\n\n\n\nThe waiting state can be marked (is accepting).\n\n\nExample 3 (Longitudinal control of a ground vehicle)  \n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nstill\n\nstill\n\n\n\ninit-&gt;still\n\n\n\n\n\naccelerating\n\naccelerating\n\n\n\nstill-&gt;accelerating\n\n\npush acc\n\n\n\ncruising\n\ncruising\n\n\n\naccelerating-&gt;cruising\n\n\ncruise ON\n\n\n\ncoasting\n\ncoasting\n\n\n\naccelerating-&gt;coasting\n\n\nrel acc\n\n\n\ncruising-&gt;accelerating\n\n\npush acc\n\n\n\ncruising-&gt;coasting\n\n\nrel acc\n\n\n\nbraking\n\nbraking\n\n\n\ncruising-&gt;braking\n\n\npush brake\n\n\n\ncoasting-&gt;braking\n\n\npush brake\n\n\n\nbraking-&gt;still\n\n\nzero vel\n\n\n\nbraking-&gt;cruising\n\n\ncruise ON\n\n\n\nbraking-&gt;coasting\n\n\nrel brake\n\n\n\n\n\n\nFigure 4: Example of a digraph representation of the automaton for a longitudinal control of a ground vehicle\n\n\n\n\n\n\n\n\nBy cruise on I mean switching on some kind of a cruise control system, which keeps the velocity constant.\nIt turns out the optimal control strategy for trains (under some circumstances).\nNote that some of the events are indeed actions started by the driver, but some are just coming from the physics of the vehicle (transition from braking to zero velocity).\n\n\n\nExample 4 (Corridor switch)  \n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nOFF\n\nOFF\n\n\n\ninit-&gt;OFF\n\n\n\n\n\nON\n\nON\n\n\n\nOFF-&gt;ON\n\n\nswitch₁,switch₂\n\n\n\nON-&gt;OFF\n\n\nswitch₁,switch₂\n\n\n\n\n\n\nFigure 5: Example of a digraph representation of the automaton for a corridor switch\n\n\n\n\n\nTwo events associated with one transitions can be seen as two transitions, each with a single event, both sharing the starting and ending states.\n\n\nExample 5 (JK flip-flop) We now consider the classical JK flip-flop logical circuit. It symbol is in Fig. 7 and the truth table follows. Our goal is to represent its functionality using a state automaton.\n\n\n\n\n\n\nFigure 6: Symbol for a JK flip-flop logical circuit\n\n\n\n\n\n\nJ\nK\nQ_k\nQ_{k+1}\nDescription\n\n\n\n\n0\n0\n0\n0\nNo change\n\n\n0\n0\n1\n1\nNo change\n\n\n0\n1\n0\n0\nReset\n\n\n0\n1\n1\n0\nReset\n\n\n1\n0\n0\n1\nSet\n\n\n1\n0\n1\n1\nSet\n\n\n1\n1\n0\n1\nToggle\n\n\n1\n1\n1\n0\nToggle\n\n\n\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nLow\n\nLow\n\n\n\ninit-&gt;Low\n\n\n\n\n\nLow-&gt;Low\n\n\n¬J ∧ ¬K ∧ clk\n\n\n\nHigh\n\nHigh\n\n\n\nLow-&gt;High\n\n\nJ ∧ clk\n\n\n\nHigh-&gt;Low\n\n\nK ∧ clk\n\n\n\nHigh-&gt;High\n\n\n¬J ∧ ¬K ∧ clk\n\n\n\n\n\n\nFigure 7: JK flip-flop as an automaton\n\n\n\n\n\n\n\nExample 6 (Double intensity switching)  \n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nOFF\n\nOFF\n\n\n\ninit-&gt;OFF\n\n\n\n\n\nON\n\nON\n\n\n\nOFF-&gt;ON\n\n\npush\n\n\n\nON-&gt;OFF\n\n\npush\n\n\n\nON2\n\nON2\n\n\n\nON-&gt;ON2\n\n\npush\n\n\n\nON2-&gt;OFF\n\n\npush\n\n\n\n\n\n\nFigure 8: Example of a digraph representation of the automaton for double intensity switching\n\n\n\n\n\nObviously we need to introduce time into the automaton…",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#state-as-the-value-of-a-state-variable",
    "href": "des_automata.html#state-as-the-value-of-a-state-variable",
    "title": "State automata",
    "section": "State as the value of a state variable",
    "text": "State as the value of a state variable\nDefinition of the state space by enumeration (such as \\mathcal X = \\{0,1,2,3,4,5\\}) doesn’t scale well. As an alternative, a state can be characterized by the value (sometimes also valuation) of a state variable. A state variable is then given by\n\nthe name (for example, x),\nthe “type” (boolean, integer, vector, …).\n\n\nExample 7 (Examples of state variables)  \n\nCorridor switch: x \\in \\{\\mathrm{false},\\mathrm{true}\\} (possibly also \\{0,1\\}).\nDouble intensity switching:\n\nx \\in \\{0,1,2\\} \\subset \\mathbb Z,\nor \\bm x = \\begin{bmatrix}x_1\\\\ x_2 \\end{bmatrix}, where x_1,x_2 \\in \\{0,1\\}.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#state-transition-equation",
    "href": "des_automata.html#state-transition-equation",
    "title": "State automata",
    "section": "State (transition) equation",
    "text": "State (transition) equation\nDenoting a new state after a transition as x^+, the state equation reads \\boxed{x^+ = f(x,e)}\nUpon introduction of discrete-time (index) k, it can also be rewritten as x_{k+1} = f(x_k,e_k) or also x[k+1] = f(x[k],e[k]).\n\n\n\n\n\n\nNote\n\n\n\n\nThe function f can be defined by a computer code rather than a clean mathematical formula.\nThe discrete-time index of the event is sometimes considered shifted, that is x_{k+1} = f(x_k,e_{k+1}). You should be aware of this.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#extensions",
    "href": "des_automata.html#extensions",
    "title": "State automata",
    "section": "Extensions",
    "text": "Extensions\nThe concept of an automaton can be extended in several ways. In particular, the following two extensions introduce the concept of an output to an automaton.\n\nMoore machine\nOne extension of an automaton with outputs is Moore machine. The outputs assigned to the states by the output function y = g(x).\nThe output is produced (emitted) when the (new) state is entered.\nNote, in particular, that the output does not depend on the input. This has a major advantage when a feedback loop is closed around this system, since no algebraic loop is created.\nGraphically, we make a conventions that outputs are the labels of the states.\n\nExample 8 (Moore machine) The following automaton has just three states, but just two outputs (FLOW and NO FLOW).\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nclosed\n\nNO FLOW\nValve\nclosed\n\n\n\ninit-&gt;closed\n\n\n\n\n\npartial\n\nFLOW\nValve\npartially\nopen\n\n\n\nclosed-&gt;partial\n\n\nopen valve one turn\n\n\n\npartial-&gt;closed\n\n\nclose valve one turn\n\n\n\nfull\n\nFLOW\nValve\nfully open\n\n\n\npartial-&gt;full\n\n\nopen valve one turn\n\n\n\nfull-&gt;closed\n\n\nemergency shut off\n\n\n\nfull-&gt;partial\n\n\nclose valve one turn\n\n\n\n\n\n\nFigure 9: Example of a digraph representation of the Moore machine for a valve control\n\n\n\n\n\n\n\n\nMealy machine\nMealy machine is another extension of an automaton. Here the outputs are associated with the transitions rather than the states.\nSince the events already associated with the states can be viewed as the inputs, we now have input/output transition labels. The transition label e_\\mathrm{i}/e_\\mathrm{o} on the transion from x_1 to x_2 reads as “the input event e_\\mathrm{i} at state x_1 activates the transition to x_2, which outputs the event e_\\mathrm{o}” and can be written as x_1\\xrightarrow{e_\\mathrm{i}/e_\\mathrm{o}} x_2.\nIt can be viewed as if the output function also considers the input and not only the state y = e_\\mathrm{o} = g(x,e_\\mathrm{i}).\nIn contrast with the Moore machine, here the output is produced (emitted) during the transition (before the new state is entered).\n\nExample 9 (Mealy machine) Coffee machine: coffee for 30 CZK, machine accepting 10 and 20 CZK coins, no change.\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\n0\n\nNo coin\n\n\n\ninit-&gt;0\n\n\n\n\n\n10\n\n10 CZK\n\n\n\n0-&gt;10\n\n\ninsert 10 CZK / no coffee\n\n\n\n20\n\n20 CZK\n\n\n\n0-&gt;20\n\n\ninsert 20 CZK / no coffee\n\n\n\n10-&gt;0\n\n\ninsert 20 CZK / coffee\n\n\n\n10-&gt;20\n\n\ninsert 10 CZK / no coffee\n\n\n\n20-&gt;0\n\n\ninsert 10 CZK / coffee\n\n\n\n20-&gt;10\n\n\ninsert 20 CZK / coffee\n\n\n\n\n\n\nFigure 10: Example of a digraph representation of the Mealy machine for a coffee machine\n\n\n\n\n\n\n\nExample 10 (Reformulate the previous example as a Moore machine) Two more states wrt Mealy\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\n0\n\nNO COFFEE\nNo\ncoin\n\n\n\ninit-&gt;0\n\n\n\n\n\n10\n\nNO COFFEE\n10\nCZK\n\n\n\n0-&gt;10\n\n\ninsert 10 CZK\n\n\n\n20\n\nNO COFFEE\n20\nCZK\n\n\n\n0-&gt;20\n\n\ninsert 20 CZK\n\n\n\n10-&gt;20\n\n\ninsert 10 CZK\n\n\n\n30\n\nCOFFEE\n10+20\nCZK\n\n\n\n10-&gt;30\n\n\ninsert 20 CZK\n\n\n\n20-&gt;30\n\n\ninsert 10 CZK\n\n\n\n40\n\nCOFFEE\n20+20\nCZK\n\n\n\n20-&gt;40\n\n\ninsert 20 CZK\n\n\n\n30-&gt;0\n\n\n\n\n\n30-&gt;10\n\n\ninsert 10 CZK\n\n\n\n30-&gt;20\n\n\ninsert 20 CZK\n\n\n\n40-&gt;10\n\n\n\n\n\n40-&gt;20\n\n\ninsert 10 CZK\n\n\n\n40-&gt;30\n\n\ninsert 20 CZK\n\n\n\n\n\n\nFigure 11: Example of a digraph representation of the Moore machine for a coffee machine\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are transitions from 30 and 40 back to 0 that are not labelled by any event. This does not seem to follow the general rule that transitions are always triggered by events. Not what? It can be resolved upon introducing time as the timeout transitions.\n\n\n\nExample 11 (Dijkstra’s token passing) The motivation for this example is to show that it is perhaps not always productive to insist on visual description of the automaton using a graph. The four components of our formal definition of an automaton are just enough, and they translate directly to a code.\nThe example comes from the field of distributed computing systems. It considers several computers that are connected in ring topology, and the communication is just one-directional as Fig. 12 shows. The task is to use the communication to determine in – a distributed way – which of the computers carries a (single) token at a given time. And to realize passing of the token to a neighbour. We assume a synchronous case, in which all the computers are sending simultaneously, say, with some fixed sending period.\n\n\n\n\n\n\n\n\nG\n\n\n0\n\n0\n\n\n\n1\n\n1\n\n\n\n0-&gt;1\n\n\n\n\n\n2\n\n2\n\n\n\n1-&gt;2\n\n\n\n\n\n3\n\n3\n\n\n\n2-&gt;3\n\n\n\n\n\n3-&gt;0\n\n\n\n\n\n\n\n\nFigure 12: Example of a ring topology for Dijkstra’s token passing in a distributed system\n\n\n\n\n\nOne popular method for this is called Dijkstra’s token passing. Each computer keeps a single integer value as its state variable. And it forwards this integer value to the neighbour (in the clockwise direction in our setting). Upon receiving the value from the other neighbour (in the counter-clockwise direction), it updates its own value according to the rule displayed in the code below. At every clock tick, the state vector (composed of the individual state variables) is updated according to the function update!() in the code. Based on the value of the state vector, an output is computed, which decodes the informovation about the location of the token from the state vector. Again, the details are in the output() function.\n\n\nShow the code\nstruct DijkstraTokenRing\n    number_of_nodes::Int64\n    max_value_of_state_variable::Int64\n    state_vector::Vector{Int64}\nend\n\nfunction update!(dtr::DijkstraTokenRing)                        \n    n = dtr.number_of_nodes\n    k = dtr.max_value_of_state_variable\n    x = dtr.state_vector\n    xnext = copy(x)\n    for i in eachindex(x)   # Mind the +1 shift. x[2] corresponds to x₁ in the literature.\n        if i == 1                                              \n            xnext[i] = (x[i] == x[n]) ? mod(x[i] + 1,k) : x[i]  # Increment if the left neighbour is identical.\n        else                                                    \n            xnext[i] = (x[i] != x[i-1]) ? x[i-1] : x[i]         # Update by the differing left neighbour.\n        end\n    end\n    dtr.state_vector .= xnext                                              \nend\n\nfunction output(dtr::DijkstraTokenRing)     # Token = 1, no token = 0 at the given position. \n    x = dtr.state_vector\n    y = similar(x)\n    y[1] = iszero(x[1]-x[end])\n    y[2:end] .= .!iszero.(diff(x))\n    return y\nend\n\n\noutput (generic function with 1 method)\n\n\nWe now rund the code for a given number of computers and some initial state vector that does not necessarily comply with the requirement that there is only one token in the ring.\n\n\nShow the code\nn = 4                           # Concrete number of nodes.\nk = n                           # Concrete max value of a state variable (&gt;= n).\n@show x_initial = rand(0:k,n)   # Initial state vector, not necessarily acceptable (&gt;1 token in the ring).\ndtr = DijkstraTokenRing(n,k,x_initial)\n@show output(dtr)               # Show where the token is (are).\n\n@show update!(dtr), output(dtr) # Perform the update, show the state vector and show where the token is.\n@show update!(dtr), output(dtr) # Repeat a few times to see the stabilization.    \n@show update!(dtr), output(dtr)\n@show update!(dtr), output(dtr)\n@show update!(dtr), output(dtr)\n\n\nx_initial = rand(0:k, n) = [0, 2, 4, 0]\noutput(dtr) = [1, 1, 1, 1]\n(update!(dtr), output(dtr)) = ([1, 0, 2, 4], [0, 1, 1, 1])\n(update!(dtr), output(dtr)) = ([1, 1, 0, 2], [0, 0, 1, 1])\n(update!(dtr), output(dtr)) = ([1, 1, 1, 0], [0, 0, 0, 1])\n(update!(dtr), output(dtr)) = ([1, 1, 1, 1], [1, 0, 0, 0])\n(update!(dtr), output(dtr)) = ([2, 1, 1, 1], [0, 1, 0, 0])\n\n\n([2, 1, 1, 1], [0, 1, 0, 0])\n\n\nWe can see that although initially the there can be more tokens, after a few iterations the algorithm achieves the goal of having just one token in the ring.\n\n\n\nExtended-state automaton\nYet another extension of an automaton is the extended-state automaton. And indeed, the hyphen is there on purpose as we extend the state space.\nIn particular, we augment the state variable(s) that define the states/modes/locations (the nodes in the graph) by additional (typed) state variables: Int, Enum, Bool, …\nTransitions from one mode to another are then guarded by conditions on theses new extra state variables.\nBesides being guarded by a guard condition, a given transition can also be labelled by a reset function that resets the extended-state variables.\n\nExample 12 (Counting up to 10) In this example, there are two modes (on and off), which can be captured by a single binary state variable, say x. But then there is an additional integer variable k, and the two variables together characterize the extended state.\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\nOFF\n\nOFF\n\n\n\ninit-&gt;OFF\n\n\nint k=0\n\n\n\nON\n\nON\n\n\n\nOFF-&gt;ON\n\n\npress\n\n\n\nON-&gt;OFF\n\n\n(press ⋁ k ≥ 10); k=0\n\n\n\nON-&gt;ON\n\n\n(press ∧ k &lt; 10); k=k+1\n\n\n\n\n\n\nFigure 13: Example of a digraph representation of the extended-state automaton for counting up to ten",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#composing-automata",
    "href": "des_automata.html#composing-automata",
    "title": "State automata",
    "section": "Composing automata",
    "text": "Composing automata\nAny practically useful modelling framework should support decomposition of a large system into smaller subsystems. These should then be able to communicate/synchronize with each other. In automata such synchronization can be realized by sending (or generating) and receiving (or accepting) events. A common choice of symbols for the two is !,?, as illustrated in the following example. But these symbols are just one possible convention, and any other symbols can be used.\n\nExample 13 (Composing automata)  \n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\n1\n\n1\n\n\n\ninit-&gt;1\n\n\n\n\n\n2\n\n2\n\n\n\n1-&gt;2\n\n\npress?\n\n\n\n3\n\n3\n\n\n\n3-&gt;3\n\n\npress!\n\n\n\n\n\n\nFigure 14: Example illustrating how two automata can be synchronized by sending and receiving events",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#languages-and-automata",
    "href": "des_automata.html#languages-and-automata",
    "title": "State automata",
    "section": "Languages and automata",
    "text": "Languages and automata\nWhen studying automata, we often encounter the concept of a language. Indeed, the concept of an automaton is heavily used in the formal laguage theory. Although in our course we are not going to refer to these results, some resources we recommend for our courses do, and so it is useful to understand how automata and languages are related.\nFirst, we extend the definition of a transition function in that it accepts the current state and not just a single event but a sequence of events, that is\n\nf: \\mathcal X \\times \\mathcal E^\\ast \\rightarrow \\mathcal X,\n where \\mathcal E^\\ast stands for the set of all possible sequences of events.\nLanguage generated by the automaton is \n\\mathcal L(\\mathcal G) = \\{s\\in\\mathcal E^\\ast \\mid f(x_0,s) \\;\\text{is defined}\\}\n\nLanguage marked by the automaton (the automaton is accepting or recognizing that language) \n\\mathcal L_\\mathrm{m}(\\mathcal G) = \\{s\\in\\mathcal L(\\mathcal G) \\mid f(x_0,s) \\in \\mathcal{X}_\\mathrm{m}\\}\n\n\nExample 14 (Language accepted by automaton) \n\\mathcal{E} = \\{a,b\\}, \\mathcal{L} = \\{a,aa,ba,aaa,aba,baa,bba,\\ldots\\}\n\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\n0\n\n0\n\n\n\ninit-&gt;0\n\n\n\n\n\n1\n\n\n1\n\n\n\n1-&gt;1\n\n\na\n\n\n\n1-&gt;0\n\n\nb\n\n\n\n0-&gt;1\n\n\na\n\n\n\n0-&gt;0\n\n\nb\n\n\n\n\n\n\nFigure 15: Example of an automaton generating the language \\mathcal{L} = \\{a,aa,ba,aaa,aba,baa,bba,\\ldots\\}\n\n\n\n\n\nWhat if we remove the self loop at state 0? The automaton then accepts languages starting with a and with b being the last event or immediately followed by a.\n\n\nWhat is the language view of automata good for?\n\nDefinitions, analysis, synthesis.\nWe then need language concepts such as\n\nconcatenation of strings: \\quad c = ab\nempty string \\varepsilon: \\quad\\varepsilon a = a \\varepsilon = a\nprefix, suffix\nprefix closure \\bar{\\mathcal{L}} (of the language \\mathcal L)\n…",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#blocking",
    "href": "des_automata.html#blocking",
    "title": "State automata",
    "section": "Blocking",
    "text": "Blocking\nAn important concept in automata is blocking. A state is blocking if there is no transition out of it. An example follows.\n\nExample 15 (Blocking states) In the automaton in Fig. 16, state 2 is blocking. It is a deadlock state. States 3 and 4 are livelock states.\n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\n0\n\n0\n\n\n\ninit-&gt;0\n\n\n\n\n\n2\n\n\n2\n\n\n\n2-&gt;0\n\n\ng\n\n\n\n1\n\n1\n\n\n\n0-&gt;1\n\n\na\n\n\n\n1-&gt;2\n\n\nb\n\n\n\n5\n\n5\n\n\n\n1-&gt;5\n\n\ng\n\n\n\n3\n\n3\n\n\n\n1-&gt;3\n\n\na\n\n\n\n4\n\n4\n\n\n\n3-&gt;4\n\n\nb\n\n\n\n4-&gt;3\n\n\na\n\n\n\n4-&gt;4\n\n\ng\n\n\n\n\n\n\nFigure 16: Example of an automaton with blocking states\n\n\n\n\n\nLanguage characterization: \\bar{\\mathcal{L}}_\\mathrm{m}(\\mathcal G) \\sub \\mathcal L(\\mathcal G).",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#queueing-systems",
    "href": "des_automata.html#queueing-systems",
    "title": "State automata",
    "section": "Queueing systems",
    "text": "Queueing systems\nQueueing systems are a particular and very useful class of discrete-event systems. They consist of these three components:\n\nentities (also customers, jobs, tasks, requests, etc.)\nresources (also servers, processors, etc.): customers are waiting for them\nqueues (also buffers): where waiting is done\n\nA common graphical representation that contains all these three compoments is in Fig. 17.\n\n\n\n\n\n\nFigure 17: Queueing system\n\n\n\n\nExamples of queueing systems\n\nentities: people waiting for service in a bank or at a bust stop\nresources: people (again) in a bank at the counter\nqueues: bank lobbies, bus stops, warehouses, …\n\n\n\n\n\n\n\nNote\n\n\n\nWhat are other examples?\n\nentities: packets, …\nresources: processor, computer periphery, router, …\nqueues: …\n\n\n\n\n\nWhy shall we study queueing systems?\n\nResources are not unlimited\nTradeoff needed between customer satisfaction and fair resources allocation\n\n\n\nNetworks of queueing systems\nQueueing systems can be interconnected into networks.\n\n\n\n\n\n\nFigure 18: Example of a network of queueing systems\n\n\n\n\n\nQueueing systems as automata\nThe reason why we mentioned queueing systems in this part of our course is that they can be modelled as automata. And we already know that in order to define and automaton, we must characterize the key components defining the automaton – three in this case:\n\nevents: \\mathcal E = \\{\\text{arrival},\\text{departure}\\};\nstates: number of customers in the queue \n\\mathcal X = \\{0,1,2,3,\\ldots\\}, \\quad \\mathcal X_0 = \\{0\\},\n\n\n\n\n\n\n\n\nNote\n\n\n\nObviously this is not a finite state automation – unless the queue is bounded – and whether the queue’s length is bounded is a modelling assumption.\n\n\n\nstate transition: \nf(x,e) =\n\\begin{cases}\nx+1, & \\text{if}\\; x\\leq 0 \\land e = \\mathrm{arrival}\\\\\nx-1, & \\text{if}\\; x &gt; 0 \\land e = \\mathrm{departure}.\n\\end{cases}\n\n\n\n\nQueueing system as an automaton\n\n\n\n\n\n\nFigure 19: Queueing system as an automaton\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote how the states correspond to the value of the state variable.\n\n\n\nExample 16 (Example of a queueing system: jobs processing by a CPU) …\n\n\n\nStochastic queueing systems\nAn important extension of the basic concept of a queueing system is the introduction of randomness. In particular, the arrivals can be modelled using random processes. Similarly, the departures given by the delays (the processing time) of the server can be modelled as random.\nObviously, the time needs to be included in the automaton, and so far we do not have it there. It is then high time to introduce it.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "des_automata.html#timed-automaton",
    "href": "des_automata.html#timed-automaton",
    "title": "State automata",
    "section": "Timed automaton",
    "text": "Timed automaton\nSo far, even if the automaton corresponded to a physical system (and did not just represent a generator of a language), the time was not included. The transitions were triggered by the events, but we did not specify the time at which the event occurred.\nThere are, however, many situations when it is useful or even crucial to incorporate time. We can then answer questions such as\n\nHow many events of a certain type in a given interval?\nIs the time interval between two events above a given threshold?\nHow long does the system spend in a given state?\n…\n\nThere are several ways how to incorporate time into the automaton. We will follow the concept of a timed automaton with guards (introduced by Alur and Dill). Within their framework we have\n\none or several resettable clocks: c_i,\\, i=1,\\ldots, k, driven by the ODE \n  \\frac{\\mathrm{d} c_i(t)}{\\mathrm d t} = 1, \\quad c_i(0) = 0;\n  \neach transition labelled by the tripple {guard; event; reset}.\n\n\n\n\n\n\n\nNote\n\n\n\nBoth satisfaction of the guard and arrival of the event constitute enabling conditions for the transition. They could be wrapped into a single compound condition.\n\n\n\nExample 17 (Timed automaton with guards)  \n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\n0\n\n0\n\n\n\ninit-&gt;0\n\n\n\n\n\n1\n\n1\n\n\n\n0-&gt;1\n\n\n-; msg; c₁\n\n\n\n1-&gt;1\n\n\nc₁≥1; msg; c₁\n\n\n\n2\n\n2\n\n\n\n1-&gt;2\n\n\n0&lt;c₁&lt;1; msg; c₁\n\n\n\n3\n\n3\n\n\n\n2-&gt;3\n\n\nc₁&lt;1; alarm; -\n\n\n\n\n\n\nFigure 20: Example of a timed automaton with guards\n\n\n\n\n\n\n\nExample 18 (Timed automaton with guards and invariant)  \n\n\n\n\n\n\n\n\nG\n\n\ninit\ninit\n\n\n\n0\n\n0\n\n\n\ninit-&gt;0\n\n\n\n\n\n2\n\n2\nc₁&lt;1\n\n\n\n3\n\n3\n\n\n\n2-&gt;3\n\n\n-; alarm; -\n\n\n\n1\n\n1\n\n\n\n0-&gt;1\n\n\n-; msg; c₁\n\n\n\n1-&gt;2\n\n\n0&lt;c₁&lt;1; msg; c₁\n\n\n\n1-&gt;1\n\n\nc₁≥1; msg; c₁\n\n\n\n\n\n\nFigure 21: Example of a timed automaton with guards and invariant\n\n\n\n\n\n\n\nInvariant vs guard\n\nInvariant (of a location) gives an upper bound on the time the system can stay at the given location. It can leave earlier but not later.\nGuard (of a given transition) gives an enabling condition on leaving the location through the given transition.\n\n\nExample 19 (Several trains approaching a bridge) The example is taken from [1] and is included in the demos coming with the Uppaal tool.",
    "crumbs": [
      "1. Discrete-event systems: Automata",
      "State automata"
    ]
  },
  {
    "objectID": "mld_DHA_parts_as_inequalities.html",
    "href": "mld_DHA_parts_as_inequalities.html",
    "title": "Components of DHA as inequalities",
    "section": "",
    "text": "In this section, we use the general results from the previous section to show how the four components of the discrete hybrid automaton (DHA) can be formulated as linear inequalities and equations.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Components of DHA as inequalities"
    ]
  },
  {
    "objectID": "mld_DHA_parts_as_inequalities.html#finite-state-machine-fsm-using-binary-variables",
    "href": "mld_DHA_parts_as_inequalities.html#finite-state-machine-fsm-using-binary-variables",
    "title": "Components of DHA as inequalities",
    "section": "Finite state machine (FSM) using binary variables",
    "text": "Finite state machine (FSM) using binary variables\nFor characterization of discrete states (both in discrete-event and hybrid systems), we used integer variables. But now, with anticipation of using numerical solvers, we will use binary variables. We encode the discrete state variable x_\\mathrm{d} in binary. As a matter of fact, vector variables are needed here \nx_b \\in \\{0,1\\}^{n_b}.\n\nSimilarly the discrete inputs \nu_b \\in \\{0,1\\}^{m_b}.\n\nThe logic state equation then \nx_b(k+1) = f_b(x_b(k),u_b(k),\\delta_e(k)).\n\n\nExample 1 (Example)  \n\n\n\n\n\n\nFigure 1: Example of a FSM\n\n\n\nThe state update/transition equation is \n\\begin{aligned}\nx_d(k+1) =\n\\begin{cases}\n\\text{Red} & \\text{if}\\; ([x_d = \\text{green}] \\land \\neg [\\delta_3=1]) \\lor ([x_d = \\text{red}] \\land \\neg [\\delta_3=1])\\\\\n\\text{Green} & \\text{if} \\; \\ldots\\\\\n\\text{Blue} & \\text{if} \\; \\ldots\n\\end{cases}\n\\end{aligned}\n\nBinary encoding of the discrete states \n\\text{Red}: x_b = \\begin{bmatrix}0\\\\0 \\end{bmatrix}, \\; \\text{Green}: x_b = \\begin{bmatrix}0\\\\1 \\end{bmatrix}, \\; \\text{Blue}: x_b = \\begin{bmatrix}1\\\\0 \\end{bmatrix}\n\nReformulating the state update equations for binary variables \n\\begin{aligned}\nx_{b1} &= (\\neg [x_{b1} = 1] \\land \\neg [x_{b2} = 1]  \\land [\\delta_1=1] \\land \\neg[u_{b2}=1]) \\\\\n&\\quad \\lor (\\neg [x_{b1} = 1] \\land [x_{b2} = 1]  \\land [\\delta_3=1] \\land [u_{b1}=1])\\\\\n&\\quad \\lor ([x_{b1} = 1]\\land [x_{b2} = 1] \\land \\neg [\\delta_2=1])\\\\\nx_{b2} &= \\ldots\n\\end{aligned}\n\nFinally, simplify, convert to CNF.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Components of DHA as inequalities"
    ]
  },
  {
    "objectID": "mld_DHA_parts_as_inequalities.html#mixing-logical-and-continuous-through-indicator-variables",
    "href": "mld_DHA_parts_as_inequalities.html#mixing-logical-and-continuous-through-indicator-variables",
    "title": "Components of DHA as inequalities",
    "section": "Mixing logical and continuous through indicator variables",
    "text": "Mixing logical and continuous through indicator variables\nNow that we have learnt to encode purely logical expressions into inequalities, we consider the cases where logical and continuous variables are mixed. We aim at the same kind of encoding as before, that is, we want to formulate inequalities.\n\nLogical implies continuous\nWe start by considering the implication X \\rightarrow [f(x)\\leq 0], where X is a Boolean variable and f(x) is a real-valued function of a real variable x. Upon represented the Boolean variable X with the binary variable \\delta (called an indicator variable) we can write the implication as [\\delta = 1] \\rightarrow [f(x)\\leq 0].\nIn order to construct an equivalent inequality, we introduce a real parameter M large enough such that when \\delta=0 in \nf(x) \\leq (1-\\delta) M,\n there is no practical restriction on f. If \\delta=1, the original inequality is trivially enforced.\n\n\n\n\n\n\nBig-M technique\n\n\n\nThis is a popular trick and is known as the Big-M technique. It is not a trouble-free trick, though. It is important to avoid setting M unnecessarily too high. See the section Dealing with Big-M Constraints in Gurobi Reference Manual for some discussion of numerical issues.\n\n\n\n\nContinuous implies logical\nThe other implication [f(x)\\leq 0] \\rightarrow X, with the Boolean variable X represented with a binary \\delta as [f(x)\\leq 0] \\rightarrow [\\delta = 1], can be written equivalently as \\neg [\\delta = 1] \\rightarrow \\neg [f(x)\\leq 0], which can be further simplified to [\\delta = 0] \\rightarrow [f(x) &gt; 0].\nWe now introduce m small enough such that that f(x) is practically unrestricted when \\delta=1 in \nf(x) &gt; m\\delta,\n while f(x)&gt;0 is trivially enforced when \\delta=0.\nFor numerical reasons, we modify the strict equality to nonstrict inequality \nf(x) \\geq \\epsilon + (m-\\epsilon)\\delta,\n where \\epsilon\\approx 0 (for example, machine epsilon).\n\n\nEquivalence between logical and continuous\nNow we combine the previous two implications so that we can write the equivalence X \\leftrightarrow [f(x)\\leq 0],\nrepresented through the indicator variable \\delta as \\boxed{\n[\\delta = 1] \\leftrightarrow [f(x)\\leq 0],\n}\n\nas the two inequalities \\boxed{\n\\begin{aligned}\nf(x) &\\leq (1-\\delta) M,\\\\\nf(x) &\\geq \\epsilon + (m-\\epsilon)\\delta.\n\\end{aligned}}\n\\tag{1}\n\n\nIF-THEN-ELSE rule as an inequality\nWe now consider the following IF-THEN-ELSE rule:\n\n\\mathrm{if} \\; X, \\; \\mathrm{then} \\; z = f(x,u), \\; \\text{else} \\; z = 0.\n\nIt can be equivalently expressed as the product \nz = \\delta\\,f(x,u),\n where \\delta is a binary indicator. This, in turn, can be written (finally using ?@eq-product-assignment) as \n\\begin{aligned}\nz &\\leq M\\delta,\\\\\n- z &\\leq -m\\delta,\\\\\nz &\\leq f(x,u) - m(1-\\delta),\\\\\n-z &\\leq -f(x,u) + M(1-\\delta).\n\\end{aligned}\n\n\n\n\n\n\n\nScalar functions only\n\n\n\nBeware that the above results are valid only for scalar functions f(), even if their arguments are possibly vectors.\n\n\nParticularly useful from a computational viewpoint will be an affine function f(x,y) = ax + bu + e. We specialize the above inequalities to this case for later convenience. \\boxed{\n\\begin{aligned}\nz &\\leq M\\delta,\\\\\n- z &\\leq -m\\delta,\\\\\nz &\\leq ax + bu + e - m(1-\\delta),\\\\\n-z &\\leq -(ax + bu + e) + M(1-\\delta).\n\\end{aligned}}\n\\tag{2}\n\n\nAnother IF-THEN-ELSE rule\nAnother IF-THEN-ELSE rule (and here we already specialized it to affine functions) can also be useful:\n\n\\mathrm{if} \\; X, \\; \\mathrm{then} \\; z = a_1x + b_1u + e_1, \\; \\mathrm{else} \\; z = a_2x + b_2u + e_2.\n\nUsing a binary indicator \\delta, it can be expressed as \nz = {\\color{blue}\\delta}\\,(a_1 x + b_1 u + e_1) + {\\color{blue}(1-\\delta)}(a_2 x + b_2 u + e_2),\n which can be rewritten as \n\\boxed{\n\\begin{aligned}\n(m_2-M_1)\\delta  + z &\\leq a_2 x + b_2 u + e_2,\\\\\n(m_1-M_2)\\delta  - z &\\leq -a_2 x - b_2 u - e_2,\\\\\n(m_1-M_2)(1-\\delta)  + z &\\leq a_1 x + b_1 u + e_1,\\\\\n(m_2-M_1)(1-\\delta)  - z &\\leq -a_1 x - b_1 u - e_1.\n\\end{aligned}}\n\\tag{3}\n\n\nGeneration of events by mixing logical and continuous variables in inequalities\nApplication of Eq. 1 to the ith event generator function h_i(x,u) leads to the following inequalities \\boxed{\n\\begin{aligned}\nh_i(x_c(k), u_c(k)) &\\leq M_i (1-\\delta_{e,i}),\\\\\nh_i(x_c(k), u_c(k)) &\\geq \\epsilon + (m_i-\\epsilon) \\delta_{e,i}.\n\\end{aligned}}\n\\tag{4}\n\n\nSwitched affine system\nWe are now ready to get rid of the IF-THEN(-ELSE) conditions in the definition of the switched affine system by reformulating it as inequalities. Namely, we compose the state variable in the next step as a sum of the auxiliary variables z_i: \nx_c(k+1) = \\sum_{i=1}^s z_i(k),  \n where \nz_1(k) =\n\\begin{cases}\na_1 x_c(k) + b_1 u_c(k) + f_1 & \\text{if}\\;i(k)=1,\\\\\n0 & \\text{otherwise},\n\\end{cases}\n \\quad \\vdots \nz_s(k) =\n\\begin{cases}\na_s x_c(k) + b_s u_c(k) + f_s & \\text{if}\\;i(k)=s,\\\\\n0 & \\text{otherwise},\n\\end{cases}\n and we rewrite it for each i\\in \\{1, 2, \\ldots, s\\} as \\boxed{\n\\begin{aligned}\nz_i &\\leq M_i\\delta_i,\\\\\n- z_i &\\leq -m_i\\delta_i,\\\\\nz_i &\\leq a_i x + b_i u + f_i - m_i(1-\\delta_i),\\\\\n-z_i &\\leq -(a_i x + b_i u + f_i) + M_i(1-\\delta_i).\n\\end{aligned}}\n\\tag{5}\n\n\n\n\n\n\nAll these results were derived just for scalar z and f()\n\n\n\nWith the formalism presented here, vector variables \\bm z and correspondingly vector right-hand-side functions \\mathbf f() must be handled but considering their individual scalar components z_1, \\ldots, z_n and f_1(), \\ldots, f_n(). Notational care must be exercised, note that the lower index in this remark has different meaning than that in Eq. 5.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Components of DHA as inequalities"
    ]
  },
  {
    "objectID": "mld_DHA.html",
    "href": "mld_DHA.html",
    "title": "Discrete hybrid automata",
    "section": "",
    "text": "We are going to introduce yet another framework for modeling hybrid systems – mixed logical dynamical (MLD) description. A question must inevitably pop up: “why yet another framework?”\nThe answer is, that we would like to have a model of a hybrid system that is suitable for model predictive control (MPC). Recall that the role of the model in MPC is that the model is used to define some constraints (equations and inequalities) in the numerical optimization problem. The frameworks that we considered so far did not offer it.\nIn particular, with the state variable and control input vectors composed of continuous and discrete variables \n\\bm x = \\begin{bmatrix}\\bm x_\\mathrm{c}\\\\\\bm x_\\mathrm{d}\\end{bmatrix}, \\quad \\bm u = \\begin{bmatrix}\\bm u_\\mathrm{c}\\\\\\bm u_\\mathrm{d}\\end{bmatrix},\n where \\bm x_\\mathrm{c}\\in\\mathbb R^{n_\\mathrm{c}},\\;\\bm x_\\mathrm{d}\\in\\mathbb N^{n_\\mathrm{d}},\\; \\bm u_\\mathrm{c}\\in\\mathbb R^{m_\\mathrm{c}} and \\bm u_\\mathrm{d}\\in\\mathbb N^{m_\\mathrm{d}}, we would like to formulate the model in the form of state equations, say \n\\begin{aligned}\n\\begin{bmatrix}\\bm x_\\mathrm{c}(k+1) \\\\ \\bm x_\\mathrm{d}(k+1)\\end{bmatrix}\n&=\n\\begin{bmatrix} \\mathbf f_\\mathrm{c}(\\bm x(k), \\bm u(k)) \\\\ \\mathbf f_\\mathrm{d}(\\bm x(k), \\bm u(k)) \\end{bmatrix}.\n\\end{aligned}\n\nIs it possible?\nUnfortunately no. At least not exactly in this form. But something close to it is achievable instead.\nBut first we need to set the terminology and notation used to define a discrete(-time) hybrid automaton.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Discrete hybrid automata"
    ]
  },
  {
    "objectID": "mld_DHA.html#why-yet-another-framework-for-hybrid-systems",
    "href": "mld_DHA.html#why-yet-another-framework-for-hybrid-systems",
    "title": "Discrete hybrid automata",
    "section": "",
    "text": "We are going to introduce yet another framework for modeling hybrid systems – mixed logical dynamical (MLD) description. A question must inevitably pop up: “why yet another framework?”\nThe answer is, that we would like to have a model of a hybrid system that is suitable for model predictive control (MPC). Recall that the role of the model in MPC is that the model is used to define some constraints (equations and inequalities) in the numerical optimization problem. The frameworks that we considered so far did not offer it.\nIn particular, with the state variable and control input vectors composed of continuous and discrete variables \n\\bm x = \\begin{bmatrix}\\bm x_\\mathrm{c}\\\\\\bm x_\\mathrm{d}\\end{bmatrix}, \\quad \\bm u = \\begin{bmatrix}\\bm u_\\mathrm{c}\\\\\\bm u_\\mathrm{d}\\end{bmatrix},\n where \\bm x_\\mathrm{c}\\in\\mathbb R^{n_\\mathrm{c}},\\;\\bm x_\\mathrm{d}\\in\\mathbb N^{n_\\mathrm{d}},\\; \\bm u_\\mathrm{c}\\in\\mathbb R^{m_\\mathrm{c}} and \\bm u_\\mathrm{d}\\in\\mathbb N^{m_\\mathrm{d}}, we would like to formulate the model in the form of state equations, say \n\\begin{aligned}\n\\begin{bmatrix}\\bm x_\\mathrm{c}(k+1) \\\\ \\bm x_\\mathrm{d}(k+1)\\end{bmatrix}\n&=\n\\begin{bmatrix} \\mathbf f_\\mathrm{c}(\\bm x(k), \\bm u(k)) \\\\ \\mathbf f_\\mathrm{d}(\\bm x(k), \\bm u(k)) \\end{bmatrix}.\n\\end{aligned}\n\nIs it possible?\nUnfortunately no. At least not exactly in this form. But something close to it is achievable instead.\nBut first we need to set the terminology and notation used to define a discrete(-time) hybrid automaton.",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Discrete hybrid automata"
    ]
  },
  {
    "objectID": "mld_DHA.html#discrete-hybrid-automaton",
    "href": "mld_DHA.html#discrete-hybrid-automaton",
    "title": "Discrete hybrid automata",
    "section": "Discrete hybrid automaton",
    "text": "Discrete hybrid automaton\nSince the new modelling framework is expected to be useful for prediction of a system response within model predictive control, it must model a hybrid system in discrete time. This is a major difference from what we did in our course so far.\nIn particular, we are going to model a hybrid system as a discrete(-time) hybrid automaton (DHA), which means that\n\nthe continuous-value dynamics (often corresponding to the physical part of the system) evolves in discrete time,\nthe events and their processing by the logical part of the system are synchronized to the same periodic clock.\n\nWe are already well familiar with the concept of a hybrid automaton, and the restriction to discrete time does not seem to warrant reopening the definition (modes/locations, guards, invariants/domains, reset maps, …). However, it turns out that reformulating/restructuring the hybrid automaton will be useful for our ultimate goal of developing an MPC-friendly modelling framework. In particular, we consider four components of a DHA:\n\nswitched affine system (SAS),\nmode selector (MS),\nevent generator (EG),\nfinite state machine (FSM).\n\nTheir interconnection is shown in the following figure.\n[TBD] #TODO: Add a figure\nLet’s discuss the individual components (and while doing that, you can think about the equivalent concept in the classical definition of a hybrid automaton such as mode, invariant, guard, …).\n\nSwitched affine systems (SAS)\nThis is a model of the continuous-value dynamics parameterized by the index i that evolves in (discrete) time \n\\begin{aligned}\nx_\\mathrm{c}(k+1) &= A_{i(k)} x_\\mathrm{c}(k) + B_{i(k)} u_\\mathrm{c}(k) + f_{i(k)},\\\\\ny_\\mathrm{c}(k) &= C_{i(k)} x_\\mathrm{c}(k) + D_{i(k)} u_\\mathrm{c}(k) + g_{i(k)}.\n\\end{aligned}\n\nIn principle there is no need to restrict the right hand sides to affine functions as we did, but the fact is that the methods and tools are currently only available for this restricted class of systems.\n\n\nEvent generator (EG)\nWe consider partitioning of the state space or possibly state-control space into polyhedral regions. The system is then in the ith region of the state-input space, if the continuous-value state x_\\mathrm{c}(k) and the continuous-value control input u_\\mathrm{c} satisfy \nH_i x_\\mathrm{c}(k) + J_i u_\\mathrm{c}(k) + K_i \\leq 0.\n\nThe event indicated by the (vector) binary variable \n\\delta_e(k) = h(x_\\mathrm{c}(k), u_\\mathrm{c}(k)) \\in \\{0,1\\}^m,\n where \nh_i(x_\\mathrm{c}(k), u_\\mathrm{c}(k)) = \\begin{cases}1 & H_i x_\\mathrm{c}(k) + J_i u_\\mathrm{c}(k) + K_i \\leq 0,\\\\ 0 & \\text{otherwise}. \\end{cases}\n\n\n\nFinite state machine (FSM)\n\nx_\\mathrm{d}(k+1) = f_\\mathrm{d}(x_\\mathrm{d}(k),u_\\mathrm{d}(k),\\delta_e(k)).\n\n\n\nMode selector (MS)\n\ni(k) \\in \\{1, 2, \\ldots, s\\}\n\n\ni(k) = \\mu(x_\\mathrm{d}(k), u_\\mathrm{d}(k), \\delta_e(k)).",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Discrete hybrid automata"
    ]
  },
  {
    "objectID": "mld_DHA.html#trajectory-of-a-dha",
    "href": "mld_DHA.html#trajectory-of-a-dha",
    "title": "Discrete hybrid automata",
    "section": "Trajectory of a DHA",
    "text": "Trajectory of a DHA\n\n\\begin{aligned}\n\\delta_e(k) &= h(x_\\mathrm{c}(k), u_\\mathrm{c}(k))\\\\\ni(k) &= \\mu(x_\\mathrm{d}(k), u_\\mathrm{d}(k), \\delta_e(k))\\\\\ny_\\mathrm{c}(k) &= C_{i(k)} x_\\mathrm{c}(k) + D_{i(k)} u_\\mathrm{c}(k) + g_{i(k)}\\\\\ny_\\mathrm{d}(k) &= g_\\mathrm{d}(x_\\mathrm{d}(k), u_\\mathrm{d}(k), \\delta_e(k))\\\\\nx_\\mathrm{c}(k+1) &= A_{i(k)} x_\\mathrm{c}(k) + B_{i(k)} u_\\mathrm{c}(k) + f_{i(k)}\\\\\nx_\\mathrm{d}(k+1) &= f_\\mathrm{d}(x_\\mathrm{d}(k),u_\\mathrm{d}(k),\\delta_e(k))\n\\end{aligned}\n\nObviously, in order to compute the trajectory, besides the standard arithmetics, some IF-THEN conditions are also present in the model. They prevent us from using this model as constraints within a mathematical program (numerical optimization problem). Can we get rid of them?",
    "crumbs": [
      "10. Mixed logical dynamical (MLD) systems",
      "Discrete hybrid automata"
    ]
  },
  {
    "objectID": "mpc_mld_references.html",
    "href": "mpc_mld_references.html",
    "title": "Literature",
    "section": "",
    "text": "The main resource for us is the Chapter 17 of the freely available book [1] that we already referred to in the previous chapter.\nThose who have not been exposed to fundamentals of MPC can check the Chapter 12 in the same book. Alternatively, our own introduction to the topic in the third chapter/week of the Optimal and robust control course can be found useful.\n\n\n\n\n Back to topReferences\n\n[1] F. Borrelli, A. Bemporad, and M. Morari, Predictive Control for Linear and Hybrid Systems. Cambridge, New York: Cambridge University Press, 2017. Available: http://cse.lab.imtlucca.it/~bemporad/publications/papers/BBMbook.pdf",
    "crumbs": [
      "11. Model predictive control (MPC) for MLD systems",
      "Literature"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html",
    "href": "stability_via_multiple_lyapunov_function.html",
    "title": "Stability via multiple Lyapunov functions",
    "section": "",
    "text": "We start with an example in which we show it can happen that even if the hybrid (switched) system is stable, there is no common quadratic Lyapunov function.\nGood, we have seen in the example that it is not always possible to find a common quadratic Lyapunov function for a switched system, even it it is stable. We need to expand the set of functions in which we search for a Lyapunov function. We have proposed one way to do it in the previouse chapter wherein we considered higher degree polynomials for which we imposed the nonnegativity constraint through in the form of SOS constraint. Here we are going to consider another approach. We are goint to “stitch” together several Lyapunov-like functions, each of which is a Lyapunov function only on some subset of the state space (that is why we call them just Lyapunov-like and not Lyapunov). This approach is sometimes called the Multiple Lyapunov Function (MLF) approach, or Piecewise Lyapunov Function approach.",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html#multiple-lyapunov-function-mlf-approach-to-analysis-of-stability",
    "href": "stability_via_multiple_lyapunov_function.html#multiple-lyapunov-function-mlf-approach-to-analysis-of-stability",
    "title": "Stability via multiple Lyapunov functions",
    "section": "Multiple Lyapunov Function (MLF) approach to analysis of stability",
    "text": "Multiple Lyapunov Function (MLF) approach to analysis of stability\nInstead of just a single common Lyapunov function V(\\bm x), we are now going to consider several Lyapunov-like functions V_i(\\bm x),\\; i=1,\\ldots,r, that qualify as Lyapunov function only on some subsets of the state space \\Omega_i. And we “stitch” them together to form a piecewise Lyapunov function V(\\bm x): \nV(x) =\n\\begin{cases}\nV_1(\\bm x) & \\text{if } \\bm x\\in \\Omega_1, \\\\\n\\vdots\\\\\nV_r(\\bm x) & \\text{if } \\bm x\\in \\Omega_r.\n\\end{cases}",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html#s-procedure",
    "href": "stability_via_multiple_lyapunov_function.html#s-procedure",
    "title": "Stability via multiple Lyapunov functions",
    "section": "S-procedure",
    "text": "S-procedure\nIn order to restrict the requirement of positive definiteness of the Lyapunov function to some region in the state space, and similarly for the regurement of negative definiteness of its time derivative, we need to introduce the the S-procedure. This is a result about solvability of two or more quadratic inequalities, not necessarily convex ones (for convex problems we have nonlinear Farkas’ lemma). Origins of this result can be found in the control theory (analysis of stability of nonlinear systems, hence the S letter) with the first rigorous result provided by Yakubovich in 1970s.\nIt gives conditions under which (satisfaction of) one quadratic inequality follows from (satisfaction of) another one (or more). Namely, it gives a condition under which the following implication holds:\n\\boxed\n{\\text{Quadratic inequality \\#1 satisfied by some}\\; \\bm x \\Rightarrow \\text{Quadratic inequality \\#0 satisfied by the same}\\; \\bm x.}\n\nIn other words, it gives a condition under which the solution set of the inequality #1 denoted as \\mathcal X_1 is included in the solution set \\mathcal X_0 of the inequality #0.\n\nS-procedure with nonstrict inequalities\nConsider the general quadratic functions F_i(\\bm x) = \\bm x^\\top \\mathbf A_i \\bm x + 2\\mathbf b_i^\\top \\bm x + c_i, \\; i=0,\\ldots, p.\nThe question is: under which conditions it holds that F_0(\\bm x) \\geq 0 for all \\bm x satisfying F_i(\\bm x)\\geq 0,\\; i=1,\\ldots,p ?\nIn other words, we are looking for conditions under which the implication \nF_i(\\bm x) \\geq 0,\\; i=1,\\ldots,p \\quad \\Rightarrow \\quad F_0(\\bm x) \\geq 0\n\nholds.\nIn the simplest (yet relevant) case p=1 we search for conditions under which F_0(\\bm x) \\geq 0 for all \\bm x satisfying F_1(\\bm x)\\geq 0, that is, conditions under which the implication \nF_1(\\bm x) \\geq 0 \\quad \\Rightarrow \\quad F_0(\\bm x) \\geq 0\n\nholds.\n\n\nSufficient conditions\nThe existence of \\alpha_i\\geq 0,\\; i=1,\\ldots,p such that \nF_0(\\bm x)-\\sum_{i=1}^p \\alpha_i F_i(\\bm x) \\geq 0\n is sufficient for the original implication to hold. Generally, it is not necessary; the condition is conservative.\nIt can be formulated as an LMI \n\\begin{bmatrix}\n\\mathbf A_0 & \\mathbf b_0 \\\\\n\\mathbf b_0^\\top & c_0\n\\end{bmatrix} -\n\\sum_{i=1}^p\n\\alpha_i\n\\begin{bmatrix}\n\\mathbf A_i & \\mathbf b_i \\\\\n\\mathbf b_i^\\top & c_i\n\\end{bmatrix}\n\\succeq 0\n\nwhere \\alpha_i \\geq 0,\\; i=1,\\ldots,p.\n\n\nSufficient and also necessary\nIt is nontrivial that for p=1 it is also necessary, provided that there is some \\bm x_0 such that F_1(\\bm x_0)&gt;0. Then we have the following equivalence between the two constraints: \n\\begin{aligned}\nF_0(\\bm x) &\\geq 0 \\; \\forall \\bm x \\;\\mathrm{satisfying}\\; F_1(\\bm x)\\geq 0 \\\\\n&\\Longleftrightarrow \\\\\nF_0(\\bm x)-\\alpha F_1(\\bm x) &\\geq 0,\\;\\text{for some}\\; \\alpha\\in\\mathbb{R}, \\; \\alpha\\geq 0,\n\\end{aligned}\n\nwhich again can be formulated as an LMI, namely\n\n\\begin{bmatrix}\n\\mathbf A_0 & \\mathbf b_0 \\\\\n\\mathbf b_0^\\top & c_0\n\\end{bmatrix} - \\alpha\n\\begin{bmatrix}\n\\mathbf A_1 & \\mathbf b_1 \\\\\n\\mathbf b_1^\\top & c_1\n\\end{bmatrix}\n\\succeq 0,\\quad \\alpha\\geq 0.\n\n\n\nMore on S-procedure\nThere are several variants\n\nstrict, nonstrict or mixed inequalities,\njust two or more,\nsome of the constraints can be equations.",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html#piecewise-quadratic-lyapunov-function",
    "href": "stability_via_multiple_lyapunov_function.html#piecewise-quadratic-lyapunov-function",
    "title": "Stability via multiple Lyapunov functions",
    "section": "Piecewise quadratic Lyapunov function",
    "text": "Piecewise quadratic Lyapunov function\nWe now restrict ourselves to quadratic Lyapunov-like functions, that is, quadratic functions V_i(\\bm x) = \\bm x^\\top \\mathbf P_i \\bm x that qualify as Lyapunov functions only on respective subsets \\Omega_i\\sub \\mathbb R^n:\n\nV_i(\\bm x) = \\bm x^\\top \\mathbf P_i \\bm x &gt; 0\\quad \\forall \\;\\bm x\\in \\Omega_i,\n\n\n\\dot V_i(\\bm x) = \\bm x^\\top \\left( \\mathbf A_i^\\top \\mathbf P_i + \\mathbf P_i \\mathbf A_i \\right) \\bm x &lt; 0\\quad \\forall \\;\\bm x\\in \\Omega_i.",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html#using-comparison-functions-and-nonstrict-inequalities",
    "href": "stability_via_multiple_lyapunov_function.html#using-comparison-functions-and-nonstrict-inequalities",
    "title": "Stability via multiple Lyapunov functions",
    "section": "Using comparison functions and nonstrict inequalities",
    "text": "Using comparison functions and nonstrict inequalities\nWe can use our good old comparison functions to formulate the conditions of positive definiteness and negative definiteness. \n\\alpha_1 \\bm x^\\top \\mathbf I \\bm x \\leq \\bm x^\\top \\mathbf P_i \\bm x \\leq \\alpha_2 \\bm x^\\top \\mathbf I \\bm x \\quad \\forall \\;\\bm x\\in \\Omega_i,\n\n\n\\bm x^\\top \\left( \\mathbf A_i^\\top \\mathbf P_i + \\mathbf P_i \\mathbf A_i \\right) \\bm x \\leq  -\\alpha_3 \\bm x^\\top \\mathbf I \\bm x\\quad \\forall \\;\\bm x\\in \\Omega_i.\n\nThe difference now is that these conditions are only reuired to hold on some state regions, some subsets of the state space. It is now time to discuss how to characterize those regions.",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html#characterization-of-subsets-of-state-space-using-lmi",
    "href": "stability_via_multiple_lyapunov_function.html#characterization-of-subsets-of-state-space-using-lmi",
    "title": "Stability via multiple Lyapunov functions",
    "section": "Characterization of subsets of state space using LMI",
    "text": "Characterization of subsets of state space using LMI\nSome subsets \\Omega_i\\sub \\mathbb R^n characterized using linear and quadratic inequalities can be formulated within the LMI framework as \n\\bm x^\\top \\mathbf Q_i \\bm x \\geq 0.\n\nIn particular, centered ellipsoids and cones.\nFor example,\n\n\\begin{aligned}\n\\Omega_i &= \\{\\bm x \\in \\mathbb R^n \\mid (\\mathbf c^\\top \\bm x \\geq 0 \\land \\mathbf d^\\top \\bm x \\geq 0) \\\\\n& \\qquad \\qquad \\qquad \\lor (\\mathbf c^\\top \\bm x \\leq 0 \\land \\mathbf d^\\top \\bm x \\leq 0)\\}.\n\\end{aligned}\n\nThis constraint can be reformulated as \n(\\mathbf c^\\top \\bm x) (\\mathbf d^\\top \\bm x) \\geq 0,\n\nwhich can be reformatted to \n\\bm x^\\top \\mathbf c \\mathbf d^\\top \\bm x \\geq 0,\n\nwhich can further be symmetrized to \n\\bm x^\\top \\left(\\frac{\\mathbf c \\mathbf d^\\top + \\mathbf d \\mathbf c^\\top}{2}\\right) \\bm x \\geq 0.\n\nMore general sets (general polyhedra, noncentered ellipsoids) can also be modelled using LMI too… We are going to have a look at them, but first we hurry to show how to combine the subset characterization and Lyapunov-ness using the S-procedure.",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html#combining-the-subset-characterization-and-lyapunov-ness-using-the-s-procedure",
    "href": "stability_via_multiple_lyapunov_function.html#combining-the-subset-characterization-and-lyapunov-ness-using-the-s-procedure",
    "title": "Stability via multiple Lyapunov functions",
    "section": "Combining the subset characterization and Lyapunov-ness using the S-procedure",
    "text": "Combining the subset characterization and Lyapunov-ness using the S-procedure\nWe want to learn if the the following hold \n\\alpha_i \\bm x^\\top \\mathbf I \\bm x \\leq \\bm x^\\top \\mathbf P_i \\bm x,\n\n\n\\bm x^\\top \\left( \\mathbf A_i^\\top \\mathbf P_i + \\mathbf P_i \\mathbf A_i \\right) \\bm x \\leq  -\\gamma_i \\bm x^\\top \\mathbf I \\bm x,\n\nbut not for all \\bm x, but only for \\bm x\\in \\Omega_i, that is, all \\bm x satisfying \\bm x^\\top \\mathbf Q_i \\bm x \\geq 0. But this is now a perfect opportunity for application of the S-procedure:\n\n\\mathbf P_i - \\alpha_i \\mathbf I - \\mu_i \\mathbf Q_i \\succeq 0,\\quad \\mu_i \\geq 0,\\; \\alpha_i &gt; 0,\n\n\n\\mathbf A_i^\\top \\mathbf P_i + \\mathbf P_i \\mathbf A_i + \\gamma_i \\mathbf I + \\xi_i \\mathbf Q \\preceq 0,\\quad \\mu_i \\geq 0,\\; \\gamma_i &gt; 0.",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html#more-general-sets-using-lmi",
    "href": "stability_via_multiple_lyapunov_function.html#more-general-sets-using-lmi",
    "title": "Stability via multiple Lyapunov functions",
    "section": "More general sets using LMI",
    "text": "More general sets using LMI\nHow can we model more general sets using LMI?\nThe inequality \n\\bm x^\\top \\mathbf Q \\bm x + 2\\mathbf r^\\top \\bm x + s \\geq 0,\n\ncan be reformulated as \n\\begin{bmatrix}\n\\bm x^\\top & 1\n\\end{bmatrix}\n\\underbrace{\n\\begin{bmatrix}\n\\mathbf Q & \\mathbf r \\\\ \\mathbf r^\\top & s\n\\end{bmatrix}}_{\\bar{\\mathbf{Q}}}\n\\underbrace{\n\\begin{bmatrix}\n\\bm x \\\\ 1\n\\end{bmatrix}}_{\\bar{\\bm x}}\n\\geq 0,\n\nthat is, as an LMI \n\\begin{bmatrix}\n\\mathbf Q & \\mathbf r \\\\ \\mathbf r^\\top & s\n\\end{bmatrix}\n\\succeq 0.\n\n\nAffine subspace\n\n\\mathbf c^\\top \\bm x + d \\geq 0,\n\n\n\\begin{bmatrix}\n\\bm x^\\top & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf 0 & \\mathbf c \\\\ \\mathbf c^\\top & 2d\n\\end{bmatrix}\n\\begin{bmatrix}\n\\bm x \\\\ 1\n\\end{bmatrix}\n\\geq 0,\n\n\n\\begin{bmatrix}\n\\mathbf 0 & \\mathbf c \\\\ \\mathbf c^\\top & 2d\n\\end{bmatrix}\n\\succeq 0.\n\nBut then the Lyapunov-like functions and system matrices must also be extended \nV(\\bm x) =\n\\begin{bmatrix}\n\\bm x^\\top & 1\n\\end{bmatrix}\n\\underbrace{\n\\begin{bmatrix}\n\\mathbf P & \\mathbf P_{12} \\\\ \\mathbf P_{12} & P_{22}\n\\end{bmatrix}}_{\\bar{\\mathbf P}}\n\\begin{bmatrix}\n\\bm x \\\\ 1\n\\end{bmatrix},\n\n\n\\bar{\\mathbf{A}} =\n\\begin{bmatrix}\n\\mathbf A & \\mathbf 0 \\\\ \\mathbf 0 & 0\n\\end{bmatrix}.",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "stability_via_multiple_lyapunov_function.html#continuity-conditions",
    "href": "stability_via_multiple_lyapunov_function.html#continuity-conditions",
    "title": "Stability via multiple Lyapunov functions",
    "section": "Continuity conditions",
    "text": "Continuity conditions\nThe boundary between the regions \\Omega_i and \\Omega_j described by \n\\Omega_{ij} = \\{\\bm x \\in \\mathbb R^n \\mid \\mathbf F_{ij} \\bm z + \\mathbf{l}_{ij}\\},\n where \\bm z\\in \\mathbb R^p, \\mathbf F_{ij}\\in \\mathbb R^{n\\times p}, and \\mathbf l_{ij}\\in \\mathbb R^{n}.\nThe continuity conditions are \nV_i(\\bm x) = V_j(\\bm x) \\quad \\forall \\bm x \\in \\Omega_{ij},\n which can be reformulated as \n\\begin{aligned}\n&\\left(\\mathbf F_{ij} \\bm z + \\mathbf{l}_{ij}\\right)^\\top \\mathbf P_i \\left(\\mathbf F_{ij} \\bm z + \\mathbf{l}_{ij}\\right) \\\\\n& \\qquad + 2\\left(\\mathbf F_{ij} \\bm z + \\mathbf{l}_{ij}\\right)^\\top \\bm q_i + r_i \\\\\n&= \\left(\\mathbf F_{ij} \\bm z + \\mathbf{l}_{ij}\\right)^\\top \\mathbf P_j \\left(\\mathbf F_{ij} \\bm z + \\mathbf{l}_{ij}\\right) \\\\\n& \\qquad + 2\\left(\\mathbf F_{ij} \\bm z + \\mathbf{l}_{ij}\\right)^\\top \\bm q_j + r_j\n\\end{aligned}.\n\nCollecting the terms with equal powers of \\bm z. \n\\begin{aligned}\n\\mathbf F_{ij}^\\top (\\mathbf P_1 - \\mathbf P_2) \\mathbf F_{ij} &= 0, \\\\\n\\mathbf F_{ij}^\\top (\\mathbf P_1 - \\mathbf P_2) \\mathbf l_{ij} + (\\mathbf q_1-\\mathbf q_2)  &= 0, \\\\\n\\mathbf l_{ij}^\\top (\\mathbf P_1 - \\mathbf P_2)\\mathbf l_{ij} + 2\\mathbf l_{ij}^\\top (\\mathbf q_1-\\mathbf q_2) + r_1-r_2 &= 0.\n\\end{aligned}",
    "crumbs": [
      "8. Stability",
      "Stability via multiple Lyapunov functions"
    ]
  },
  {
    "objectID": "complementarity_references.html",
    "href": "complementarity_references.html",
    "title": "Literature",
    "section": "",
    "text": "Concise (short and yet sufficient for our purposes) introduction to (linear) complementarity problems and systems is in [1]. Besides describing the idea of complementarity in dynamical systems, it also shows how it is related to other modeling frameworks for hybrid dynamical systems. More detailed and yet very accessible introduction is in the thesis [2]. Condensed treatment is in the papers [3] and [4].\nA readable introduction to the Extended Linear Complementarity Problem is in [5] (it is also freely available as a technical report).\nThe topics of complementarity constraints in dynamical systems and optimization is still being actively researched. A recent publication on QP optimization with complementarity constraints (LCQP) is [6].\nNumerical methods for nonsmooth dynamical systems that are based on complementary constraints (and implemented in SICONOS software) are comprehensively presented in [7].\n\n\n\n\n Back to topReferences\n\n[1] W. P. M. H. Heemels, B. De Schutter, and A. Bemporad, “Equivalence of hybrid dynamical models,” Automatica, vol. 37, no. 7, pp. 1085–1091, Jul. 2001, doi: 10.1016/S0005-1098(01)00059-0.\n\n\n[2] M. Heemels, “Linear complementarity systems: a study in hybrid dynamics,” PhD thesis, Technische Universiteit Eindhoven, Eindhoven, NL, 1999. Available: https://heemels.tue.nl/content/papers/Hee_TUE99a.pdf\n\n\n[3] W. P. M. H. Heemels, J. M. Schumacher, and S. Weiland, “Linear Complementarity Systems,” SIAM Journal on Applied Mathematics, vol. 60, no. 4, pp. 1234–1269, Jan. 2000, doi: 10.1137/S0036139997325199.\n\n\n[4] A. J. van der Schaft and J. M. Schumacher, “Complementarity modeling of hybrid systems,” IEEE Transactions on Automatic Control, vol. 43, no. 4, pp. 483–490, Apr. 1998, doi: 10.1109/9.664151.\n\n\n[5] B. De Schutter and B. De Moor, “The Extended Linear Complementarity Problem and the Modeling and Analysis of Hybrid Systems,” in Hybrid Systems V, P. Antsaklis, M. Lemmon, W. Kohn, A. Nerode, and S. Sastry, Eds., in Lecture Notes in Computer Science. Berlin, Heidelberg: Springer, 1999, pp. 70–85. doi: 10.1007/3-540-49163-5_4.\n\n\n[6] J. Hall, A. Nurkanovic, F. Messerer, and M. Diehl, “LCQPow – A Solver for Linear Complementarity Quadratic Programs.” arXiv, Nov. 2022. Accessed: Dec. 03, 2022. [Online]. Available: http://arxiv.org/abs/2211.16341\n\n\n[7] V. Acary and B. Brogliato, Numerical Methods for Nonsmooth Dynamical Systems: Applications in Mechanics and Electronics. in Lecture Notes in Applied and Computational Mechanics, no. 35. Berlin Heidelberg: Springer, 2008. Available: https://doi.org/10.1007/978-3-540-75392-6",
    "crumbs": [
      "9. Complementarity systems",
      "Literature"
    ]
  },
  {
    "objectID": "intro_outline.html",
    "href": "intro_outline.html",
    "title": "Course outline",
    "section": "",
    "text": "The course is structured into 14 topics, each of them corresponding to one lecture. The topics are as follows:\n\nDiscrete-event systems\n\n(State) automata (state machines) (incl. timed variants)\nPetri nets (and timed Petri nets),\nMax-Plus algebra and Max-Plus Linear (MPL) systems\n\nHybrid systems\n\nHybrid automata\nHybrid equations\n\nSpecial classes of hybrid systems\n\nReset (control) systems, Switched/switching systems, Piecewise affine systems (PWA)\nComplementarity dynamical systems (and complementarity optimization constraints)\n\n\n\n\nSolutions of hybrid systems\n\n\nStability of hybrid systems\n\nCommon Lyapunov function\n\nQuadratic Lyapunov function via linear matrix inequality (LMI) and semidefinite programming (SDP)\nPolynomial Lyapunov function via sum-of-squares (SOS) programming\n\nPiecewise quadratic/polynomial Lyapunov function via S-procedure\n\n\n\nMixed-logical dynamical (MLD) description of hybrid systems\nModel predictive control (MPC) for MLD systems\n(Formal) verification of hybrid systems\n\n\n\n\n Back to top",
    "crumbs": [
      "0. Introduction",
      "Course outline"
    ]
  },
  {
    "objectID": "hybrid_equations_references.html",
    "href": "hybrid_equations_references.html",
    "title": "Literature",
    "section": "",
    "text": "The theoretical and computational framework of hybrid equations has been mostly developed by a relatively small circle of researchers (Sanfelice, Goebel, Teel, …). The primary monograph is [1]. It is also supported by a freely available Matlab toolbox, see the section on software.\n\nThe book [2] can be regarded as a predecessor and/or complement of the just mentioned [1]. Although the book is not available online, a short version appears as an article [3] in the popular IEEE Control Systems magazine (the one with color figures :-).\n\n\n\n\n\n Back to topReferences\n\n[1] R. G. Sanfelice, Hybrid Feedback Control. Princeton University Press, 2021. Accessed: Sep. 23, 2020. [Online]. Available: https://press.princeton.edu/books/hardcover/9780691180229/hybrid-feedback-control\n\n\n[2] R. Goebel, R. G. Sanfelice, and A. R. Teel, Hybrid Dynamical Systems: Modeling, Stability, and Robustness. Princeton University Press, 2012. Available: https://press.princeton.edu/books/hardcover/9780691153896/hybrid-dynamical-systems\n\n\n[3] R. Goebel, R. G. Sanfelice, and A. R. Teel, “Hybrid dynamical systems,” IEEE Control Systems Magazine, vol. 29, no. 2, pp. 28–93, Apr. 2009, doi: 10.1109/MCS.2008.931718.",
    "crumbs": [
      "5. Hybrid systems: Hybrid equations",
      "Literature"
    ]
  },
  {
    "objectID": "hybrid_automata.html",
    "href": "hybrid_automata.html",
    "title": "Hybrid automata",
    "section": "",
    "text": "Well, here we are at last. After these three introductory topics on discrete-event systems, we’ll finally get into hybrid systems.\nThere are two frameworks for modelling hybrid systems:\nHere we start with the former and save the latter for the next chapter/week.\nFirst we consider an autonomous (=no external/control inputs) hybrid automaton – it is a tuple of sets and (set) mappings \n\\boxed{\n\\mathcal{H} = \\{\\mathcal Q, \\mathcal Q_0, \\mathcal X, \\mathcal X_0, f, \\mathcal I, \\mathcal E, \\mathcal G, \\mathcal R\\},}\n where",
    "crumbs": [
      "4. Hybrid systems: Hybrid automata",
      "Hybrid automata"
    ]
  },
  {
    "objectID": "hybrid_automata.html#hybrid-automaton-with-external-events-and-control-inputs",
    "href": "hybrid_automata.html#hybrid-automaton-with-external-events-and-control-inputs",
    "title": "Hybrid automata",
    "section": "Hybrid automaton with external events and control inputs",
    "text": "Hybrid automaton with external events and control inputs\nWe now extend the hybrid automaton with two new components:\n\na set \\mathcal{A} of (external) events (also actions or symbols),\na set \\mathcal{U} external continuous-valued inputs (control inputs or disturbances).\n\n\\boxed{\n  \\mathcal{H} = \\{\\mathcal Q, \\mathcal Q_0, \\mathcal X, \\mathcal X_0, \\mathcal I, \\mathcal A, \\mathcal U, f, \\mathcal E, \\mathcal G, \\mathcal R\\} ,}\n where\n\n\\mathcal A = \\{a_1,a_2,\\ldots, a_s\\} is a set of events\n\nThe role identical as in a (finite) state automaton: an external event triggers an (enabled) transition from the current discrete state (mode, location) to another.\nUnlike in pure discrete-event systems, here they are considered within a model that does recognize passing of time – each action must be “time-stamped”.\nIn simulations such timed event can be represented by an edge in the signal. In this regard, it might be tempting not to introduce it as a seperate entity, but it is useful to do so.\n\n\\mathcal U\\in\\mathbb R^m is a set of continuous-valued inputs\n\nReal-valued functions of time.\nControl inputs, disturbances, references, noises. In applications it will certainly be useful to distinghuish these roles, but here we keep just a single type of such an external variable, we do not have to distinguish.\n\n\n\nSome modifications needed\nUpon introduction of these two types of external inputs we must modify the components of the definition we provided earlier:\n\nf: \\mathcal Q \\times \\mathcal X \\times \\mathcal U \\rightarrow \\mathbb R^n is a vector field that now depends not only on the location but also on the external (control) input, that is, at a given location we consider the state equation \\dot x = f_q(x,u).\n\\mathcal E\\subseteq \\mathcal Q \\times (\\mathcal A) \\times \\mathcal Q is a set of transitions now possibly parameterized by the actions (as in classical automata).\n\\mathcal I : \\mathcal Q \\rightarrow 2^{\\mathcal{X}\\times \\mathcal U} is a location invariant now augmented with a subset of the control input set. The necessary condition for staying in the given mode can be thus imposed not only on x but also on u.\n\\mathcal G: \\mathcal E \\rightarrow 2^{\\mathcal{X}\\times U} is a guard set now augmented with a subset of the control input set. The necessary condition for a given transition can be thus imposed not only on x but also on u.\n\\mathcal R: \\mathcal E \\times \\mathcal X\\times \\mathcal U\\rightarrow 2^{\\mathcal X} is a (state) reset map that is now additionally parameterized by the control input.\n\nIf enabled, the transition can happen if one of the two things is satisfied:\n\nthe continous state leaves the invariant set of the given location,\n\nan external event occurs.\n\n\nExample 2 (Button-controlled LED)  \n\n\n\n\n\n\nFigure 2: Automaton for a button controlled LED\n\n\n\n\n\\mathcal{Q} = \\{\\mathrm{off}, \\mathrm{dim}, \\mathrm{bright}\\},\\quad \\mathcal{Q}_0 = \\{\\mathrm{off}\\}\n\n\n\\mathcal{X} = \\mathbb{R}, \\quad \\mathcal{X}_0 = \\{0\\}\n\n\n\\mathcal{I(\\mathrm{off})} = \\mathcal{I(\\mathrm{bright})} = \\mathcal{I(\\mathrm{dim})} = \\{x\\in\\mathbb R \\mid x \\geq 0\\}\n\n\nf(x) = 1\n\n\n\\mathcal{A} = \\{\\mathrm{press}\\}\n\n\n\\begin{aligned}\n\\mathcal{E} &= \\{(\\mathrm{off},\\mathrm{press},\\mathrm{dim}),(\\mathrm{dim},\\mathrm{press},\\mathrm{off}),\\\\\n&\\qquad (\\mathrm{dim},\\mathrm{press},\\mathrm{bright}),(\\mathrm{bright},\\mathrm{press},\\mathrm{off})\\}\n\\end{aligned}\n\n\n\\begin{aligned}\n\\mathcal{G}((\\mathrm{off},\\mathrm{press},\\mathrm{dim})) &= \\mathcal X \\\\\n\\mathcal{G}((\\mathrm{dim},\\mathrm{press},\\mathrm{off})) &= \\{x \\in \\mathcal X \\mid x&gt;2\\}\\\\\n\\mathcal{G}((\\mathrm{dim},\\mathrm{press},\\mathrm{bright})) &= \\{x \\in \\mathcal X \\mid x\\leq 2\\}\\\\\n\\mathcal{G}((\\mathrm{bright},\\mathrm{press},\\mathrm{off})) &= \\mathcal X.\n\\end{aligned}\n\n\nr((\\mathrm{off},\\mathrm{press},\\mathrm{dim}),x) = 0,\n\n\nthat is, x^+ = r((\\mathrm{off},\\mathrm{press},\\mathrm{dim}),x) = 0.\nFor all other transitions r((\\cdot, \\cdot, \\cdot),x)=x,\n\nthat is, x^+ = x.\n\n\n\n\nExample 3 (Water tank) We consider a water tank with one inflow and two outflows – one at the bottom, the other at some nonzero height h_\\mathrm{m}. The water level h is the continuous state variable.\n\n\n\n\n\n\nFigure 3: Water tank example\n\n\n\nThe model essentially expresses that the change in the volume is given by the difference between the inflow and the outflows. The outflows are proportional to the square root of the water level (Torricelli’s law) \n\\dot V =\n\\begin{cases}\nQ_\\mathrm{in} - Q_\\mathrm{out,middle} - Q_\\mathrm{out,bottom}, & h&gt;h_\\mathrm{m}\\\\\nQ_\\mathrm{in} - Q_\\mathrm{out,bottom}, & h\\leq h_\\mathrm{m}\n\\end{cases}\n\nApparently things change when the water level crosses (in any direction) the height h_\\mathrm{m}. This can be modelled using a hybrid automaton.\n\n\n\n\n\n\nFigure 4: Automaton for a water tank example\n\n\n\nOne lesson to learn from this example is that the transition from one mode to another is not necessarily due to some computer-controlled switch. Instead, it is our modelling choice. It is an approximation that assumes negligible diameter of the middle pipe. But taking into the consideration the volume of the tank, it is probably a justifiable approximation.\n\n\nExample 4 (Bouncing ball) We assume that a ball is falling from some initial nonzero height above the table. After hitting the table, it bounces back, loosing a portion of the energy (the deformation is not perfectly elastic).\n\n\n\n\n\n\nFigure 5: Bouncing ball example\n\n\n\nThe state equation during the free fall is \n\\dot{\\bm x} = \\begin{bmatrix} x_2\\\\ -g\\end{bmatrix}, \\quad \\bm x = \\begin{bmatrix}10\\\\0\\end{bmatrix}.\n\nBut how can we model what happens during and after the collision? High-fidelity model would be complicated, involving partial differential equations to model the deformation of the ball and the table. These complexities can be avoided with a simpler model assuming that immediately after the collision the sign of the velocity abruptly (discontinuously) changes, and at the same time the ball also looses a portion of the energy.\nWhen modelling this using a hybrid automaton, it turns out that we only need a single discrete state. The crucial feature of the model is then the nontrivial (non-identity) reset map. This is depicted in Fig. 6.\n\n\n\n\n\n\nFigure 6: Hybrid automaton for a bouncing ball eaxample\n\n\n\nFor completeness, here are the individual components of the hybrid automaton: \n\\mathcal{Q} = \\{q\\}, \\; \\mathcal{Q}_0 = \\{q\\}\n\n\n\\mathcal{X} = \\mathbb R^2, \\; \\mathcal{X}_0 = \\left\\{\\begin{bmatrix}10\\\\0\\end{bmatrix}\\right\\}\n\n\n\\mathcal{I} = \\{\\mathbb R^2 \\mid x_1 &gt; 0 \\lor (x_1 = 0 \\land x_2 \\geq 0)\\}\n\n\nf(\\bm x) = \\begin{bmatrix} x_2\\\\ -g\\end{bmatrix}\n\n\n\\mathcal{E} = \\{(q,q)\\}\n\n\n\\mathcal{G} = \\{\\bm x\\in\\mathbb R^2 \\mid x_1=0 \\land x_2 &lt; 0\\}\n\n\nr((q,q),\\bm x) = \\begin{bmatrix}x_1\\\\ -\\gamma x_2 \\end{bmatrix},\n where \\gamma is the coefficient of restitution (e.g., \\gamma = 0.9).\n\n\n\n\n\n\nComment on the invariant set for the bouncing ball\n\n\n\nSome authors characterize the invariant set as x_1\\geq 0. But this means that as the ball touches the ground, nothing forces it to leave the location and do the transition. Instead, the ball must penetrate the ground, however tiny distance, in order to trigger the transition. The current definition avoids this.\n\n\n\n\n\n\n\n\nAnother comment on the invariant set for the bouncing ball\n\n\n\nWhile the previous remark certainly holds, when solving the model numerically, the use of inequalities to define sets is inevitable. And some numerical solvers, in particular optimization solvers, cannot handle strict inequalities. That is perhaps why some authors are quite relaxed about this issue. We will encounter it later on.\n\n\n\n\nExample 5 (Stick-slip friction model (Karnopp)) Consider a block of mass m placed freely on a surface. External horizontal force F_\\mathrm{a} is applied to the block, setting it to a horizontaly sliding motion, against which the friction force F_\\mathrm{f} is acting: \nm\\dot v = F_\\mathrm{a} - F_\\mathrm{f}(v).\n\nCommon choice for a model of friction between two surfaces is Coulomb friction \nF_\\mathrm{f}(v) = F_\\mathrm{c}\\operatorname*{sgn}(v).\n\nThe model is perfectly intuitive, isn’t it? Well, what if v=0 and F_\\mathrm{a}&lt;F_\\mathrm{c}? Can you see the trouble?\nOne of the remedies is the Karnopp model of friction \nm\\dot v = 0, \\qquad v=0, \\; |F_\\mathrm{a}| &lt; F_\\mathrm{c}\n \nF_\\mathrm{f} = \\begin{cases}\\operatorname*{sat}(F_\\mathrm{a},F_\\mathrm{c}), & v=0\\\\F_\\mathrm{c}\\operatorname*{sgn}(v), & \\mathrm{else}\\end{cases}\n\nThe model can be formulated as a hybrid automaton with two discrete states (modes, locations) as in Fig. 7.\n\n\n\n\n\n\nFigure 7: Hybrid automaton for the Karnopp model of friction\n\n\n\n\n\nExample 6 (Rimless wheel) A simple mechanical model that is occasionally used in the walking robot community is the rimless wheel rolling down a declined plane as depicted in Fig. 8.\n\n\n\n\n\n\nFigure 8: Rimless wheel\n\n\n\nA hybrid automaton for the rimless wheel is below.\n\n\n\n\n\n\nFigure 9: Hybrid automaton for a rimless wheel\n\n\n\nAlternatively, we do not represent the discrete state graphically as a node in the graph but rather as another – extending – state variable s \\in \\{0, 1, \\ldots, 5\\} within a single location.\n\n\n\n\n\n\nFigure 10: Alternative hybrid automaton for a rimless wheel\n\n\n\n\n\nExample 7 (DC-DC boost converter) The enabling mechanism for a DC-DC converter is switching. Although the switching is realized with a semiconductor switch, for simplicity of the exposition we consider a manual switch in Fig. 11 below.\n\n\n\n\n\n\nFigure 11: DC-DC boost converter\n\n\n\nThe switch introduces two modes of operation. But the (ideal) diode introduces a mode transition too.\n\nThe switch closed\n\n\n\n\n\n\nFigure 12: DC-DC boost converter: the switch closed\n\n\n\n\n\\begin{bmatrix}\n\\frac{\\mathrm{d}i_\\mathrm{L}}{\\mathrm{d}t}\\\\\n\\frac{\\mathrm{d}v_\\mathrm{C}}{\\mathrm{d}t}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-\\frac{R_\\mathrm{L}}{L}i_\\mathrm{L} & 0\\\\\n0 & -\\frac{1}{C(R+R_\\mathrm{C})}\n\\end{bmatrix}\n\\begin{bmatrix}\ni_\\mathrm{L}\\\\\nv_\\mathrm{C}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\frac{1}{L}\\\\\n0\n\\end{bmatrix}\nv_0\n\n\n\nContinuous conduction mode (CCM)\n\n\n\n\n\n\nFigure 13: DC-DC boost converter: continuous conduction mode (CCM)\n\n\n\n\n\\begin{bmatrix}\n\\frac{\\mathrm{d}i_\\mathrm{L}}{\\mathrm{d}t}\\\\\n\\frac{\\mathrm{d}v_\\mathrm{C}}{\\mathrm{d}t}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-\\frac{R_\\mathrm{L}+ \\frac{RR_\\mathrm{C}}{R+R_\\mathrm{C}}}{L} & -\\frac{R}{L(R+R_\\mathrm{C})}\\\\\n\\frac{R}{C(R+R_\\mathrm{C})} & -\\frac{1}{C(R+R_\\mathrm{C})}\n\\end{bmatrix}\n\\begin{bmatrix}\ni_\\mathrm{L}\\\\\nv_\\mathrm{C}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\frac{1}{L}\\\\\n0\n\\end{bmatrix}\nv_0\n\n\n\nDiscontinuous cond. mode (DCM)\n\n\n\n\n\n\nFigure 14: DC-DC boost converter: discontinuous conduction model (DCM)\n\n\n\n\n\\begin{bmatrix}\n\\frac{\\mathrm{d}i_\\mathrm{L}}{\\mathrm{d}t}\\\\\n\\frac{\\mathrm{d}v_\\mathrm{C}}{\\mathrm{d}t}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 & 0\\\\\n0 & -\\frac{1}{C(R+R_\\mathrm{C})}\n\\end{bmatrix}\n\\begin{bmatrix}\ni_\\mathrm{L}\\\\\nv_\\mathrm{C}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n0\\\\\n0\n\\end{bmatrix}\nv_0\n\n\nPossibly the events of opening and closing the switch can be driven by time: opening the switch is derived from the value of an input signal, closing the switch is periodic.\n\n\n\n\n\n\n\nFigure 15: Hybrid automaton for a DC-DC boost converter",
    "crumbs": [
      "4. Hybrid systems: Hybrid automata",
      "Hybrid automata"
    ]
  }
]